{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR2eE_KHDdEY"
      },
      "source": [
        "# INSTALLATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ErvJRkTnCan",
        "outputId": "fe400366-1421-4b6c-a9f2-788e635cd3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOdHWBRi2G9v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Code that triggers warnings\n",
        "# ...\n",
        "\n",
        "# Restore the warning behavior\n",
        "warnings.resetwarnings()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv-7G2Y93iuq",
        "outputId": "bc5a8cd7-cbd1-471d-e81d-95d42d4f24f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Collecting textattack\n",
            "  Downloading textattack-0.3.9-py3-none-any.whl (436 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.8/436.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bert-score>=0.3.5 (from textattack)\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from textattack) (0.6.2)\n",
            "Collecting flair (from textattack)\n",
            "  Downloading flair-0.13.1-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from textattack) (3.13.1)\n",
            "Collecting language-tool-python (from textattack)\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Collecting lemminflect (from textattack)\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lru-dict (from textattack)\n",
            "  Downloading lru_dict-1.3.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting datasets>=2.4.0 (from textattack)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textattack) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.11.4)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (4.35.2)\n",
            "Collecting terminaltables (from textattack)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from textattack) (4.66.1)\n",
            "Collecting word2number (from textattack)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words (from textattack)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from textattack) (10.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.7.1)\n",
            "Collecting pinyin>=0.4.0 (from textattack)\n",
            "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from textattack) (0.42.1)\n",
            "Collecting OpenHowNet (from textattack)\n",
            "  Downloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
            "Collecting pycld2 (from textattack)\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click<8.1.0 (from textattack)\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (23.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.4.0->textattack)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.4.1)\n",
            "Collecting multiprocess (from datasets>=2.4.0->textattack)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2023.3.post1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.4.1)\n",
            "Collecting boto3>=1.20.27 (from flair->textattack)\n",
            "  Downloading boto3-1.34.29-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m786.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.2 (from flair->textattack)\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Collecting conllu>=4.0 (from flair->textattack)\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting deprecated>=1.2.13 (from flair->textattack)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting ftfy>=6.1.0 (from flair->textattack)\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.7.3)\n",
            "Requirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.3.2)\n",
            "Collecting janome>=0.4.2 (from flair->textattack)\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect>=1.0.9 (from flair->textattack)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.9.4)\n",
            "Collecting mpld3>=0.3 (from flair->textattack)\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pptree>=3.1 (from flair->textattack)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair->textattack)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.2)\n",
            "Collecting segtok>=1.5.11 (from flair->textattack)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair->textattack)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.9.0)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack)\n",
            "  Downloading transformer_smaller_training_vocab-0.3.3-py3-none-any.whl (14 kB)\n",
            "Collecting urllib3<2.0.0,>=1.0.0 (from flair->textattack)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wikipedia-api>=0.5.7 (from flair->textattack)\n",
            "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
            "Collecting semver<4.0.0,>=3.0.0 (from flair->textattack)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (1.3.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->textattack)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anytree (from OpenHowNet->textattack)\n",
            "  Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (67.7.2)\n",
            "Collecting botocore<1.35.0,>=1.34.29 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading botocore-1.34.29-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair->textattack)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from bpemb>=0.3.2->flair->textattack)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair->textattack) (1.14.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (4.0.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack) (4.11.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair->textattack) (6.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair->textattack) (3.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (3.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (2.1.4)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets>=2.4.0->textattack)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
            "Collecting accelerate>=0.20.3 (from transformers>=4.30.0->textattack)\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers>=4.30.0->textattack) (5.9.5)\n",
            "Building wheels for collected packages: pinyin, pycld2, word2number, docopt, langdetect, pptree, sqlitedict\n",
            "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630476 sha256=f3d61ed033b0a5dc0554713a40b5a9b03929a440cafedec5de30aa2a9db55fda\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/38/af/616fc6f154aa5bae65a1da12b22d79943434269f0468ff9b3f\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=9904061 sha256=03ce6a25edc44ad2881f68155aa920e80a81d1bd9365ef9c7510d0d1a9baf02a\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=3211b892d7a8b548965fe2f3140506553b40155f31a0fcdadef916645908824d\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=6bf157ff759852c6adf496e1ebdc1a6d954348c59bfa675a215d2b2fff9fefac\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=f22cb05c9e2af2b37fd91b84fa42ec90e37a60c2904ce25f57cc71c1e3942090\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=9421d0a3a288de85ecb36f8b6e290a343993bcd2feb41d22e72372b14bc4c469\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=63d312fbd4cf2fc26b9058b735e5999adc911846f3bb9e9b698b8189d7150c5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "Successfully built pinyin pycld2 word2number docopt langdetect pptree sqlitedict\n",
            "Installing collected packages: word2number, sqlitedict, sentencepiece, pycld2, pptree, pinyin, janome, docopt, urllib3, terminaltables, semver, segtok, num2words, lru-dict, lemminflect, langdetect, jmespath, ftfy, dill, deprecated, conllu, click, anytree, multiprocess, botocore, wikipedia-api, s3transfer, pytorch-revgrad, OpenHowNet, mpld3, language-tool-python, bpemb, datasets, boto3, accelerate, bert-score, transformer-smaller-training-vocab, flair, textattack\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed OpenHowNet-2.0 accelerate-0.26.1 anytree-2.12.1 bert-score-0.3.13 boto3-1.34.29 botocore-1.34.29 bpemb-0.3.4 click-8.0.4 conllu-4.5.3 datasets-2.16.1 deprecated-1.2.14 dill-0.3.7 docopt-0.6.2 flair-0.13.1 ftfy-6.1.3 janome-0.5.0 jmespath-1.0.1 langdetect-1.0.9 language-tool-python-2.7.1 lemminflect-0.2.3 lru-dict-1.3.0 mpld3-0.5.10 multiprocess-0.70.15 num2words-0.5.13 pinyin-0.4.0 pptree-3.1 pycld2-0.41 pytorch-revgrad-0.2.0 s3transfer-0.10.0 segtok-1.5.11 semver-3.0.2 sentencepiece-0.1.99 sqlitedict-2.1.0 terminaltables-3.1.10 textattack-0.3.9 transformer-smaller-training-vocab-0.3.3 urllib3-1.26.18 wikipedia-api-0.6.0 word2number-1.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/OpenHowNet-2.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/accelerate-0.26.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/bert_score-0.3.13.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/boto3-1.34.29.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/botocore-1.34.29.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/bpemb-0.3.4.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/click-8.0.4.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/conllu-4.5.3.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/datasets-2.16.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/Deprecated-1.2.14.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/dill-0.3.7.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/docopt-0.6.2.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/flair-0.13.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/Janome-0.5.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/jmespath-1.0.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/langdetect-1.0.9.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/language_tool_python-2.7.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/lemminflect-0.2.3.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/lru_dict-1.3.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/mpld3-0.5.10.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/multiprocess-0.70.15.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/num2words-0.5.13.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/pinyin-0.4.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/pptree-3.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/pycld2-0.41.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/s3transfer-0.10.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/segtok-1.5.11.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/semver-3.0.2.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/sentencepiece-0.1.99.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/sqlitedict-2.1.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/textattack-0.3.9.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/urllib3-1.26.18.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/Wikipedia_API-0.6.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_pip.py:85: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.10/dist-packages/word2number-1.1.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install textattack\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCByBHUp3rN6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(f'/content/gdrive/My Drive/Transformer-Explainability')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cep8C1eS4DzT"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt\n",
        "#!pip install --no-cache-dir --find-links https://download.pytorch.org/whl/torch_stable.html torch==1.6.0+cu101 torchvision==0.7.0+cu101\n",
        "#!pip install --upgrade numpy scipy pandas matplotlib\n",
        "!pip install captum\n",
        "!pip install textattack\n",
        "!pip install tensorflow_text==2.8.2\n",
        "!pip install symspellpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wbHJ8VtXqR7"
      },
      "outputs": [],
      "source": [
        "!pip install textattack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjD5ByQD4NVc"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.14\n",
        "!pip install -U kaleido\n",
        "!pip install homoglyphs\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE2X1khx_yMF"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1BvOXA84ZkO"
      },
      "source": [
        "#IMPORT DEPENDIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmtWyfFB4gw1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(f'/content/gdrive/My Drive/Transformer-Explainability')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.stats import entropy\n",
        "!python -m pip install scipy\n",
        "from scipy import stats\n",
        "import statistics as st\n",
        "import plotly.express as px\n",
        "import codecs\n",
        "codecs.register_error(\"strict\", codecs.ignore_errors)\n",
        "import nltk\n",
        "import pickle\n",
        "import operator,functools\n",
        "nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string,re\n",
        "from string import digits\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')+[\"be\"]+[\"even\"]\n",
        "import re\n",
        "from collections import Counter\n",
        "from transformers import BertTokenizer\n",
        "from BERT_explainability.modules.BERT.ExplanationGenerator_org import Generator\n",
        "from BERT_explainability.modules.BERT.BertForSequenceClassification import BertForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForMaskedLM\n",
        "from BERT_explainability.modules.BERT.ExplanationGenerator2 import Generator3\n",
        "from BERT_explainability.modules.BERT.ExplanationGenerator3 import Generator786\n",
        "from captum.attr import (\n",
        "    visualization\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SnG9ZOiXh7Y"
      },
      "outputs": [],
      "source": [
        "import textattack\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "from collections import defaultdict\n",
        "import math\n",
        "from scipy import stats\n",
        "from statistics import *\n",
        "import csv\n",
        "import homoglyphs as hg\n",
        "homoglyphs =hg.Homoglyphs(languages={'en'},\n",
        "            strategy=hg.STRATEGY_LOAD,\n",
        "            ascii_strategy=hg.STRATEGY_REMOVE\n",
        "        )\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BISvQt8z5W4H"
      },
      "source": [
        "#EDIT UTILITIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lohQwqqr5VuN"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "from nltk.tokenize import word_tokenize,wordpunct_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "porter = PorterStemmer()\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def clean_str(text):\n",
        "    text = text.replace('\\\\n',' ')\n",
        "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
        "    text=re.sub(r'\\t',' t',text)\n",
        "    text = text.translate(str.maketrans(digits, ' '*len(digits)))\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = text.strip().lower()\n",
        "    finaltext=''\n",
        "    for word in text.split(' '):\n",
        "        finaltext+=porter.stem(word)+' '\n",
        "    finaltext=finaltext.strip()\n",
        "\n",
        "    return finaltext\n",
        "def get_label_batch(text_batch):\n",
        "  scores=[]\n",
        "  labels=[]\n",
        "  encoding = tokenizer(text_batch,padding=True,truncation=True, return_tensors='pt')\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask,return_dict=True)\n",
        "  for r in result.logits:\n",
        "\n",
        "     output2 = torch.nn.functional.softmax(r,dim=-1)\n",
        "     classification = output2.argmax(dim=-1).item()\n",
        "     output2=np.array(output2.detach().cpu())\n",
        "     scores.append(output2)\n",
        "     labels.append(int(classification))\n",
        "  return scores,labels\n",
        "def clean_str_wo_lemma(text):\n",
        "    text = text.replace('\\\\n',' ')\n",
        "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
        "    text=re.sub(r'\\t',' t',text)\n",
        "    text = text.translate(str.maketrans(digits, ' '*len(digits)))\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = text.strip().lower()\n",
        "    finaltext=text\n",
        "    # for word in text.split(' '):\n",
        "    #     finaltext+=porter.stem(word)+' '\n",
        "    # finaltext=finaltext.strip()\n",
        "\n",
        "    return finaltext\n",
        "def get_label(text):\n",
        "  encoding = tokenizer(text,padding=True,truncation=True, return_tensors='pt')\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  result = model(input_ids=input_ids, attention_mask=attention_mask,return_dict=True)\n",
        "  output2 = torch.nn.functional.softmax(result.logits,dim=-1)\n",
        "  classification = output2.argmax(dim=-1).item()\n",
        "  predicted_label_classes=classification\n",
        "\n",
        "  return int(predicted_label_classes),output2.detach().cpu()\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "def get_AEs_Roberta(datasetname,modelname,attack,sample_size):\n",
        "  print(\"RBOERA\")\n",
        "  path='/content/gdrive/My Drive/dataset/original/'+datasetname+'/roberta/'\n",
        "  filename=path+attack+'/roberta-base-'+datasetname+'_'+attack+'.csv'\n",
        "  test_AEs = pd.read_csv(filename)\n",
        "  random_df=shuffle(test_AEs)\n",
        "  random_df['attack']=attack\n",
        "\n",
        "  actual_adversarial = pd.DataFrame()  # Corrected the capitalization of 'DataFrame'\n",
        "  for i, row in random_df.iterrows():\n",
        "    Adv = row['perturbed_text']\n",
        "    Adv_Label, Adv_PCS = get_label(Adv)\n",
        "\n",
        "    if len(actual_adversarial) <=sample_size:  # Removed unnecessary parentheses\n",
        "        if Adv_Label != row['ground_truth_output']:\n",
        "            new_row = {\n",
        "                'perturbed_text': Adv,\n",
        "                'attack': row['attack'],\n",
        "                'Adv_Label': Adv_Label,\n",
        "                'Adv_PCS': Adv_PCS,\n",
        "                'ground_truth_output':row['ground_truth_output'],\n",
        "                'type':'adversarial'\n",
        "            }\n",
        "            actual_adversarial = actual_adversarial.append(new_row, ignore_index=True)\n",
        "            print(len(actual_adversarial), \" \", sample_size)\n",
        "            print(new_row)\n",
        "    else:\n",
        "      break\n",
        "  #test_AEs=test_AEs.sample(frac=1).reset_index(drop=True)\n",
        "  return actual_adversarial\n",
        "\n",
        "def get_AEs(datasetname,modelname,attack,sample_size):\n",
        "  path='/content/gdrive/My Drive/dataset/original/'+datasetname+'/bert/'\n",
        "  filename=path+attack+'/bert-base-uncased-'+datasetname+'_'+attack+'.csv'\n",
        "  test_AEs = pd.read_csv(filename)\n",
        "  # if(len(test_AEs)>sample_size):\n",
        "  #   # Seed for reproducibility\n",
        "  #   np.random.seed(42)\n",
        "\n",
        "    # Select 2000 random row indices\n",
        "    #random_indices = np.random.choice(test_AEs.index, size=sample_size, replace=False)\n",
        "\n",
        "    # Create a new dataframe using the selected rows\n",
        "    #random_df = test_AEs.loc[random_indices].copy()\n",
        "\n",
        "    # Reset the index of the new dataframe\n",
        "    #random_df.reset_index(drop=True, inplace=True)\n",
        "  #else:\n",
        "  random_df=shuffle(test_AEs)\n",
        "  random_df['attack']=attack\n",
        "\n",
        "  actual_adversarial = pd.DataFrame()  # Corrected the capitalization of 'DataFrame'\n",
        "  for i, row in random_df.iterrows():\n",
        "    Adv = row['perturbed_text']\n",
        "    Adv_Label, Adv_PCS = get_label(Adv)\n",
        "\n",
        "    if len(actual_adversarial) <=sample_size:  # Removed unnecessary parentheses\n",
        "        if Adv_Label != row['ground_truth_output']:\n",
        "            new_row = {\n",
        "                'perturbed_text': Adv,\n",
        "                'attack': row['attack'],\n",
        "                'Adv_Label': Adv_Label,\n",
        "                'Adv_PCS': Adv_PCS,\n",
        "                'ground_truth_output':row['ground_truth_output'],\n",
        "                'type':'adversarial'\n",
        "            }\n",
        "            actual_adversarial = actual_adversarial.append(new_row, ignore_index=True)\n",
        "            # print(len(actual_adversarial), \" \", sample_size)\n",
        "            # print(new_row)\n",
        "    else:\n",
        "      break\n",
        "  #test_AEs=test_AEs.sample(frac=1).reset_index(drop=True)\n",
        "  return actual_adversarial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20hkprE4dhto"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMbiymm6WkwF"
      },
      "source": [
        "# EDIT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur87yIheWqJP"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Dec 14 16:04:59 2022\n",
        "\n",
        "@author: bushra\n",
        "\"\"\"\n",
        "from sklearn import metrics\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "import sys\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import gutenberg\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "import re\n",
        "import random\n",
        "import csv\n",
        "from nltk.corpus import brown\n",
        "from collections import Counter\n",
        "import urllib.request\n",
        "from difflib import SequenceMatcher\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import ensemble\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import csv\n",
        "from numpy import average\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import coverage_error\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import average_precision_score\n",
        "# Load CSV (using python)\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "import itertools\n",
        "\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import pickle ,os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "\n",
        "from scipy.sparse import hstack\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Aug  1 11:42:35 2019\n",
        "\n",
        "@author: bushra\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import ensemble\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.svm import SVC\n",
        "from numpy import average\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import coverage_error\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import average_precision_score\n",
        "# Load CSV (using python)\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import label_ranking_average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        " # -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Jul 25 14:28:29 2019\n",
        "\n",
        "@author: bushra\n",
        "\"\"\"\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "from nltk import FreqDist\n",
        "import re\n",
        "import random\n",
        "import csv\n",
        "from nltk.corpus import brown\n",
        "from collections import Counter\n",
        "import urllib.request\n",
        "from difflib import SequenceMatcher\n",
        "import os\n",
        "import time\n",
        "start = time.time()\n",
        "import random\n",
        "#import validators\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "import itertools\n",
        "import sys\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import gutenberg\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "import re\n",
        "import random\n",
        "import csv\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import codecs,re\n",
        "codecs.register_error(\"strict\", codecs.ignore_errors)\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import sort\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import itertools,re\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# Load datasets\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score,balanced_accuracy_score\n",
        "from sklearn import feature_extraction\n",
        "\n",
        "\n",
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK,early_stop\n",
        "import pandas as pd,pickle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import scale, StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "models = {\n",
        "\n",
        "                   # 'rf' : RandomForestClassifier,\n",
        "                   # 'dt':DecisionTreeClassifier,\n",
        "                   # 'xgb':XGBClassifier,\n",
        "                    'lgbm':LGBMClassifier,\n",
        "                    # 'lr' : LogisticRegression,\n",
        "                    # 'knn' : KNeighborsClassifier\n",
        "                   #'svm' : SVC\n",
        "\n",
        "               }\n",
        "def search_space(model):\n",
        "    model = model.lower()\n",
        "    space = {}\n",
        "    if model == 'knn':\n",
        "                space = {\n",
        "                         'n_neighbors': hp.choice('n_neighbors', range(1,100)),\n",
        "                                         'scale': hp.choice('scale', [0, 1]),\n",
        "                         'normalize': hp.choice('normalize', [0, 1]),\n",
        "                        }\n",
        "\n",
        "    elif model == 'svm':\n",
        "                 space = {\n",
        "                             'C': hp.uniform('C', 0, 3),\n",
        "                             'kernel': hp.choice('kernel', ['linear']),\n",
        "                             #'gamma': hp.uniform('gamma', 0.01, 10),\n",
        "                             'scale': hp.choice('scale', [0, 1]),\n",
        "                         }\n",
        "    elif model == 'rf':\n",
        "        space = {\n",
        "                   'max_depth': hp.choice('max_depth', range(1,200)),\n",
        "                   #'max_features': hp.choice('max_features', range(1,3)),\n",
        "                   'n_estimators': hp.choice('n_estimators', range(100,400,100)),\n",
        "                   'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
        "                }\n",
        "    elif model == 'lr':\n",
        "       space = {\n",
        "              'warm_start' : hp.choice('warm_start', [True, False]),\n",
        "              'fit_intercept' : hp.choice('fit_intercept', [True, False]),\n",
        "              'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
        "               'C' : hp.uniform('C', 0.05, 3),\n",
        "               'solver' : hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
        "               'max_iter' : hp.choice('max_iter', range(100,1000)),\n",
        "               'scale': hp.choice('scale', [0, 1]),\n",
        "               'normalize': hp.choice('normalize', [0, 1]),\n",
        "               'multi_class' : 'auto',\n",
        "               'class_weight' : 'balanced'\n",
        "               }\n",
        "    elif model == 'dt':\n",
        "         space = {\n",
        "                'max_depth': hp.choice('max_depth', range(0,200)),\n",
        "                #'max_features': hp.choice('max_features', range(1,10)),\n",
        "                'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
        "                'scale': hp.choice('scale', [0, 1]),\n",
        "                'normalize': hp.choice('normalize', [0, 1])\n",
        "            }\n",
        "    elif model=='lgbm':\n",
        "        #LIGHTGBM PARAMETERS\n",
        "        space = {\n",
        "            'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
        "            'num_leaves': hp.quniform('num_leaves', 31, 500, 1),\n",
        "            'max_depth': hp.choice('max_depth', np.arange(3, 20, 1, dtype=int)),\n",
        "            'min_child_samples': hp.choice('min_child_samples', np.arange(1, 20, 1, dtype=int)),\n",
        "            'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
        "            'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
        "            'reg_alpha': hp.loguniform('reg_alpha', np.log(0.001), np.log(10.0)),\n",
        "            'reg_lambda': hp.loguniform('reg_lambda', np.log(0.001), np.log(1.0)),\n",
        "            'n_estimators': hp.choice('n_estimators', [100, 200, 300, 400, 500])\n",
        "        }\n",
        "\n",
        "    elif model =='xgb':\n",
        "\n",
        "         tree_method = [\n",
        "            #{'tree_method' : 'exact'},\n",
        "               {'tree_method' : 'approx'},\n",
        "               {'tree_method' : 'hist',\n",
        "                #'max_bin': hp.quniform('max_bin', 2**3, 2**7, 1),\n",
        "                'grow_policy' : {'grow_policy': {'grow_policy':'depthwise'},\n",
        "                                'grow_policy' : {'grow_policy':'lossguide',\n",
        "                                                 'max_leaves': hp.quniform('max_leaves', 100, 200, 1)}}}]\n",
        "\n",
        "\n",
        "         space ={\n",
        "                'tree_method' : hp.choice('tree_method', tree_method),\n",
        "                'max_depth': hp.quniform('max_depth', 30, 100, 1),\n",
        "                #'max_leaves':hp.quniform('max_leaves', 100, 200, 1),\n",
        "               }\n",
        "\n",
        "\n",
        "    space['model'] = model\n",
        "    return space\n",
        "\n",
        "def get_acc_status(clf,X_,y):\n",
        "    custom_scorer = {'accuracy': make_scorer(accuracy_score),\n",
        "                 'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
        "                 'precision': make_scorer(precision_score, average='macro'),\n",
        "                 'recall': make_scorer(recall_score, average='macro'),\n",
        "                 'f1': make_scorer(f1_score, average='macro'),\n",
        "                 'auc':'roc_auc',\n",
        "                 'Matthew': make_scorer(matthews_corrcoef),\n",
        "                 'FPR':FPR\n",
        "                 }\n",
        "    kf = StratifiedKFold(n_splits=10,random_state=42,shuffle=True)\n",
        "    score = cross_validate(clf, X_, y,cv=kf,scoring=custom_scorer,n_jobs=-1)\n",
        "    clf.fit(X_,y)\n",
        "\n",
        "\n",
        "    print('score is ####################',score)\n",
        "    return {'loss':1-score['test_Matthew'].mean(), 'status': STATUS_OK, 'Trained_Model': clf,'scoreMetrics': score}\n",
        "def scale_normalize(params,X_):\n",
        "    if 'normalize' in params:\n",
        "        if params['normalize'] == 1:\n",
        "            X_ = normalize(X_)\n",
        "        del params['normalize']\n",
        "    if 'scale' in params:\n",
        "        if params['scale'] == 1:\n",
        "            X_ = scale(X_,with_mean=False)\n",
        "        del params['scale']\n",
        "\n",
        "    return X_\n",
        "def obj_fnc(params):\n",
        "    model = params.get('model').lower()\n",
        "\n",
        "    if model == 'lgbm' :\n",
        "        integer_params = ['num_leaves']\n",
        "        for param in integer_params:\n",
        "               params[param] = int(params[param])\n",
        "    if model == 'xgb' :\n",
        "        integer_params = ['max_depth']\n",
        "        for param in integer_params:\n",
        "               params[param] = int(params[param])\n",
        "        if params['tree_method']['tree_method'] == 'hist':\n",
        "                #max_bin = params['tree_method'].get('max_bin')\n",
        "                #params['max_bin'] = int(max_bin)\n",
        "                if params['tree_method']['grow_policy']['grow_policy']['grow_policy'] == 'depthwise':\n",
        "                    grow_policy = params['tree_method'].get('grow_policy').get('grow_policy').get('grow_policy')\n",
        "                    params['grow_policy'] = grow_policy\n",
        "                    params['tree_method'] = 'hist'\n",
        "                else:\n",
        "                    max_leaves = params['tree_method']['grow_policy']['grow_policy'].get('max_leaves')\n",
        "                    params['grow_policy'] = 'lossguide'\n",
        "                    params['max_leaves'] = int(max_leaves)\n",
        "                    params['tree_method'] = 'hist'\n",
        "        else:\n",
        "                params['tree_method'] = params['tree_method'].get('tree_method')\n",
        "\n",
        "\n",
        "    X_ = scale_normalize(params,X[:])\n",
        "    del params['model']\n",
        "    clf = models[model](**params)\n",
        "    return(get_acc_status(clf,X_,y))\n",
        "\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "def getBestScoreMetricfromTrials(trials):\n",
        "    valid_trial_list = [trial for trial in trials\n",
        "                            if STATUS_OK == trial['result']['status']]\n",
        "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
        "    index_having_minumum_loss = np.argmin(losses)\n",
        "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
        "    return best_trial_obj['result']['scoreMetrics']\n",
        "\n",
        "def getBestModelfromTrials(trials):\n",
        "    valid_trial_list = [trial for trial in trials\n",
        "                            if STATUS_OK == trial['result']['status']]\n",
        "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
        "    index_having_minumum_loss = np.argmin(losses)\n",
        "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
        "    return best_trial_obj['result']['Trained_Model']\n",
        "#['Classifier','best_parameters','MCC','accuracy','bal_accu','precision','recall','f1','auc','fpr','fnr'])\n",
        "\n",
        "def evaluate(clf, X_train, X_test, y_train, y_test):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    FPR=0\n",
        "    FNR=0\n",
        "    Auc=0\n",
        "    cnmat = confusion_matrix(np.asarray(y_test),y_pred).ravel().tolist()\n",
        "    if(len(cnmat)>2):\n",
        "            TN=cnmat[0]\n",
        "            FP=cnmat[1]\n",
        "            FN=cnmat[2]\n",
        "            TP=cnmat[3]\n",
        "            totalpos=(FN+TP)\n",
        "            totalneg=(FP+TN)\n",
        "\n",
        "            if(totalpos!=0):\n",
        "                FNR=(FN/totalpos)\n",
        "\n",
        "            if(totalneg!=0):\n",
        "                FPR=(FP/totalneg)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
        "    Auc=metrics.auc(fpr, tpr)\n",
        "\n",
        "    return matthews_corrcoef(y_test,y_pred),accuracy_score(y_test, y_pred),balanced_accuracy_score(y_test,y_pred),precision_score(y_test, y_pred, average='macro'),recall_score(y_test, y_pred, average='macro'),f1_score(y_test, y_pred, average='macro'),Auc,FPR,FNR\n",
        "\n",
        "def train(X_train,y_train,clf,clf_name,config,overall):\n",
        "        hypopt_trials = Trials()\n",
        "        global X\n",
        "        global y\n",
        "        X=X_train\n",
        "        y=y_train\n",
        "        best_params = fmin(obj_fnc, search_space(clf_name), algo=tpe.suggest, max_evals=50, trials= hypopt_trials,early_stop_fn=early_stop.no_progress_loss(5))\n",
        "        #print(hypopt_trials.best_trial['result']['loss'])\n",
        "        bestmodel = getBestModelfromTrials(hypopt_trials)\n",
        "        scores= getBestScoreMetricfromTrials(hypopt_trials)\n",
        "        overall.writerow([clf_name,best_params,(1-hypopt_trials.best_trial['result']['loss']),scores['test_accuracy'].mean(),scores['test_balanced_accuracy'].mean(),\n",
        "                 scores['test_precision'].mean(),scores['test_recall'].mean(),scores['test_f1'].mean(),scores['test_auc'].mean(),scores['test_FPR'].mean(),(1-scores['test_recall'].mean())])\n",
        "        return bestmodel\n",
        "#    classification(urllisttr,X_train_transformed,Y,config)\n",
        "\n",
        "def classification(X_train,y_train,X_test,y_test):\n",
        "\n",
        "    clf=models\n",
        "    #FoldDetails=open(Datapath+config+'//Results//K_foldResults.csv', 'w+' ,encoding='utf-8',newline='')\n",
        "    #details = csv.writer(FoldDetails)\n",
        "    #details.writerow(['Classifier','kfold','Accuracy','FscoreMacro','FscoreWeighted','recall_macro','preci_macro','FPR','FNR','AUC'])\n",
        "\n",
        "    for clf_name, clf in clf.items():\n",
        "        print(\"NOW training  \",clf_name)\n",
        "        Overall=open(Datapath+config+'_ValidationSummary786'+clf_name+'.csv','a+',encoding='utf-8',newline='')\n",
        "        overall=csv.writer(Overall)\n",
        "        overall.writerow(['Classifier','best_parameters','MCC','accuracy','bal_accu','precision','recall','f1','auc','fpr','fnr'])\n",
        "        bestmodel=train(X_train,y_train,clf,clf_name,config,overall)\n",
        "        print(clf_name,'   finished')\n",
        "        Overall.close()\n",
        "        pkl_filename = Datapath+config+clf_name+'models786.pkl'\n",
        "        with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(bestmodel, file)\n",
        "        file.close()\n",
        "        Overall1=open(Datapath+config+'_unseenDataSummary786'+clf_name+'.csv','a+',encoding='utf-8',newline='')\n",
        "        overall1=csv.writer(Overall1)\n",
        "        overall1.writerow(['Classifier','MCC','accuracy','bal_accu','precision','recall','f1','auc','fpr','fnr'])\n",
        "        result=evaluate(bestmodel, X_train, X_test, y_train, y_test)\n",
        "        row=[]\n",
        "        row.append(clf_name)\n",
        "        row.extend(result)\n",
        "        print(row)\n",
        "        overall1.writerow(row)\n",
        "        Overall1.close()\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.metrics import make_scorer,balanced_accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "def FPR(clf, X, y):\n",
        "     y_pred = clf.predict(X)\n",
        "     cm= confusion_matrix(y, y_pred)\n",
        "     tn= cm[0, 0]\n",
        "     fp=cm[0, 1]\n",
        "     fn=cm[1, 0]\n",
        "     tp= cm[1, 1]\n",
        "     totalpos=(fn+tp)\n",
        "     totalneg=(fp+tn)\n",
        "\n",
        "     return fp/totalneg\n",
        "\n",
        "def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)\n",
        "\n",
        "plt.rcParams.update({'figure.figsize': (12.0,12.0)})\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcx-BC3-sakN"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JPPoiW2sbDX"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx2MYxkN426t"
      },
      "source": [
        "#COMPARISON BENCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VyAtcmM2P8m"
      },
      "outputs": [],
      "source": [
        "def select_random_samples(df,sample_size):\n",
        "  if(sample_size<len(df)):\n",
        "          train_df, random_df = train_test_split(df, train_size=sample_size, stratify=df['label'], random_state=42)\n",
        "          train_df.reset_index(drop=True, inplace=True)\n",
        "  else:\n",
        "    train_df=df\n",
        "  return train_df\n",
        "def combine_df(df1,df2):\n",
        "   combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "   combined_df.reset_index(drop=True, inplace=True)\n",
        "   return combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kiRbojo0o7i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def benchmark(datasetname,modelname,sample_size=1000):\n",
        "   dataset = load_dataset(datasetname)\n",
        "   tr_dataset= pd.DataFrame(dataset['train'])\n",
        "   te_dataset= pd.DataFrame(dataset['test'])\n",
        "\n",
        "   clean_tr_dataset=select_random_samples(tr_dataset,sample_size)\n",
        "   clean_tr_dataset['type']='train'\n",
        "   clean_te_dataset=select_random_samples(te_dataset,sample_size)\n",
        "   clean_te_dataset['type']='test'\n",
        "   clean_dataset=combine_df(clean_tr_dataset,clean_te_dataset)\n",
        "   if(datasetname=='ag_news'):\n",
        "      datasetname='ag-news'\n",
        "   elif(datasetname=='yelp_polarity'):\n",
        "      datasetname='yelp'\n",
        "   attacks=['textbugger','textfooler','deepwordbug','pwws','bae','tf-adj','a2t']\n",
        "   attack_sample_size=int(len(clean_dataset)/len(attacks))\n",
        "   for attack in attacks:\n",
        "\n",
        "        if(attack=='textbugger'):\n",
        "            if('roberta' in modelname):\n",
        "              attack_dataset=get_AEs_Roberta(datasetname,modelname,attack,attack_sample_size)\n",
        "            else:\n",
        "              attack_dataset=get_AEs(datasetname,modelname,attack,attack_sample_size)\n",
        "\n",
        "        else:\n",
        "            if('roberta' in modelname):\n",
        "              attack_dataset=combine_df(attack_dataset,get_AEs_Roberta(datasetname,modelname,attack,attack_sample_size))\n",
        "            else:\n",
        "              attack_dataset=combine_df(attack_dataset,get_AEs(datasetname,modelname,attack,attack_sample_size))\n",
        "\n",
        "   adv_dataset=attack_dataset\n",
        "\n",
        "   return clean_dataset,adv_dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po7LYSqwdkFx"
      },
      "source": [
        "#BERT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVL0ibVgHdw9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "def load_model(modelname):\n",
        "  model = BertForSequenceClassification.from_pretrained(modelname).to(device)\n",
        "  tokenizer = BertTokenizer.from_pretrained(modelname,use_fast=True, add_prefix_space=True)\n",
        "  average_sentence_length=19\n",
        "  model.eval()\n",
        "  return model, tokenizer\n",
        "\n",
        "def clean(text):\n",
        "  text=text.lower()\n",
        "  text=text.replace('\\\\n','. ')\n",
        "  text=text.replace('...',' ')\n",
        "  text=text.replace('!!!','!')\n",
        "  CLEANR = re.compile('<.*?>')\n",
        "  text=re.sub(CLEANR,' ',text)\n",
        "  text = text.replace('<br>',' ')\n",
        "  text = text.replace('</br>',' ')\n",
        "  text = text.replace('/>',' ')\n",
        "  text=text.replace(\"n't\",\"not\")\n",
        "  text=text.replace(\"not\",\" not\")\n",
        "  text=re.sub(' +', ' ', text)\n",
        "  text=text.strip()\n",
        "  return text\n",
        "def get_tokens_to_word_map(words):\n",
        "  idx = 1\n",
        "  enc =[tokenizer.encode(x,add_special_tokens=False) for x in words]\n",
        "  desired_output = []\n",
        "  for token in enc:\n",
        "    tokenoutput = []\n",
        "    for ids in token:\n",
        "      tokenoutput.append(idx)\n",
        "      idx +=1\n",
        "    desired_output.append(tokenoutput)\n",
        "\n",
        " # print(words,' token map',desired_output)\n",
        "  return desired_output\n",
        "\n",
        "def map_token_attention_to_words(example,tokenattentions):\n",
        "  example_word_attention=[]\n",
        "  words_used=[]\n",
        "  words=clean_str(example).split(' ')\n",
        "  #print(words)\n",
        "  word_token_index_map=get_tokens_to_word_map(words)\n",
        "  flag=False\n",
        "  for wordid,items in enumerate(word_token_index_map):\n",
        "          if(flag==True or wordid>=512):\n",
        "            break\n",
        "          else:\n",
        "            wordattention=0\n",
        "            for tokenid in items:\n",
        "                if(tokenid>=512):\n",
        "                  flag=True\n",
        "                  break\n",
        "                else:\n",
        "                  #print(tokenid,' length of tokenattentions ', len(tokenattentions))\n",
        "                  #print('global tokens', tokens[tokenid+lowid-1],'local tokens', localtokens[tokenid])#,'attention', (localexpl[tokenid].item()))\n",
        "                  wordattention+=(tokenattentions[tokenid].item())\n",
        "\n",
        "            example_word_attention.append([words[wordid],wordattention])\n",
        "  return example_word_attention\n",
        "def getoutliersforanalysis(expl,words,N=10):\n",
        "\n",
        "   data=pd.DataFrame(expl)\n",
        "   outliers={}\n",
        "   word_freq=text_to_freq(words)\n",
        "   med=np.median(expl)\n",
        "   expl_med=np.absolute(expl-med)\n",
        "\n",
        "  # #  print(expl_med)\n",
        "   MAD=np.median(expl_med)*1.4826\n",
        "   q1, q3 = np.percentile(data, [25,50])\n",
        "   # compute IRQ\n",
        "   #print(q1,\" \",q3)\n",
        "   iqr = q3 - q1\n",
        "   lower_bound = q1 - (1.5* iqr)\n",
        "   upper_bound = q3 + (1.5 * iqr)\n",
        "\n",
        "   for i,att in enumerate(expl):\n",
        "       #print(words[i]z,\" --> \",att)\n",
        "       clean_to_infer=clean_str(words[i])\n",
        "\n",
        "\n",
        "       if(att>=upper_bound and len(clean_to_infer)>2 and clean_to_infer!='' and clean(words[i]) not in STOPWORDS):\n",
        "\n",
        "\n",
        "\n",
        "         outliers[words[i].lower()]=word_freq[i]\n",
        "      #  elif(words[i] not in string.punctuation):\n",
        "      #     priaznt(\"NOT OUTLIER \",words[i])\n",
        "\n",
        "\n",
        "   return outliers\n",
        "def eliminate_oov(text):\n",
        "  words=text.split(' ')\n",
        "  newsentence=''\n",
        "  for word in words:\n",
        "     if(word in word_frequency.keys()):\n",
        "          newsentence+=word+' '\n",
        "\n",
        "  return newsentence\n",
        "def get_word_attention(words,word_token_index_map,localexpl,tokens):\n",
        "  word_based_attention=[]\n",
        "  words_used=[]\n",
        "  #wordattend={}\n",
        "\n",
        "  for wordid,items in enumerate(word_token_index_map):\n",
        "\n",
        "                  localattention=0\n",
        "                  wordattention=0\n",
        "\n",
        "                  for tokenid in items:\n",
        "                        #print(tokenid)\n",
        "                        #print(tokens[tokenid])\n",
        "                        if(tokenid>=512 or tokenid>=len(localexpl)):\n",
        "                              return word_based_attention,words_used\n",
        "                        localattention+=localexpl[tokenid].item() #*frequencyofword\n",
        "\n",
        "                  if(len(items)>0):\n",
        "                        wordattention=localattention#/len(items)\n",
        "                  else:\n",
        "                        wordattention=localattention\n",
        "                  word_based_attention.append(wordattention)\n",
        "                  words_used.append(words[wordid])\n",
        "                  #wordattend[words[wordid]]=wordattention\n",
        "                  #print(wordattention,\"\\n########\")\n",
        "\n",
        "  return word_based_attention, words_used\n",
        "\n",
        "def get_explaination(text_batch,start=0):\n",
        "      #text_batch=clean(text_batch).strip()\n",
        "      encoding = tokenizer(text_batch,padding=True,truncation=True, return_tensors='pt')\n",
        "      input_ids = encoding['input_ids'].to(device)\n",
        "      attention_mask = encoding['attention_mask'].to(device)\n",
        "      expl,expl_grad = explanations786.generate_LRP(input_ids=input_ids, attention_mask=attention_mask, start_layer=start)\n",
        "\n",
        "      expl=expl[0]\n",
        "      expl_grad=expl_grad[0]\n",
        "      tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "      reconstructed=tokenizer.convert_tokens_to_string(tokens)\n",
        "      reconstructed=reconstructed.replace('[CLS]','')\n",
        "      reconstructed=reconstructed.replace('[SEP]','')\n",
        "      #reconstructed=reconstructed.replace('\"','')\n",
        "      #print(reconstructed)\n",
        "      words=wordpunct_tokenize(reconstructed)\n",
        "      word_token_index_map=get_tokens_to_word_map(words)\n",
        "\n",
        "      word_attentions,words_up=get_word_attention(words,word_token_index_map,expl,tokens)\n",
        "      #print(\"\\n\\nWORD\",[(words_up[i], word_attentions[i]) for i in range(len(words_up))])\n",
        "      return word_attentions,expl_grad,words_up\n",
        "def getoutliers_freq(words,thr=0.001,N=10):\n",
        "  outlier={}\n",
        "  data=pd.DataFrame(text_to_freq(words))\n",
        "  q1, q3 = np.percentile(data, [25,75])\n",
        "  iqr = q3 - q1\n",
        "  lower_bound = q1\n",
        "  #print(\"freq_lower_bound \",lower_bound)\n",
        "  for i,word in enumerate(words):\n",
        "\n",
        "           sub=clean_str(word)\n",
        "           if(sub in word_frequency and word_frequency[sub]<=thr and sub!='' and len(sub)>2):\n",
        "\n",
        "                      outlier[clean_str_wo_lemma(word)]=word_frequency[sub]\n",
        "           elif(sub not in word_frequency and word not in string.punctuation and sub!=''):\n",
        "                     #print(\"HEREE \",word)\n",
        "                     outlier[(word).lower()]=0\n",
        "  if(outlier!={}):\n",
        "         sorted_out=dict(sorted(outlier.items(), key=lambda x: x[1])[:N])\n",
        "\n",
        "  else:\n",
        "        sorted_out={}\n",
        "  return sorted_out\n",
        "def getoutliers(expl,words,N=15):\n",
        "\n",
        "   data=pd.DataFrame(expl)\n",
        "   outliers={}\n",
        "\n",
        "\n",
        "   q1, q3 = np.percentile(data, [25,75])\n",
        "   # compute IRQ\n",
        "   #print(q1,\" \",q3)\n",
        "   iqr = q3 - q1\n",
        "   lower_bound = q1 - (1.5* iqr)\n",
        "   upper_bound = q3#+ (1.5 * iqr)\n",
        "\n",
        "   for i,att in enumerate(expl):\n",
        "       #print(words[i]z,\" --> \",att)\n",
        "       clean_to_infer=clean_str(words[i])\n",
        "\n",
        "\n",
        "       if(att>=upper_bound and len(clean_to_infer)>2 and clean_to_infer!='' and clean(words[i]) not in STOPWORDS):\n",
        "\n",
        "\n",
        "\n",
        "         outliers[words[i].lower()]=(att)#/word_freq\n",
        "      #  elif(words[i] not in string.punctuation):\n",
        "      #     print(\"NOT OUTLIER \",words[i])\n",
        "\n",
        "   if(outliers!={}):\n",
        "         sorted_out=dict(sorted(outliers.items(), key=lambda x: x[1], reverse=True)[:N])\n",
        "\n",
        "   else:\n",
        "        sorted_out={}\n",
        "\n",
        "   freq_outliers=getoutliers_freq(words)\n",
        "   #print(freq_outliers)\n",
        "   final_outliers={**sorted_out,**freq_outliers}\n",
        "\n",
        "   outlierslist=(final_outliers.keys())\n",
        "\n",
        "   return outlierslist\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.stats import entropy\n",
        "!python -m pip install scipy\n",
        "from scipy import stats\n",
        "import statistics as st\n",
        "def peak_vals(expl,peaks):\n",
        "  peak_values=0\n",
        "  for p in peaks:\n",
        "      peak_values+=expl[p]\n",
        "  return peak_values\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.stats import entropy\n",
        "def get_stats(expl):\n",
        "  stats_features=[]\n",
        "  statistics_org=stats.describe(expl)\n",
        "    # Here you should fine tune parameters to get what you want\n",
        "  peaks = find_peaks(expl)\n",
        "  countofpeaks=len(peaks[0])\n",
        "\n",
        "  peaksvalue=peak_vals(expl,peaks[0])\n",
        "  entro=entropy(expl,base=2)\n",
        "  stats_features=[statistics_org.nobs,statistics_org.minmax[0],statistics_org.minmax[1],statistics_org.mean,median(expl),st.mode(expl),statistics_org.variance,np.std(expl),statistics_org.skewness,statistics_org.kurtosis,entro,np.mean(abs(np.gradient(expl))),peaksvalue]\n",
        "  return stats_features\n",
        "\n",
        "def text_to_freq(words):\n",
        "\n",
        "  word_freq_pair=[]\n",
        "  offset = 1e-50\n",
        "\n",
        "  for word in words:\n",
        "\n",
        "           sub=word.lower()\n",
        "           if(clean_str(sub) in word_frequency ):\n",
        "                      word_freq_pair.append(word_frequency[clean_str(sub)] )\n",
        "           else:\n",
        "                      word_freq_pair.append(0+offset)\n",
        "\n",
        "  return word_freq_pair\n",
        "\n",
        "def get_features_for_anomaly_detection(text,Adv_Label,Adv_PCS):\n",
        "    expl,expl_grad,words2=get_explaination(text)\n",
        "    expl=expl\n",
        "    expl_grad=np.array(expl_grad.cpu())\n",
        "    features=[]\n",
        "    try:\n",
        "        explain=get_stats(expl)\n",
        "        gradient=get_stats(expl_grad[1:])\n",
        "        outliers=getoutliersforanalysis(expl,words2)\n",
        "        freq_vector=list(outliers.values())#text_to_freq(outliers)\n",
        "        try:\n",
        "            if(outliers!={}):\n",
        "                  frequency_outlier=get_stats(freq_vector)\n",
        "            else:\n",
        "                  frequency_outlier=-1*np.ones(len(gradient))\n",
        "        except:\n",
        "                #print(freq_vector)\n",
        "                frequency_outlier=np.ones(len(gradient))*freq_vector[0]\n",
        "                frequency_outlier[0]=len(outliers)\n",
        "                #print(frequency_outlier)\n",
        "        frequency=text_to_freq(words2)\n",
        "        frequency_text=get_stats(frequency)\n",
        "\n",
        "        features.extend(explain)\n",
        "        features.extend(gradient)\n",
        "        features.extend(frequency_outlier)\n",
        "        features.extend(frequency_text)\n",
        "    except:\n",
        "      print(\"HERER\")\n",
        "      print(expl)\n",
        "      print(text)\n",
        "\n",
        "    return features\n",
        "def get_feature_names():\n",
        "    featurenames=[]\n",
        "    mainfeatures=['explain','gradient','freq_outlier','freq_text']\n",
        "    secondaryfeatures=['nobs','min','max','mean','median','mode','variance','std','skewness','kurtosis','entropy','gradient_mean','peaksvalue_sum']\n",
        "    for feat in mainfeatures:\n",
        "        for sec in secondaryfeatures:\n",
        "          featurenames.append(feat+'_'+sec)\n",
        "\n",
        "    return featurenames\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F7GoY20i-9Kr"
      },
      "outputs": [],
      "source": [
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/Dataset_Comparison'\n",
        "datasetnames=['imdb','yelp_polarity','sst2','ag_news']\n",
        "modelpath='textattack/bert-base-uncased-'\n",
        "for i,datasetname in enumerate(datasetnames):\n",
        "    if(datasetname=='ag_news'):\n",
        "        modelname=modelpath+'ag-news'\n",
        "    elif datasetname=='yelp_polarity':\n",
        "       modelname=modelpath+'yelp-polarity'\n",
        "    elif datasetname=='sst2':\n",
        "       modelname=modelpath+'SST-2'\n",
        "    else:\n",
        "       modelname=modelpath+datasetname\n",
        "    model,tokenizer=load_model(modelname)\n",
        "    clean_dataset, adv_dataset=benchmark(datasetname,modelname)\n",
        "    print(len(clean_dataset),\" \",len(adv_dataset))\n",
        "    clean_dataset.to_csv(savepath+datasetname+'_bert'+'_clean_data.csv', index=False)\n",
        "\n",
        "    adv_dataset.to_csv(savepath+datasetname+'_bert'+'_adv_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ_HCbxv8WWw"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAavfdo_Tcpn"
      },
      "source": [
        "##TRAINING FEATURE EXTRACTION TO TRAINING BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2FNGpIwJnm9"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, precision_recall_fscore_support, auc,f1_score,balanced_accuracy_score,roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "Datapath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "# Record the start time\n",
        "Overall_start_time = time.time()\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/Dataset_Comparison'\n",
        "editfeaturepath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "datasetnames=['imdb']\n",
        "#datasetnames=['imdb','yelp_polarity','sst2','ag_news\n",
        "modelpath='textattack/bert-base-uncased-'\n",
        "for i,datasetname in enumerate(datasetnames):\n",
        "    if(datasetname=='ag_news'):\n",
        "        modelname=modelpath+'ag-news'\n",
        "    elif datasetname=='yelp_polarity':\n",
        "       modelname=modelpath+'yelp-polarity'\n",
        "    elif datasetname=='sst2':\n",
        "       modelname=modelpath+'SST-2'\n",
        "    else:\n",
        "       modelname=modelpath+datasetname\n",
        "    model,tokenizer=load_model(modelname)\n",
        "    explanations786 = Generator786(model)\n",
        "    with open('/content/gdrive/My Drive/'+datasetname+'_word_label_freq_dict.pickle', 'rb') as f:\n",
        "        word_label_freq_dict=pickle.load(f)\n",
        "    with open('/content/gdrive/My Drive/'+datasetname+'_voca_freq.pickle', 'rb') as f:\n",
        "        word_frequency= pickle.load(f)\n",
        "    freq_thres=np.mean(np.array(list(word_frequency.values())))\n",
        "    freq_thres_median=np.median(np.array(list(word_frequency.values())))\n",
        "    print(\"freqthres \",freq_thres_median)\n",
        "    Result_File=editfeaturepath+'Features/Featureset'+datasetname+'_'+modelname.split('/')[1]+'_786.csv'\n",
        "    result=open(Result_File, 'w+' ,encoding='utf-8',newline='')\n",
        "    result_csv= csv.writer(result)\n",
        "    headerrow=[]\n",
        "    headerrow.extend(['text','attack','type','org_label','adv_label','pred_label'])\n",
        "    featurenames=get_feature_names()\n",
        "    headerrow.extend(featurenames)\n",
        "    headerrow.append('time_to_process')\n",
        "    print(\"total columns \",len(headerrow))\n",
        "    result_csv.writerow(headerrow)\n",
        "\n",
        "    clean_df=pd.read_csv(savepath+datasetname+'_bert'+'_clean_data.csv')\n",
        "    clean_df['attack']='No'\n",
        "\n",
        "    for i,row in clean_df.iterrows():\n",
        "\n",
        "              print(\"clean \",i, \" \",datasetname)\n",
        "              if(i%100==0):\n",
        "                result.close()\n",
        "                result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "                result_csv= csv.writer(result)\n",
        "              start_time = time.time()\n",
        "              resultrow=[]\n",
        "              if(datasetname=='sst2'):\n",
        "                  Adv=row['sentence']\n",
        "              else:\n",
        "                  Adv=row['text']\n",
        "              resultrow.append(Adv)\n",
        "              resultrow.append(row['attack'])\n",
        "              resultrow.append(row['type'])\n",
        "              resultrow.append(row['label'])\n",
        "              resultrow.append(0)\n",
        "              Adv_Label,Adv_PCS=get_label(Adv)\n",
        "              resultrow.append(Adv_Label)\n",
        "              features=get_features_for_anomaly_detection(Adv,Adv_Label,Adv_PCS)\n",
        "\n",
        "                          # Record the end time\n",
        "              end_time = time.time()\n",
        "\n",
        "              # Calculate the elapsed time\n",
        "              elapsed_time = end_time - start_time\n",
        "              formatted_time = \"{:.2f} seconds\".format(elapsed_time)\n",
        "\n",
        "              if features!=[]:\n",
        "                    resultrow.extend(features)\n",
        "                    resultrow.append(str(formatted_time))\n",
        "                    result_csv.writerow(resultrow)\n",
        "                    #print(\"total columns resultrow \",len(resultrow))\n",
        "\n",
        "    result.close()\n",
        "    # Result_File=editfeaturepath+'Features/compare_feature'+datasetname+'_'+modelname.split('/')[1]+'_786.csv'\n",
        "    # result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "    # result_csv= csv.writer(result)\n",
        "    # adv_df=pd.read_csv (savepath+datasetname+'_bert'+'_adv_data.csv')\n",
        "    # adv_df['type']='adversarial'\n",
        "    # for i,row in adv_df.iterrows():\n",
        "\n",
        "    #           print(\"adv \",i, \" \",datasetname)\n",
        "    #           if(i%100==0):\n",
        "    #             result.close()\n",
        "    #             result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "    #             result_csv= csv.writer(result)\n",
        "    #           start_time = time.time()\n",
        "    #           resultrow=[]\n",
        "    #           Adv=row['perturbed_text']\n",
        "    #           resultrow.append(Adv)\n",
        "    #           resultrow.append(row['attack'])\n",
        "    #           resultrow.append(row['type'])\n",
        "    #           resultrow.append(row['ground_truth_output'])\n",
        "    #           #'Adversarial Label'\n",
        "    #           resultrow.append(1)\n",
        "    #           Adv_Label=row['Adv_Label']\n",
        "    #           Adv_PCS=row['Adv_PCS']\n",
        "    #           resultrow.append(Adv_Label)\n",
        "    #           features=get_features_for_anomaly_detection(Adv,Adv_Label,Adv_PCS)\n",
        "\n",
        "    #           end_time = time.time()\n",
        "\n",
        "    #           # Calculate the elapsed time\n",
        "    #           elapsed_time = end_time - start_time\n",
        "    #           formatted_time = \"{:.2f} seconds\".format(elapsed_time)\n",
        "    #           if features!=[] and Adv_Label!=row['ground_truth_output']:\n",
        "    #                 resultrow.extend(features)\n",
        "    #                 resultrow.append(str(formatted_time))\n",
        "    #                 result_csv.writerow(resultrow)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # result.close()\n",
        "    # end_time = time.time()\n",
        "    # elapsed_time = end_time - Overall_start_time\n",
        "    # print(f\"Total Time to extract features : {elapsed_time:.2f} seconds\", \" for dataset \", datasetname)\n",
        "    # # config=datasetname+'_'+modelname.split('/')[1]\n",
        "    # # filename=Result_File#Datapath+'Features/Featureset'+datasetname+'_'+modelname.split('/')[1]+'_786.csv'\n",
        "    # test_AEs = pd.read_csv(filename)\n",
        "    # test_AEs=test_AEs.fillna(0)\n",
        "    # print(datasetname)\n",
        "    # print(test_AEs['time_to_process'])\n",
        "\n",
        "    # # Assuming 'test_AEs' is your DataFrame\n",
        "    # traindata = test_AEs.copy()  # Create a copy to avoid modifying the original DataFrame\n",
        "    # labels = traindata['adv_label']\n",
        "\n",
        "    # # Create a dictionary to map unique attack labels to numerical values\n",
        "    # unique_attack = {attack: index for index, attack in enumerate(set(traindata['attack']))}\n",
        "\n",
        "    # # Convert attack labels to numerical values\n",
        "    # attackvals = [unique_attack[attack] for attack in traindata['attack']]\n",
        "\n",
        "    # # Split the data into train and test sets\n",
        "    # traind, testd, y_train, y_test = train_test_split(traindata, labels, stratify=attackvals, test_size=0.2, random_state=42)\n",
        "\n",
        "    # # Drop unnecessary columns from the training data\n",
        "    # columns_to_drop = ['text','org_label', 'adv_label', 'attack', 'dataset_type', 'time_to_process']\n",
        "\n",
        "    # # List of specific attack types\n",
        "\n",
        "    #     # Create a mask to filter specific attack types\n",
        "    # mask = traind['attack'].isin(specific_attacks)\n",
        "\n",
        "    #     # Create separate dataframes for specific attacks and others\n",
        "    # traind = traind[mask]\n",
        "    # y_train = traind.apply(label_attack, axis=1)\n",
        "    # test_df = traind[~mask]\n",
        "    # print(\"Training Attacks \",set(traind['attack']))\n",
        "    # X_train = traind.drop(columns=columns_to_drop, axis=1)\n",
        "    # # traindata=clean_dataset(traindata)\n",
        "    # X_train = X_train.fillna(0)\n",
        "    # X_train = np.float32(X_train)\n",
        "    # X_train = np.nan_to_num(X_train, nan=-9999, posinf=33333333, neginf=33333333)\n",
        "    # testd = pd.concat([testd, test_df], axis=0, ignore_index=True)\n",
        "    # print(\"TEST Attacks \", set(testd['attack']))\n",
        "    # y_test=np.concatenate([y_test, np.ones(len(test_df))])\n",
        "    # X_test = testd.drop(columns=columns_to_drop, axis=1)\n",
        "    # X_test = np.float32(X_test)\n",
        "    # X_test = np.nan_to_num(X_test, nan=-9999, posinf=33333333, neginf=33333333)\n",
        "    # classification(X_train, y_train, X_test, y_test)\n",
        "    # model='bert'\n",
        "    # clf_name = 'lgbm'\n",
        "    # with open(Datapath+'Detectors/'+config+clf_name+'models786.pkl', 'rb') as f:\n",
        "    #         anomaly_detector = pickle.load(f)\n",
        "    # Adv_labels = []\n",
        "    # for t in list(testd['attack']):\n",
        "    #     Adv_labels.append(uniqueattack[t])\n",
        "    #     uniqueattack = dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "    #     for attack in uniqueattack.keys():\n",
        "\n",
        "    #             target = []\n",
        "    #             conf = []\n",
        "    #             X_Adv_attack = testd.loc[testd['attack'] == attack]\n",
        "\n",
        "    #             X_Adv_attack = X_Adv_attack.drop(\n",
        "    #                 ['attack', 'type', 'org_label'], axis=1)\n",
        "    #             # X_holdout=test_AEs[(test_AEs['type']=='test')&(test_AEs['attack']==attack)]\n",
        "    #             if(attack.upper() != 'NO'):\n",
        "    #                 X_Adv_Label = np.ones(len(X_Adv_attack))\n",
        "    #             else:\n",
        "    #                 X_Adv_Label = np.zeros(len(X_Adv_attack))\n",
        "    #             from sklearn.metrics import accuracy_score\n",
        "\n",
        "    #         # Assuming you have trained your model and obtained predictions\n",
        "    #             y_pred = anomaly_detector.predict(X_Adv_attack)\n",
        "    #             accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "    #             row = [specific_attacks,len(X_Adv_attack), attack.upper(),\n",
        "    #                     datasename.upper(), model.upper(), accuracy]\n",
        "    #             result_csv.writerow(row)\n",
        "    #             print(\"Attack: \", attack, \" accuracy \", accuracy)\n",
        "    # result.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWF9tiNd8sUF"
      },
      "source": [
        "Training the learners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRr6LyF_8abn"
      },
      "outputs": [],
      "source": [
        "# prompt: generate a comparison benchmarks\n",
        "\n",
        "\n",
        "def compare_benchmarks(model_name,train_dataset,dev_dataset,test_dataset,train_dataloader,dev_dataloader,test_dataloader,num_labels,device):\n",
        "\n",
        "  # Initialize the models\n",
        "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels=num_labels)\n",
        "  model = model.to(device)\n",
        "  model2 = BertForMaskedLM.from_pretrained(model_name,num_labels=num_labels)\n",
        "  model2 = model2.to(device)\n",
        "  model3 = Generator(model_name,num_labels=num_labels)\n",
        "  model3 = model3.to(device)\n",
        "  model4 = Generator3(model_name,num_labels=num_labels)\n",
        "  model4 = model4.to(device)\n",
        "  model5 = Generator786(model_name,num_labels=num_labels)\n",
        "  model5 = model5.to(device)\n",
        "\n",
        "  # Train the models\n",
        "  train(model,train_dataloader,device)\n",
        "  train(model2,train_dataloader,device)\n",
        "  train(model3,train_dataloader,device)\n",
        "  train(model4,train_dataloader,device)\n",
        "  train(model5,train_dataloader,device)\n",
        "\n",
        "  # Evaluate the models on the dev set\n",
        "  eval(model,dev_dataloader,device)\n",
        "  eval(model2,dev_dataloader,device)\n",
        "  eval(model3,dev_dataloader,device)\n",
        "  eval(model4,dev_dataloader,device)\n",
        "  eval(model5,dev_dataloader,device)\n",
        "\n",
        "  # Evaluate the models on the test set\n",
        "  eval(model,test_dataloader,device)\n",
        "  eval(model2,test_dataloader,device)\n",
        "  eval(model3,test_dataloader,device)\n",
        "  eval(model4,test_dataloader,device)\n",
        "  eval(model5,test_dataloader,device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJcnhhqRdrqT"
      },
      "source": [
        "#ROBERTA MODEL BENCHMARK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8xI1H7xjlAa"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from BERT_explainability.modules.BERT.ExplanationGeneratorRoberta import GeneratorRoberta786\n",
        "from BERT_explainability.modules.BERT.RobertaForSequenceClassification import RobertaForSequenceClassification\n",
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "#explanations786 = GeneratorRoberta786(model)\n",
        "def load_model(modelname):\n",
        "  model = RobertaForSequenceClassification.from_pretrained(modelname).to(device)\n",
        "  tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-large\")\n",
        "  average_sentence_length=19\n",
        "  model.eval()\n",
        "  return model, tokenizer\n",
        "\n",
        "def clean(text):\n",
        "  text=text.lower()\n",
        "  text=text.replace('\\\\n','. ')\n",
        "  text=text.replace('...',' ')\n",
        "  text=text.replace('!!!','!')\n",
        "  CLEANR = re.compile('<.*?>')\n",
        "  text=re.sub(CLEANR,' ',text)\n",
        "  text = text.replace('<br>',' ')\n",
        "  text = text.replace('</br>',' ')\n",
        "  text = text.replace('/>',' ')\n",
        "  text=text.replace(\"n't\",\"not\")\n",
        "  text=text.replace(\"not\",\" not\")\n",
        "  text=re.sub(' +', ' ', text)\n",
        "  text=text.strip()\n",
        "  return text\n",
        "\n",
        "\n",
        "def getoutliersforanalysis(expl,words,N=10):\n",
        "\n",
        "   data=pd.DataFrame(expl)\n",
        "   outliers={}\n",
        "   word_freq=text_to_freq(words)\n",
        "   med=np.median(expl)\n",
        "   expl_med=np.absolute(expl-med)\n",
        "\n",
        "  # #  print(expl_med)\n",
        "   MAD=np.median(expl_med)*1.4826\n",
        "   q1, q3 = np.percentile(data, [25,50])\n",
        "   # compute IRQ\n",
        "   #print(q1,\" \",q3)\n",
        "   iqr = q3 - q1\n",
        "   lower_bound = q1 - (1.5* iqr)\n",
        "   upper_bound = q3 + (1.5 * iqr)\n",
        "\n",
        "   for i,att in enumerate(expl):\n",
        "       #print(words[i]z,\" --> \",att)\n",
        "       clean_to_infer=clean_str(words[i])\n",
        "\n",
        "\n",
        "       if(att>=upper_bound and len(clean_to_infer)>2 and clean_to_infer!='' and clean(words[i]) not in STOPWORDS):\n",
        "\n",
        "\n",
        "\n",
        "         outliers[words[i].lower()]=word_freq[i]\n",
        "      #  elif(words[i] not in string.punctuation):\n",
        "      #     priaznt(\"NOT OUTLIER \",words[i])\n",
        "\n",
        "\n",
        "   return outliers\n",
        "def get_word_attention(words,word_token_index_map,localexpl,tokens):\n",
        "  word_based_attention=[]\n",
        "  words_used=[]\n",
        "  #wordattend={}\n",
        "\n",
        "  for wordid,items in enumerate(word_token_index_map):\n",
        "                  #print(wordid,' ',items)\n",
        "                  localattention=0\n",
        "                  wordattention=0\n",
        "                  if(type(items[0])==list):\n",
        "                     items=items[0]\n",
        "                  for tokenid in items:\n",
        "\n",
        "                        #print(tokens[tokenid])\n",
        "                        if(tokenid>=512 or tokenid>=len(localexpl)):\n",
        "                              return word_based_attention,words_used\n",
        "                        localattention+=localexpl[tokenid].item() #*frequencyofword\n",
        "                        #print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "                        #print(words[wordid],\" \",tokens[tokenid], \" \",localexpl[tokenid].item())\n",
        "                  if(len(items)>0):\n",
        "                        wordattention=localattention#/len(items)\n",
        "                  else:\n",
        "                        wordattention=localattention\n",
        "                  word_based_attention.append(wordattention)\n",
        "                  words_used.append(words[wordid])\n",
        "                  #wordattend[words[wordid]]=wordattention\n",
        "                  #print(words[wordid],\"  \", wordattention,\"\\n########\")\n",
        "\n",
        "  return word_based_attention, words_used\n",
        "def get_tokens_to_word_map(text):\n",
        "  encoded = tokenizer(text,padding=True,truncation=True, return_tensors='pt')\n",
        "\n",
        "  # Check the full mapping token -> word:\n",
        "\n",
        "  ## [None, 0, 1, 2, 3, 3, 4, None]\n",
        "  #[None, 0, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, None]\n",
        "  #[0,1,2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "  # Build your desired mapping\n",
        "  words={}\n",
        "  token_id=0\n",
        "  desired_output = []\n",
        "  tokenoutput={}\n",
        "  tokens=list(encoded.tokens())\n",
        "  for word_id in encoded.words():\n",
        "\n",
        "      if word_id is not None:\n",
        "        if(tokens[token_id]!='Ġ'):\n",
        "\n",
        "          if (word_id not in tokenoutput.keys()):\n",
        "                tokenoutput[word_id]=[token_id]\n",
        "                words[word_id]=re.sub('Ġ','',tokens[token_id])\n",
        "          else:\n",
        "\n",
        "                tokenoutput[word_id].append(token_id)\n",
        "                words[word_id]+=re.sub('Ġ','',tokens[token_id])\n",
        "\n",
        "\n",
        "      token_id+=1\n",
        "\n",
        "  desired_output.extend(list(tokenoutput.values()))\n",
        "\n",
        "  return desired_output,words\n",
        "\n",
        "def get_tokens_to_word_map1(words):\n",
        "  idx = 1\n",
        "  enc =[]\n",
        "  for x in words:\n",
        "    wordtotoken=tokenizer.encode(x,add_special_tokens=False)\n",
        "    enc.append(wordtotoken)\n",
        "\n",
        "  desired_output = []\n",
        "  for token in enc:\n",
        "    tokenoutput = []\n",
        "    for ids in token:\n",
        "      tokenoutput.append(idx)\n",
        "      idx +=1\n",
        "    desired_output.append(tokenoutput)\n",
        "  #print(\"MAPPING         \")\n",
        "\n",
        "  return desired_output\n",
        "\n",
        "def map_token_attention_to_words(example,tokenattentions):\n",
        "  example_word_attention=[]\n",
        "  words_used=[]\n",
        "  words=clean_str(example).split(' ')\n",
        "  #print(words)\n",
        "  word_token_index_map=get_tokens_to_word_map(words)\n",
        "  flag=False\n",
        "  for wordid,items in enumerate(word_token_index_map):\n",
        "          if(flag==True or wordid>=512):\n",
        "            break\n",
        "          else:\n",
        "            wordattention=0\n",
        "            for tokenid in items:\n",
        "                if(tokenid>=512):\n",
        "                  flag=True\n",
        "                  break\n",
        "                else:\n",
        "                  #print(tokenid,' length of tokenattentions ', len(tokenattentions))\n",
        "                  #print('global tokens', tokens[tokenid+lowid-1],'local tokens', localtokens[tokenid])#,'attention', (localexpl[tokenid].item()))\n",
        "                  wordattention+=(tokenattentions[tokenid].item())\n",
        "\n",
        "            example_word_attention.append([words[wordid],wordattention])\n",
        "  return example_word_attention\n",
        "\n",
        "def eliminate_oov(text):\n",
        "  words=text.split(' ')\n",
        "  newsentence=''\n",
        "  for word in words:\n",
        "     if(word in word_frequency.keys()):\n",
        "          newsentence+=word+' '\n",
        "\n",
        "  return newsentence\n",
        "\n",
        "def tokens_to_words(tokens):\n",
        "  pretok_sent = \"\"\n",
        "  for tok in tokens:\n",
        "    if(tok!='[CLS]' and tok!='[SEP]'):\n",
        "     if tok.startswith(\"##\"):\n",
        "         pretok_sent += tok[2:]\n",
        "     else:\n",
        "         pretok_sent += \" \" + tok\n",
        "  pretok_sent = pretok_sent[1:]\n",
        "  return word_tokenize(pretok_sent)\n",
        "def get_explaination(text_batch):\n",
        "      #text_batch=clean(text_batch).strip()\n",
        "      encoding = tokenizer(text_batch,padding=True,truncation=True, return_tensors='pt')\n",
        "      input_ids = encoding['input_ids'].to(device)\n",
        "      attention_mask = encoding['attention_mask'].to(device)\n",
        "      expl,expl_grad = explanations786.generate_LRP(input_ids=input_ids, attention_mask=attention_mask, start_layer=0)\n",
        "      #print(len(expl))\n",
        "      expl=expl[0]\n",
        "      expl_grad=expl_grad[0]\n",
        "      #expl = (expl - expl.min()) / (expl.max() - expl.min())\n",
        "\n",
        "\n",
        "      tokens = tokenizer.convert_ids_to_tokens(input_ids.flatten())\n",
        "      # reconstructed=tokenizer.convert_tokens_to_string(tokens)\n",
        "      # reconstructed=reconstructed.replace('<s>','')\n",
        "      # reconstructed=reconstructed.replace('</s>','')\n",
        "      # reconstructed=reconstructed.replace('<pad>','')\n",
        "\n",
        "      # #reconstructed=reconstructed.replace('\"','')\n",
        "      # #print(reconstructed)\n",
        "      # words=word_tokenize(reconstructed)\n",
        "\n",
        "      word_token_index_map,words_dict=get_tokens_to_word_map(text_batch)\n",
        "      #print(len(word_token_index_map))\n",
        "      words=list(words_dict.values())\n",
        "      #print([(tokens[i], expl[i].item()) for i in range(len(tokens))])\n",
        "      word_attentions,words_up=get_word_attention(words,word_token_index_map,expl,tokens)\n",
        "      #print(\"\\n\\nWORD\",[(words_up[i], word_attentions[i]) for i in range(len(words_up))])\n",
        "      return word_attentions,expl_grad,words_up\n",
        "\n",
        "def getoutliers_freq(words,thr=0.001,N=10):\n",
        "  outlier={}\n",
        "  data=pd.DataFrame(text_to_freq(words))\n",
        "  q1, q3 = np.percentile(data, [25,75])\n",
        "  iqr = q3 - q1\n",
        "  lower_bound = q1\n",
        "  #print(\"freq_lower_bound \",lower_bound)\n",
        "  for i,word in enumerate(words):\n",
        "\n",
        "           sub=clean_str(word)\n",
        "           if(sub in word_frequency and word_frequency[sub]<=thr and sub!='' and len(sub)>2):\n",
        "\n",
        "                      outlier[clean_str_wo_lemma(word)]=word_frequency[sub]\n",
        "           elif(sub not in word_frequency and word not in string.punctuation and sub!=''):\n",
        "                     #print(\"HEREE \",word)\n",
        "                     outlier[(word).lower()]=0\n",
        "  if(outlier!={}):\n",
        "         sorted_out=dict(sorted(outlier.items(), key=lambda x: x[1])[:N])\n",
        "\n",
        "  else:\n",
        "        sorted_out={}\n",
        "  return sorted_out\n",
        "def getoutliers(expl,words,N=15):\n",
        "\n",
        "   data=pd.DataFrame(expl)\n",
        "   outliers={}\n",
        "\n",
        "\n",
        "   q1, q3 = np.percentile(data, [25,75])\n",
        "   # compute IRQ\n",
        "   #print(q1,\" \",q3)\n",
        "   iqr = q3 - q1\n",
        "   lower_bound = q1 - (1.5* iqr)\n",
        "   upper_bound = q3#+ (1.5 * iqr)\n",
        "\n",
        "   for i,att in enumerate(expl):\n",
        "       #print(words[i]z,\" --> \",att)\n",
        "       clean_to_infer=clean_str(words[i])\n",
        "\n",
        "\n",
        "       if(att>=upper_bound and len(clean_to_infer)>2 and clean_to_infer!='' and clean(words[i]) not in STOPWORDS):\n",
        "\n",
        "\n",
        "\n",
        "         outliers[words[i].lower()]=(att)#/word_freq\n",
        "      #  elif(words[i] not in string.punctuation):\n",
        "      #     print(\"NOT OUTLIER \",words[i])\n",
        "\n",
        "   if(outliers!={}):\n",
        "         sorted_out=dict(sorted(outliers.items(), key=lambda x: x[1], reverse=True)[:N])\n",
        "\n",
        "   else:\n",
        "        sorted_out={}\n",
        "\n",
        "   freq_outliers=getoutliers_freq(words)\n",
        "   #print(freq_outliers)\n",
        "   final_outliers={**sorted_out,**freq_outliers}\n",
        "\n",
        "   outlierslist=(final_outliers.keys())\n",
        "\n",
        "   return outlierslist\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.stats import entropy\n",
        "!python -m pip install scipy\n",
        "from scipy import stats\n",
        "import statistics as st\n",
        "def peak_vals(expl,peaks):\n",
        "  peak_values=0\n",
        "  for p in peaks:\n",
        "      peak_values+=expl[p]\n",
        "  return peak_values\n",
        "\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.stats import entropy\n",
        "def get_stats(expl):\n",
        "  stats_features=[]\n",
        "  statistics_org=stats.describe(expl)\n",
        "    # Here you should fine tune parameters to get what you want\n",
        "  peaks = find_peaks(expl)\n",
        "  countofpeaks=len(peaks[0])\n",
        "\n",
        "  peaksvalue=peak_vals(expl,peaks[0])\n",
        "  entro=entropy(expl,base=2)\n",
        "  stats_features=[statistics_org.nobs,statistics_org.minmax[0],statistics_org.minmax[1],statistics_org.mean,median(expl),st.mode(expl),statistics_org.variance,np.std(expl),statistics_org.skewness,statistics_org.kurtosis,entro,np.mean(abs(np.gradient(expl))),peaksvalue]\n",
        "  return stats_features\n",
        "\n",
        "def text_to_freq(words):\n",
        "\n",
        "  word_freq_pair=[]\n",
        "  offset = 1e-50\n",
        "\n",
        "  for word in words:\n",
        "\n",
        "           sub=word.lower()\n",
        "           if(clean_str(sub) in word_frequency ):\n",
        "                      word_freq_pair.append(word_frequency[clean_str(sub)] )\n",
        "           else:\n",
        "                      word_freq_pair.append(0+offset)\n",
        "\n",
        "  return word_freq_pair\n",
        "\n",
        "def get_features_for_anomaly_detection(text,Adv_Label,Adv_PCS):\n",
        "    expl,expl_grad,words2=get_explaination(text)\n",
        "    expl=expl\n",
        "    expl_grad=np.array(expl_grad.cpu())\n",
        "    features=[]\n",
        "    try:\n",
        "        explain=get_stats(expl)\n",
        "        gradient=get_stats(expl_grad[1:])\n",
        "        outliers=getoutliersforanalysis(expl,words2)\n",
        "        freq_vector=list(outliers.values())#text_to_freq(outliers)\n",
        "        try:\n",
        "            if(outliers!={}):\n",
        "                  frequency_outlier=get_stats(freq_vector)\n",
        "            else:\n",
        "                  frequency_outlier=-1*np.ones(len(gradient))\n",
        "        except:\n",
        "                #print(freq_vector)\n",
        "                frequency_outlier=np.ones(len(gradient))*freq_vector[0]\n",
        "                frequency_outlier[0]=len(outliers)\n",
        "                #print(frequency_outlier)\n",
        "        frequency=text_to_freq(words2)\n",
        "        frequency_text=get_stats(frequency)\n",
        "\n",
        "        features.extend(explain)\n",
        "        features.extend(gradient)\n",
        "        features.extend(frequency_outlier)\n",
        "        features.extend(frequency_text)\n",
        "    except:\n",
        "      print(\"HERER\")\n",
        "      print(expl)\n",
        "      print(text)\n",
        "\n",
        "    return features\n",
        "def get_feature_names():\n",
        "    featurenames=[]\n",
        "    mainfeatures=['explain','gradient','freq_outlier','freq_text']\n",
        "    secondaryfeatures=['nobs','min','max','mean','median','mode','variance','std','skewness','kurtosis','entropy','gradient_mean','peaksvalue_sum']\n",
        "    for feat in mainfeatures:\n",
        "        for sec in secondaryfeatures:\n",
        "          featurenames.append(feat+'_'+sec)\n",
        "\n",
        "    return featurenames\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DbrEnmDdqxi"
      },
      "outputs": [],
      "source": [
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/Dataset_Comparison'\n",
        "datasetnames=['imdb','yelp_polarity','sst2','ag_news']\n",
        "modelpath='textattack/roberta-base-'\n",
        "for i,datasetname in enumerate(datasetnames):\n",
        "    if(datasetname=='ag_news'):\n",
        "        modelname=modelpath+'ag-news'\n",
        "    elif datasetname=='yelp_polarity':\n",
        "       modelname='VictorSanh/roberta-base-finetuned-'+'yelp-polarity'\n",
        "    elif datasetname=='sst2':\n",
        "       modelname=modelpath+'SST-2'\n",
        "    else:\n",
        "       modelname=modelpath+datasetname\n",
        "    model,tokenizer=load_model(modelname)\n",
        "    clean_dataset, adv_dataset=benchmark(datasetname,modelname,sample_size=500)\n",
        "    print(len(clean_dataset),\" \",len(adv_dataset))\n",
        "    clean_dataset.to_csv(savepath+datasetname+'_roberta'+'_clean_data.csv', index=False)\n",
        "\n",
        "    adv_dataset.to_csv(savepath+datasetname+'_roberta'+'_adv_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bpci3kPo8wt"
      },
      "outputs": [],
      "source": [
        "# Suppress specific warning messages\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning,\n",
        "                        message=\".*No further splits with positive gain.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning,\n",
        "                        message=\".*Stopped training because there are no more leaves that meet the split requirements.*\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l24inrClCwI"
      },
      "source": [
        "##FEATURE EXTRACTION< BUILD MODEL ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHHsbBKhZawZ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, precision_recall_fscore_support, auc,f1_score,balanced_accuracy_score,roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Datapath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "# Record the start time\n",
        "Overall_start_time = time.time()\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/Dataset_Comparison'\n",
        "editfeaturepath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "datasetnames=['imdb','yelp_polarity','sst2','ag_news']\n",
        "modelpath='textattack/roberta-base-'\n",
        "for i,datasetname in enumerate(datasetnames):\n",
        "    if(datasetname=='ag_news'):\n",
        "        modelname=modelpath+'ag-news'\n",
        "    elif datasetname=='yelp_polarity':\n",
        "       modelname='VictorSanh/roberta-base-finetuned-'+'yelp-polarity'\n",
        "    elif datasetname=='sst2':\n",
        "       modelname=modelpath+'SST-2'\n",
        "    else:\n",
        "       modelname=modelpath+datasetname\n",
        "    model,tokenizer=load_model(modelname)\n",
        "    explanations786 = GeneratorRoberta786(model)\n",
        "    with open('/content/gdrive/My Drive/'+datasetname+'_word_label_freq_dict.pickle', 'rb') as f:\n",
        "        word_label_freq_dict=pickle.load(f)\n",
        "    with open('/content/gdrive/My Drive/'+datasetname+'_voca_freq.pickle', 'rb') as f:\n",
        "        word_frequency= pickle.load(f)\n",
        "    freq_thres=np.mean(np.array(list(word_frequency.values())))\n",
        "    freq_thres_median=np.median(np.array(list(word_frequency.values())))\n",
        "    print(\"freqthres \",freq_thres_median)\n",
        "\n",
        "    Result_File=editfeaturepath+'Features/Featureset'+datasetname+'_'+modelname.split('/')[1]+'_786.csv'\n",
        "    result=open(Result_File, 'w+' ,encoding='utf-8',newline='')\n",
        "    result_csv= csv.writer(result)\n",
        "    headerrow=[]\n",
        "    headerrow.extend(['text','attack','dataset_type','org_label','adv_label','pred_label'])\n",
        "    featurenames=get_feature_names()\n",
        "    headerrow.extend(featurenames)\n",
        "    headerrow.append('time_to_process')\n",
        "    print(\"total columns \",len(headerrow))\n",
        "    result_csv.writerow(headerrow)\n",
        "    #CLEAN DATA\n",
        "    clean_df=pd.read_csv(savepath+datasetname+'_roberta'+'_clean_data.csv')\n",
        "    print(len(clean_df))\n",
        "    clean_df['attack']='No'\n",
        "    for i,row in clean_df.iterrows():\n",
        "\n",
        "            print(\"clean \",i, \" \",datasetname)\n",
        "            start_time = time.time()\n",
        "            resultrow=[]\n",
        "            if(datasetname=='sst2'):\n",
        "                Adv=row['sentence']\n",
        "            else:\n",
        "                Adv=row['text']\n",
        "            resultrow.append(Adv)\n",
        "            resultrow.append(row['attack'])\n",
        "            resultrow.append(row['type'])\n",
        "            resultrow.append(row['label'])\n",
        "            resultrow.append(0)\n",
        "            Adv_Label,Adv_PCS=get_label(Adv)\n",
        "            resultrow.append(Adv_Label)\n",
        "            features=get_features_for_anomaly_detection(Adv,Adv_Label,Adv_PCS)\n",
        "\n",
        "                        # Record the end time\n",
        "            end_time = time.time()\n",
        "\n",
        "            # Calculate the elapsed time\n",
        "            elapsed_time = end_time - start_time\n",
        "            formatted_time = \"{:.2f} seconds\".format(elapsed_time)\n",
        "\n",
        "            if features!=[]:\n",
        "                  resultrow.extend(features)\n",
        "                  resultrow.append(str(formatted_time))\n",
        "                  result_csv.writerow(resultrow)\n",
        "                  print(\"total columns resultrow \",len(resultrow))\n",
        "\n",
        "\n",
        "    #ADVERSARIAL\n",
        "    adv_df=pd.read_csv (savepath+datasetname+'_roberta'+'_adv_data.csv')\n",
        "    print(len(adv_df))\n",
        "    adv_df['type']='adversarial'\n",
        "    for i,row in adv_df.iterrows():\n",
        "              print(\"adv \",i, \" \",datasetname)\n",
        "              start_time = time.time()\n",
        "              resultrow=[]\n",
        "              Adv=row['perturbed_text']\n",
        "              resultrow.append(Adv)\n",
        "              resultrow.append(row['attack'])\n",
        "              resultrow.append(row['type'])\n",
        "              resultrow.append(row['ground_truth_output'])\n",
        "              #'Adversarial Label'\n",
        "              resultrow.append(1)\n",
        "              Adv_Label=row['Adv_Label']\n",
        "              Adv_PCS=row['Adv_PCS']\n",
        "              resultrow.append(Adv_Label)\n",
        "              features=get_features_for_anomaly_detection(Adv,Adv_Label,Adv_PCS)\n",
        "\n",
        "              end_time = time.time()\n",
        "\n",
        "              # Calculate the elapsed time\n",
        "              elapsed_time = end_time - start_time\n",
        "              formatted_time = \"{:.2f} seconds\".format(elapsed_time)\n",
        "              if features!=[]:\n",
        "                    resultrow.extend(features)\n",
        "                    resultrow.append(str(formatted_time))\n",
        "                    result_csv.writerow(resultrow)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    result.close()\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - Overall_start_time\n",
        "    print(f\"Total Time to extract features : {elapsed_time:.2f} seconds\", \" for dataset \", datasetname)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLMynv2v8Fpm"
      },
      "outputs": [],
      "source": [
        "classification(X_train,y_train,X_test,y_test)\n",
        "model='roberta'\n",
        "Result_File=Datapath+'Supervised_DetectorResult_Attack_wise_Roberta.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "    #result_csv.writerow(['sample_size','attack','dataset','model','accuracy'])\n",
        "clf_name='lgbm'\n",
        "with open(Datapath+config+clf_name+'models786.pkl', 'rb') as f:\n",
        "        anomaly_detector=pickle.load(f)\n",
        "        Adv_labels=[]\n",
        "        uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "        for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=columns_to_drop, axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = anomaly_detector.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),model.upper(),accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lUBN08K4cuE"
      },
      "source": [
        "##ROBERTA YELP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkxhBRzEXvRK"
      },
      "outputs": [],
      "source": [
        "editfeaturepath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "Datapath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "datasetname='yelp_polarity'\n",
        "modelname='VictorSanh/roberta-base-finetuned-'+'yelp-polarity'\n",
        "Result_File=editfeaturepath+'Features/Featureset'+datasetname+'_'+modelname.split('/')[1]+'_786.csv'\n",
        "config=datasetname+'_'+modelname.split('/')[1]\n",
        "filename=Result_File#Datapath+'_Featureset'+datasetname+'_'+modelname.split('/')[1]+'_786.csv'\n",
        "test_AEs = pd.read_csv(filename)\n",
        "test_AEs=test_AEs.fillna(0)\n",
        "print(datasetname)\n",
        "print(test_AEs['time_to_process'])\n",
        "\n",
        "    # Assuming 'test_AEs' is your DataFrame\n",
        "traindata = test_AEs.copy()  # Create a copy to avoid modifying the original DataFrame\n",
        "labels = traindata['adv_label']\n",
        "\n",
        "    # Create a dictionary to map unique attack labels to numerical values\n",
        "unique_attack = {attack: index for index, attack in enumerate(set(traindata['attack']))}\n",
        "\n",
        "    # Convert attack labels to numerical values\n",
        "attackvals = [unique_attack[attack] for attack in traindata['attack']]\n",
        "\n",
        "    # Split the data into train and test sets\n",
        "traind, testd, y_train, y_test = train_test_split(traindata, labels, stratify=attackvals, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Drop unnecessary columns from the training data\n",
        "columns_to_drop = ['text','org_label', 'adv_label', 'attack', 'dataset_type', 'time_to_process']\n",
        "X_train = traind.drop(columns=columns_to_drop, axis=1)\n",
        "print(X_train.columns)\n",
        "X_train=X_train.fillna(0)\n",
        "\n",
        "X_train=np.nan_to_num(X_train, nan=-9999, posinf=33333333, neginf=33333333)\n",
        "X_test=testd.drop(columns=columns_to_drop,axis=1)\n",
        "\n",
        "X_test=np.nan_to_num(X_test, nan=-9999, posinf=33333333, neginf=33333333)\n",
        "classification(X_train,y_train,X_test,y_test)\n",
        "model='roberta'\n",
        "Result_File=Datapath+'Supervised_DetectorResult_Attack_wise_Roberta.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "    #result_csv.writerow(['sample_size','attack','dataset','model','accuracy'])\n",
        "clf_name='lgbm'\n",
        "with open(Datapath+config+clf_name+'models786.pkl', 'rb') as f:\n",
        "        anomaly_detector=pickle.load(f)\n",
        "        Adv_labels=[]\n",
        "        uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "        for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=columns_to_drop, axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = anomaly_detector.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),model.upper(),accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzkfaNlm4gfr"
      },
      "source": [
        "##ROBERTA IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0yFppR618qZ"
      },
      "outputs": [],
      "source": [
        "editfeaturepath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "Datapath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "datasetname='imdb'\n",
        "modelname='textattack/roberta-base-'+datasetname\n",
        "Result_File=editfeaturepath+'Features/Featureset'+datasetname+'_'+modelname.split('/')[1]+'_786.csv'\n",
        "config=datasetname+'_'+modelname.split('/')[1]\n",
        "filename=Result_File#Datapath+'_Featureset'+datasetname+'_'+modelname.split('/')[1]+'_786.csv'\n",
        "test_AEs = pd.read_csv(filename)\n",
        "test_AEs=test_AEs.fillna(0)\n",
        "print(datasetname)\n",
        "print(test_AEs['time_to_process'])\n",
        "\n",
        "    # Assuming 'test_AEs' is your DataFrame\n",
        "traindata = test_AEs.copy()  # Create a copy to avoid modifying the original DataFrame\n",
        "labels = traindata['adv_label']\n",
        "\n",
        "    # Create a dictionary to map unique attack labels to numerical values\n",
        "unique_attack = {attack: index for index, attack in enumerate(set(traindata['attack']))}\n",
        "\n",
        "    # Convert attack labels to numerical values\n",
        "attackvals = [unique_attack[attack] for attack in traindata['attack']]\n",
        "\n",
        "    # Split the data into train and test sets\n",
        "traind, testd, y_train, y_test = train_test_split(traindata, labels, stratify=attackvals, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Drop unnecessary columns from the training data\n",
        "columns_to_drop = ['text','org_label', 'adv_label', 'attack', 'dataset_type', 'time_to_process']\n",
        "X_train = traind.drop(columns=columns_to_drop, axis=1)\n",
        "print(X_train.columns)\n",
        "X_train=X_train.fillna(0)\n",
        "\n",
        "X_train=np.nan_to_num(X_train, nan=-9999, posinf=33333333, neginf=33333333)\n",
        "X_test=testd.drop(columns=columns_to_drop,axis=1)\n",
        "\n",
        "X_test=np.nan_to_num(X_test, nan=-9999, posinf=33333333, neginf=33333333)\n",
        "classification(X_train,y_train,X_test,y_test)\n",
        "model='roberta'\n",
        "Result_File=Datapath+'Supervised_DetectorResult_Attack_wise_Roberta.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "    #result_csv.writerow(['sample_size','attack','dataset','model','accuracy'])\n",
        "clf_name='lgbm'\n",
        "with open(Datapath+config+clf_name+'models786.pkl', 'rb') as f:\n",
        "        anomaly_detector=pickle.load(f)\n",
        "        Adv_labels=[]\n",
        "        uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "        for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=columns_to_drop, axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = anomaly_detector.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),model.upper(),accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMU3jw79JRAr"
      },
      "source": [
        "#RDE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbqtH6J9WWgy"
      },
      "source": [
        "##Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MShH_3SXJR0X"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/bangawayoo/adversarial-examples-in-text-classification.git '/content/gdrive/My Drive/RDE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SimVPlYMN_7"
      },
      "outputs": [],
      "source": [
        "%cd '/content/gdrive/My Drive/RDE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyiNW5XtMXHw"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# Load environment.yaml\n",
        "with open('environment.yaml', 'r') as yaml_file:\n",
        "    yaml_data = yaml.safe_load(yaml_file)\n",
        "\n",
        "# Extract dependencies and pip dependencies\n",
        "dependencies = yaml_data.get('dependencies', [])\n",
        "pip_dependencies = []\n",
        "for item in dependencies:\n",
        "\n",
        "    if isinstance(item, dict) and 'pip' in item:\n",
        "        print(item)\n",
        "        pip_dependencies.extend(item['pip'])\n",
        "\n",
        "# Write to requirements.txt\n",
        "with open('requirements.txt', 'w') as req_file:\n",
        "    for dependency in pip_dependencies:\n",
        "        req_file.write(dependency + '\\n')\n",
        "\n",
        "print(\"Conversion completed: environment.yaml -> requirements.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZH1D5TINUuT"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyoltUdHlNeg"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFV5XgzCOupU"
      },
      "outputs": [],
      "source": [
        "%cd '/content/gdrive/My Drive/RDE/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCEfxuS3M-8y"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uqltmw_WJJn"
      },
      "source": [
        "##BERT IMBD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwblYddgKBgV"
      },
      "outputs": [],
      "source": [
        "%cd '/content/gdrive/My Drive/RDE'\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import pdb\n",
        "import glob\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define input variables\n",
        "dataset = \"imdb\"\n",
        "preprocess = \"standard\"\n",
        "data_type = \"standard\"\n",
        "target_model = \"textattack/bert-base-uncased-imdb\"\n",
        "model_type = None  # Fill in the desired value\n",
        "use_state_dict = False\n",
        "data_root_dir = 'attack-log/original'\n",
        "scenario = None  # Fill in the desired value\n",
        "include_fae = False\n",
        "unbalanced = False\n",
        "use_val = False\n",
        "cov_estimator = None  # Fill in the desired value\n",
        "pkl_test_path = \" \"\n",
        "pkl_val_path = \" \"\n",
        "attack_type = 'textfooler'\n",
        "exp_name = 'tmp'\n",
        "fpr_threshold = 0.10\n",
        "compute_bootstrap = False\n",
        "baseline = False\n",
        "visualize = False\n",
        "tune_params = False\n",
        "model_params_path = \"params/attention_key-exclude.json\"\n",
        "PCA_dim = None\n",
        "MCD_h = None\n",
        "ensemble = False\n",
        "adapt_ckpt = None\n",
        "gpu = '0'\n",
        "start_seed = 0\n",
        "end_seed = 0\n",
        "mnli_option = \"matched\"\n",
        "\n",
        "# Import libraries and modules\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "\n",
        "\n",
        "model_type = target_model.replace(\"/\", \"-\")\n",
        "if exp_name:\n",
        "    log_path = f\"runs/{dataset}/{exp_name}/{model_type}/{attack_type}\"\n",
        "else:\n",
        "    log_path = f\"runs/{dataset}/{model_type}/{attack_type}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.isdir(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "\n",
        "\n",
        "input_variables = {\n",
        "    \"dataset\": \"imdb\",\n",
        "    \"preprocess\": \"standard\",\n",
        "    \"data_type\": \"standard\",\n",
        "    \"target_model\": \"textattack/bert-base-uncased-imdb\",\n",
        "    \"model_type\": None,  # Fill in the desired value\n",
        "    \"use_state_dict\": False,\n",
        "    \"data_root_dir\": 'attack-log/original',\n",
        "    \"scenario\": None,  # Fill in the desired value\n",
        "    \"include_fae\": False,\n",
        "    \"unbalanced\": False,\n",
        "    \"use_val\": False,\n",
        "    \"cov_estimator\": None,  # Fill in the desired value\n",
        "    \"pkl_test_path\": \" \",\n",
        "    \"pkl_val_path\": \" \",\n",
        "    \"attack_type\": 'textfooler',\n",
        "    \"exp_name\": 'tmp',\n",
        "    \"fpr_threshold\": 0.10,\n",
        "    \"compute_bootstrap\": False,\n",
        "    \"baseline\": False,\n",
        "    \"visualize\": False,\n",
        "    \"tune_params\": False,\n",
        "    \"model_params_path\": \"params/reduce_dim_100.json\",\n",
        "    \"PCA_dim\": None,\n",
        "    \"MCD_h\": None,\n",
        "    \"ensemble\": False,\n",
        "    \"adapt_ckpt\": None,\n",
        "    \"gpu\": '0',\n",
        "    \"start_seed\": 0,\n",
        "    \"end_seed\": 0,\n",
        "    \"mnli_option\": \"matched\"\n",
        "}\n",
        "\n",
        "    # Rest of the code remains unchanged\n",
        "logger = Logger('logs/')\n",
        "logger.log.info(input_variables)\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._dict = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._dict:\n",
        "            return self._dict[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "args=DotDict(input_variables)\n",
        "import transformers\n",
        "model_wrapper = BertWrapper(args, logger)\n",
        "model = model_wrapper.model\n",
        "tokenizer = model_wrapper.tokenizer\n",
        "datasetname='imdb'\n",
        "model_name=target_model\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/Dataset_Comparison'\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "clean_df['advlabel']=0\n",
        "clean_labels=np.zeros(len(clean_df))\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "adv_labels=np.ones(len(adv_df))\n",
        "\n",
        "train_data = np.concatenate((org_text, adv_text), axis=0)\n",
        "train_labels = np.concatenate((clean_labels, adv_labels), axis=0)\n",
        "attacks = np.concatenate((attack_org, adv_df['attack']), axis=0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "with open(args.model_params_path, \"r\") as r:\n",
        "    params = json.load(r)\n",
        "    if args.PCA_dim:\n",
        "       params['reduce_dim']['dim'] = args.PCA_dim\n",
        "    if args.MCD_h:\n",
        "        params['h'] = float(args.MCD_h)\n",
        "    num_params = len(glob.glob(os.path.join('logs/', \"*.json\")))\n",
        "\n",
        "# Create a DataFrame\n",
        "\n",
        "traind, testd = train_test_split(clean_df, test_size=0.30, random_state=42)\n",
        "key = 'text' if (datasetname in [\"ag-news\", \"imdb\", \"yelp\"]) else 'sentence'\n",
        "feats = get_train_features(model_wrapper, args, batch_size=100, dataset=traind, text_key=key,\n",
        "                             layer=params['layer_param']['cls_layer'])\n",
        "if(isinstance(feats,list)):\n",
        "  feats=feats[0]\n",
        "feats=feats.detach().numpy()\n",
        "reduced_feat, labels, reducer, scaler = preprocess_features(feats, params, args, logger)\n",
        "print(reduced_feat)\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "train_stats, estimators = get_stats(reduced_feat, labels, cov_estim_name=args.cov_estimator, use_shared_cov=params['shared_cov'], params=params)\n",
        "naive_train_stats, naive_estimators = get_stats(reduced_feat, labels, cov_estim_name=\"None\", use_shared_cov=params['shared_cov'])\n",
        "all_train_stats = [naive_train_stats, train_stats]\n",
        "all_estimators = [naive_estimators, estimators]\n",
        "if args.visualize:\n",
        "    dir_name = os.path.dirname(args.log_path)\n",
        "    path_to_feat = os.path.join(dir_name, 'feats.txt')\n",
        "    feat_n_label = np.concatenate([reduced_feat, labels[:,np.newaxis]], axis=-1)\n",
        "    np.savetxt(path_to_feat, feat_n_label)\n",
        "    for cls_idx, mu_n_cov in enumerate(train_stats):\n",
        "      np.save(os.path.join(dir_name, f\"cls{cls_idx}-cov.npy\"), mu_n_cov[1])\n",
        "\n",
        "    for name, stat in zip(['naive', 'robust'], all_train_stats):\n",
        "      for idx, (mu, cov) in enumerate(stat):\n",
        "        spectrum = np.linalg.eigvals(cov)\n",
        "        path_to_csv = os.path.join(os.path.dirname(args.log_path), 'spectrum.csv')\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "          wr = csv.writer(f)\n",
        "          wr.writerow([name, max(spectrum), min(spectrum)])\n",
        "        kappa = max(spectrum) / min(spectrum)\n",
        "        plt.matshow(cov)\n",
        "        plt.title(f\"Cond.:{kappa:.3e} Max:{max(spectrum):.3e} Min: {min(spectrum):.3e}\")\n",
        "        cb = plt.colorbar()\n",
        "        cb.ax.tick_params(labelsize=14)\n",
        "        plt.savefig(os.path.join(os.path.dirname(args.log_path), f\"{name}-cls{idx}.png\"))\n",
        "    exit()\n",
        "loader = pd.DataFrame()\n",
        "loader['text'] = np.concatenate([adv_text, testd[key]])\n",
        "loader['result_type']=np.concatenate([np.ones(len(adv_text)), np.zeros(len(testd[key]))])\n",
        "loader['attack']=np.concatenate([adv_df['attack'],testd['attack']])\n",
        "print(loader)\n",
        "for s in range(args.start_seed, args.end_seed+1):\n",
        "    logger.set_seed(s)\n",
        "\n",
        "    detector = Detector(model_wrapper, all_train_stats, loader, logger, params, (scaler, reducer, all_estimators, args.cov_estimator), use_val=args.use_val , dataset=args.dataset , seed=s)\n",
        "    if args.baseline:\n",
        "      detector.test_baseline_PPL(args.fpr_threshold)\n",
        "    else:\n",
        "\n",
        "      roc, tpr_at_fpr,conf, testset = detector.test(args.fpr_threshold, args.pkl_test_path)\n",
        "\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "# Convert metrics_dict to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict.items(), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNbPqah5jd6k"
      },
      "source": [
        "##ROBERTA IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZBz11Htjf0-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pdb\n",
        "import glob\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define input variables\n",
        "dataset = \"imdb\"\n",
        "preprocess = \"standard\"\n",
        "data_type = \"standard\"\n",
        "target_model = \"textattack/roberta-base-imdb\"\n",
        "model_type = None  # Fill in the desired value\n",
        "use_state_dict = False\n",
        "data_root_dir = 'attack-log/original'\n",
        "scenario = None  # Fill in the desired value\n",
        "include_fae = False\n",
        "unbalanced = False\n",
        "use_val = False\n",
        "cov_estimator = None  # Fill in the desired value\n",
        "pkl_test_path = \" \"\n",
        "pkl_val_path = \" \"\n",
        "attack_type = 'textfooler'\n",
        "exp_name = 'tmp'\n",
        "fpr_threshold = 0.10\n",
        "compute_bootstrap = False\n",
        "baseline = False\n",
        "visualize = False\n",
        "tune_params = False\n",
        "model_params_path = \"params/attention_key-exclude.json\"\n",
        "PCA_dim = None\n",
        "MCD_h = None\n",
        "ensemble = False\n",
        "adapt_ckpt = None\n",
        "gpu = '0'\n",
        "start_seed = 0\n",
        "end_seed = 0\n",
        "mnli_option = \"matched\"\n",
        "\n",
        "# Import libraries and modules\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "\n",
        "\n",
        "model_type = target_model.replace(\"/\", \"-\")\n",
        "if exp_name:\n",
        "    log_path = f\"runs/{dataset}/{exp_name}/{model_type}/{attack_type}\"\n",
        "else:\n",
        "    log_path = f\"runs/{dataset}/{model_type}/{attack_type}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.isdir(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "\n",
        "\n",
        "input_variables = {\n",
        "    \"dataset\": \"imdb\",\n",
        "    \"preprocess\": \"standard\",\n",
        "    \"data_type\": \"standard\",\n",
        "    \"target_model\": \"textattack/roberta-base-imdb\",\n",
        "    \"model_type\": None,  # Fill in the desired value\n",
        "    \"use_state_dict\": False,\n",
        "    \"data_root_dir\": 'attack-log/original',\n",
        "    \"scenario\": None,  # Fill in the desired value\n",
        "    \"include_fae\": False,\n",
        "    \"unbalanced\": False,\n",
        "    \"use_val\": False,\n",
        "    \"cov_estimator\": None,  # Fill in the desired value\n",
        "    \"pkl_test_path\": \" \",\n",
        "    \"pkl_val_path\": \" \",\n",
        "    \"attack_type\": 'textfooler',\n",
        "    \"exp_name\": 'tmp',\n",
        "    \"fpr_threshold\": 0.10,\n",
        "    \"compute_bootstrap\": False,\n",
        "    \"baseline\": False,\n",
        "    \"visualize\": False,\n",
        "    \"tune_params\": False,\n",
        "    \"model_params_path\": \"params/reduce_dim_100.json\",\n",
        "    \"PCA_dim\": None,\n",
        "    \"MCD_h\": None,\n",
        "    \"ensemble\": False,\n",
        "    \"adapt_ckpt\": None,\n",
        "    \"gpu\": '0',\n",
        "    \"start_seed\": 0,\n",
        "    \"end_seed\": 0,\n",
        "    \"mnli_option\": \"matched\"\n",
        "}\n",
        "\n",
        "    # Rest of the code remains unchanged\n",
        "logger = Logger('logs/')\n",
        "logger.log.info(input_variables)\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._dict = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._dict:\n",
        "            return self._dict[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "args=DotDict(input_variables)\n",
        "import transformers\n",
        "model_wrapper = BertWrapper(args, logger)\n",
        "model = model_wrapper.model\n",
        "tokenizer = model_wrapper.tokenizer\n",
        "datasetname='imdb'\n",
        "model_name=target_model\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "clean_labels=np.zeros(len(clean_df))\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "adv_labels=np.ones(len(adv_df))\n",
        "\n",
        "train_data = np.concatenate((org_text, adv_text), axis=0)\n",
        "train_labels = np.concatenate((clean_labels, adv_labels), axis=0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dict = {\n",
        "    'text_key': org_text,\n",
        "    'label': clean_df['label']\n",
        "}\n",
        "with open(args.model_params_path, \"r\") as r:\n",
        "    params = json.load(r)\n",
        "    if args.PCA_dim:\n",
        "       params['reduce_dim']['dim'] = args.PCA_dim\n",
        "    if args.MCD_h:\n",
        "        params['h'] = float(args.MCD_h)\n",
        "    num_params = len(glob.glob(os.path.join('logs/', \"*.json\")))\n",
        "\n",
        "# Create a DataFrame\n",
        "train_dataframe = pd.DataFrame(data_dict)\n",
        "traind, testd, y_train, y_test = train_test_split(train_dataframe,train_dataframe['label'], stratify=train_dataframe['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "feats = get_train_features(model_wrapper, args, batch_size=100, dataset=traind, text_key=y_train,\n",
        "                             layer=params['layer_param']['cls_layer'])\n",
        "if(isinstance(feats,list)):\n",
        "  feats=feats[0]\n",
        "feats=feats.detach().numpy()\n",
        "reduced_feat, labels, reducer, scaler = preprocess_features(feats, params, args, logger)\n",
        "print(reduced_feat)\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "train_stats, estimators = get_stats(reduced_feat, labels, cov_estim_name=args.cov_estimator, use_shared_cov=params['shared_cov'], params=params)\n",
        "naive_train_stats, naive_estimators = get_stats(reduced_feat, labels, cov_estim_name=\"None\", use_shared_cov=params['shared_cov'])\n",
        "all_train_stats = [naive_train_stats, train_stats]\n",
        "all_estimators = [naive_estimators, estimators]\n",
        "if args.visualize:\n",
        "    dir_name = os.path.dirname(args.log_path)\n",
        "    path_to_feat = os.path.join(dir_name, 'feats.txt')\n",
        "    feat_n_label = np.concatenate([reduced_feat, labels[:,np.newaxis]], axis=-1)\n",
        "    np.savetxt(path_to_feat, feat_n_label)\n",
        "    for cls_idx, mu_n_cov in enumerate(train_stats):\n",
        "      np.save(os.path.join(dir_name, f\"cls{cls_idx}-cov.npy\"), mu_n_cov[1])\n",
        "\n",
        "    for name, stat in zip(['naive', 'robust'], all_train_stats):\n",
        "      for idx, (mu, cov) in enumerate(stat):\n",
        "        spectrum = np.linalg.eigvals(cov)\n",
        "        path_to_csv = os.path.join(os.path.dirname(args.log_path), 'spectrum.csv')\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "          wr = csv.writer(f)\n",
        "          wr.writerow([name, max(spectrum), min(spectrum)])\n",
        "        kappa = max(spectrum) / min(spectrum)\n",
        "        plt.matshow(cov)\n",
        "        plt.title(f\"Cond.:{kappa:.3e} Max:{max(spectrum):.3e} Min: {min(spectrum):.3e}\")\n",
        "        cb = plt.colorbar()\n",
        "        cb.ax.tick_params(labelsize=14)\n",
        "        plt.savefig(os.path.join(os.path.dirname(args.log_path), f\"{name}-cls{idx}.png\"))\n",
        "    exit()\n",
        "loader = pd.DataFrame()\n",
        "loader['text'] = np.concatenate([adv_text, testd['text_key']])\n",
        "loader['result_type']=np.concatenate([np.ones(len(adv_text)), np.zeros(len(testd['text_key']))])\n",
        "testd['attack']='NO'\n",
        "loader['attack']=np.concatenate([adv_df['attack'],testd['attack']])\n",
        "print(loader)\n",
        "for s in range(args.start_seed, args.end_seed+1):\n",
        "    logger.set_seed(s)\n",
        "\n",
        "    detector = Detector(model_wrapper, all_train_stats, loader, logger, params, (scaler, reducer, all_estimators, args.cov_estimator), use_val=args.use_val , dataset=args.dataset , seed=s)\n",
        "    if args.baseline:\n",
        "      detector.test_baseline_PPL(args.fpr_threshold)\n",
        "    else:\n",
        "      roc, tpr_at_fpr, metrics_dict,conf, testset = detector.test(args.fpr_threshold, args.pkl_test_path)\n",
        "\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "# Convert metrics_dict to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict.items(), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B_511BLWcLO"
      },
      "source": [
        "##AG-NEWS BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_q7a42MWgbY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pdb\n",
        "import glob\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define input variables\n",
        "dataset = \"ag-news\"\n",
        "datasetname=\"ag_news\"\n",
        "preprocess = \"standard\"\n",
        "data_type = \"standard\"\n",
        "target_model = \"textattack/bert-base-uncased-ag-news\"\n",
        "model_type = None  # Fill in the desired value\n",
        "use_state_dict = False\n",
        "data_root_dir = 'attack-log/original'\n",
        "scenario = None  # Fill in the desired value\n",
        "include_fae = False\n",
        "unbalanced = False\n",
        "use_val = False\n",
        "cov_estimator = None  # Fill in the desired value\n",
        "pkl_test_path = \" \"\n",
        "pkl_val_path = \" \"\n",
        "attack_type = 'textfooler'\n",
        "exp_name = 'tmp'\n",
        "fpr_threshold = 0.10\n",
        "compute_bootstrap = False\n",
        "baseline = False\n",
        "visualize = False\n",
        "tune_params = False\n",
        "model_params_path = \"params/attention_key-exclude.json\"\n",
        "PCA_dim = None\n",
        "MCD_h = None\n",
        "ensemble = False\n",
        "adapt_ckpt = None\n",
        "gpu = '0'\n",
        "start_seed = 0\n",
        "end_seed = 0\n",
        "mnli_option = \"matched\"\n",
        "\n",
        "# Import libraries and modules\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "\n",
        "\n",
        "model_type = target_model.replace(\"/\", \"-\")\n",
        "if exp_name:\n",
        "    log_path = f\"runs/{dataset}/{exp_name}/{model_type}/{attack_type}\"\n",
        "else:\n",
        "    log_path = f\"runs/{dataset}/{model_type}/{attack_type}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.isdir(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "\n",
        "\n",
        "input_variables = {\n",
        "    \"dataset\": dataset,\n",
        "    \"preprocess\": \"standard\",\n",
        "    \"data_type\": \"standard\",\n",
        "    \"target_model\": target_model,\n",
        "    \"model_type\": None,  # Fill in the desired value\n",
        "    \"use_state_dict\": False,\n",
        "    \"data_root_dir\": 'attack-log/original',\n",
        "    \"scenario\": None,  # Fill in the desired value\n",
        "    \"include_fae\": False,\n",
        "    \"unbalanced\": False,\n",
        "    \"use_val\": False,\n",
        "    \"cov_estimator\": None,  # Fill in the desired value\n",
        "    \"pkl_test_path\": \" \",\n",
        "    \"pkl_val_path\": \" \",\n",
        "    \"attack_type\": 'textfooler',\n",
        "    \"exp_name\": 'tmp',\n",
        "    \"fpr_threshold\": 0.10,\n",
        "    \"compute_bootstrap\": False,\n",
        "    \"baseline\": False,\n",
        "    \"visualize\": False,\n",
        "    \"tune_params\": False,\n",
        "    \"model_params_path\": \"params/reduce_dim_100.json\",\n",
        "    \"PCA_dim\": None,\n",
        "    \"MCD_h\": None,\n",
        "    \"ensemble\": False,\n",
        "    \"adapt_ckpt\": None,\n",
        "    \"gpu\": '0',\n",
        "    \"start_seed\": 0,\n",
        "    \"end_seed\": 0,\n",
        "    \"mnli_option\": \"matched\"\n",
        "}\n",
        "\n",
        "    # Rest of the code remains unchanged\n",
        "logger = Logger('logs/')\n",
        "logger.log.info(input_variables)\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._dict = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._dict:\n",
        "            return self._dict[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "args=DotDict(input_variables)\n",
        "import transformers\n",
        "model_wrapper = BertWrapper(args, logger)\n",
        "model = model_wrapper.model\n",
        "tokenizer = model_wrapper.tokenizer\n",
        "\n",
        "model_name=target_model\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "clean_labels=np.zeros(len(clean_df))\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "adv_labels=np.ones(len(adv_df))\n",
        "\n",
        "train_data = np.concatenate((org_text, adv_text), axis=0)\n",
        "train_labels = np.concatenate((clean_labels, adv_labels), axis=0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dict = {\n",
        "    'text_key': org_text,\n",
        "    'label': clean_df['label']\n",
        "}\n",
        "with open(args.model_params_path, \"r\") as r:\n",
        "    params = json.load(r)\n",
        "    if args.PCA_dim:\n",
        "       params['reduce_dim']['dim'] = args.PCA_dim\n",
        "    if args.MCD_h:\n",
        "        params['h'] = float(args.MCD_h)\n",
        "    num_params = len(glob.glob(os.path.join('logs/', \"*.json\")))\n",
        "\n",
        "# Create a DataFrame\n",
        "train_dataframe = pd.DataFrame(data_dict)\n",
        "traind, testd, y_train, y_test = train_test_split(train_dataframe,train_dataframe['label'], stratify=train_dataframe['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "feats = get_train_features(model_wrapper, args, batch_size=100, dataset=traind, text_key=y_train,\n",
        "                             layer=params['layer_param']['cls_layer'])\n",
        "if(isinstance(feats,list)):\n",
        "  feats=feats[0]\n",
        "feats=feats.detach().numpy()\n",
        "reduced_feat, labels, reducer, scaler = preprocess_features(feats, params, args, logger)\n",
        "print(reduced_feat)\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "train_stats, estimators = get_stats(reduced_feat, labels, cov_estim_name=args.cov_estimator, use_shared_cov=params['shared_cov'], params=params)\n",
        "naive_train_stats, naive_estimators = get_stats(reduced_feat, labels, cov_estim_name=\"None\", use_shared_cov=params['shared_cov'])\n",
        "all_train_stats = [naive_train_stats, train_stats]\n",
        "all_estimators = [naive_estimators, estimators]\n",
        "if args.visualize:\n",
        "    dir_name = os.path.dirname(args.log_path)\n",
        "    path_to_feat = os.path.join(dir_name, 'feats.txt')\n",
        "    feat_n_label = np.concatenate([reduced_feat, labels[:,np.newaxis]], axis=-1)\n",
        "    np.savetxt(path_to_feat, feat_n_label)\n",
        "    for cls_idx, mu_n_cov in enumerate(train_stats):\n",
        "      np.save(os.path.join(dir_name, f\"cls{cls_idx}-cov.npy\"), mu_n_cov[1])\n",
        "\n",
        "    for name, stat in zip(['naive', 'robust'], all_train_stats):\n",
        "      for idx, (mu, cov) in enumerate(stat):\n",
        "        spectrum = np.linalg.eigvals(cov)\n",
        "        path_to_csv = os.path.join(os.path.dirname(args.log_path), 'spectrum.csv')\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "          wr = csv.writer(f)\n",
        "          wr.writerow([name, max(spectrum), min(spectrum)])\n",
        "        kappa = max(spectrum) / min(spectrum)\n",
        "        plt.matshow(cov)\n",
        "        plt.title(f\"Cond.:{kappa:.3e} Max:{max(spectrum):.3e} Min: {min(spectrum):.3e}\")\n",
        "        cb = plt.colorbar()\n",
        "        cb.ax.tick_params(labelsize=14)\n",
        "        plt.savefig(os.path.join(os.path.dirname(args.log_path), f\"{name}-cls{idx}.png\"))\n",
        "    exit()\n",
        "loader = pd.DataFrame()\n",
        "loader['text'] = np.concatenate([adv_text, testd['text_key']])\n",
        "loader['result_type']=np.concatenate([np.ones(len(adv_text)), np.zeros(len(testd['text_key']))])\n",
        "\n",
        "for s in range(args.start_seed, args.end_seed+1):\n",
        "    logger.set_seed(s)\n",
        "\n",
        "    detector = Detector(model_wrapper, all_train_stats, loader, logger, params, (scaler, reducer, all_estimators, args.cov_estimator), use_val=args.use_val , dataset=args.dataset , seed=s)\n",
        "    if args.baseline:\n",
        "      detector.test_baseline_PPL(args.fpr_threshold)\n",
        "    else:\n",
        "      roc, tpr_at_fpr, metrics_dict,conf, testset = detector.test(args.fpr_threshold, args.pkl_test_path)\n",
        "\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "# Convert metrics_dict to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict.items(), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)\n",
        "metrics_df.to_csv(datasetname+'bert_test_data_evaluation_metrics.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMshX3GPlZJB"
      },
      "source": [
        "##AGNEWS ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4WbiYsflYtx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pdb\n",
        "import glob\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define input variables\n",
        "dataset = \"ag-news\"\n",
        "datasetname=\"ag_news\"\n",
        "preprocess = \"standard\"\n",
        "\n",
        "data_type = \"standard\"\n",
        "target_model = \"textattack/roberta-base-ag-news\"\n",
        "model_type = None  # Fill in the desired value\n",
        "use_state_dict = False\n",
        "data_root_dir = 'attack-log/original'\n",
        "scenario = None  # Fill in the desired value\n",
        "include_fae = False\n",
        "unbalanced = False\n",
        "use_val = False\n",
        "cov_estimator = None  # Fill in the desired value\n",
        "pkl_test_path = \" \"\n",
        "pkl_val_path = \" \"\n",
        "attack_type = 'textfooler'\n",
        "exp_name = 'tmp'\n",
        "fpr_threshold = 0.10\n",
        "compute_bootstrap = False\n",
        "baseline = False\n",
        "visualize = False\n",
        "tune_params = False\n",
        "model_params_path = \"params/attention_key-exclude.json\"\n",
        "PCA_dim = None\n",
        "MCD_h = None\n",
        "ensemble = False\n",
        "adapt_ckpt = None\n",
        "gpu = '0'\n",
        "start_seed = 0\n",
        "end_seed = 0\n",
        "mnli_option = \"matched\"\n",
        "\n",
        "# Import libraries and modules\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "\n",
        "\n",
        "model_type = target_model.replace(\"/\", \"-\")\n",
        "if exp_name:\n",
        "    log_path = f\"runs/{dataset}/{exp_name}/{model_type}/{attack_type}\"\n",
        "else:\n",
        "    log_path = f\"runs/{dataset}/{model_type}/{attack_type}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.isdir(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "\n",
        "\n",
        "input_variables = {\n",
        "    \"dataset\": dataset,\n",
        "    \"preprocess\": \"standard\",\n",
        "    \"data_type\": \"standard\",\n",
        "    \"target_model\": target_model,\n",
        "    \"model_type\": None,  # Fill in the desired value\n",
        "    \"use_state_dict\": False,\n",
        "    \"data_root_dir\": 'attack-log/original',\n",
        "    \"scenario\": None,  # Fill in the desired value\n",
        "    \"include_fae\": False,\n",
        "    \"unbalanced\": False,\n",
        "    \"use_val\": False,\n",
        "    \"cov_estimator\": None,  # Fill in the desired value\n",
        "    \"pkl_test_path\": \" \",\n",
        "    \"pkl_val_path\": \" \",\n",
        "    \"attack_type\": 'textfooler',\n",
        "    \"exp_name\": 'tmp',\n",
        "    \"fpr_threshold\": 0.10,\n",
        "    \"compute_bootstrap\": False,\n",
        "    \"baseline\": False,\n",
        "    \"visualize\": False,\n",
        "    \"tune_params\": False,\n",
        "    \"model_params_path\": \"params/reduce_dim_100.json\",\n",
        "    \"PCA_dim\": None,\n",
        "    \"MCD_h\": None,\n",
        "    \"ensemble\": False,\n",
        "    \"adapt_ckpt\": None,\n",
        "    \"gpu\": '0',\n",
        "    \"start_seed\": 0,\n",
        "    \"end_seed\": 0,\n",
        "    \"mnli_option\": \"matched\"\n",
        "}\n",
        "\n",
        "    # Rest of the code remains unchanged\n",
        "logger = Logger('logs/')\n",
        "logger.log.info(input_variables)\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._dict = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._dict:\n",
        "            return self._dict[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "args=DotDict(input_variables)\n",
        "import transformers\n",
        "model_wrapper = BertWrapper(args, logger)\n",
        "model = model_wrapper.model\n",
        "tokenizer = model_wrapper.tokenizer\n",
        "\n",
        "model_name=target_model\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "clean_labels=np.zeros(len(clean_df))\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "adv_labels=np.ones(len(adv_df))\n",
        "\n",
        "train_data = np.concatenate((org_text, adv_text), axis=0)\n",
        "train_labels = np.concatenate((clean_labels, adv_labels), axis=0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dict = {\n",
        "    'text_key': org_text,\n",
        "    'label': clean_df['label']\n",
        "}\n",
        "with open(args.model_params_path, \"r\") as r:\n",
        "    params = json.load(r)\n",
        "    if args.PCA_dim:\n",
        "       params['reduce_dim']['dim'] = args.PCA_dim\n",
        "    if args.MCD_h:\n",
        "        params['h'] = float(args.MCD_h)\n",
        "    num_params = len(glob.glob(os.path.join('logs/', \"*.json\")))\n",
        "\n",
        "# Create a DataFrame\n",
        "train_dataframe = pd.DataFrame(data_dict)\n",
        "traind, testd, y_train, y_test = train_test_split(train_dataframe,train_dataframe['label'], stratify=train_dataframe['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "feats = get_train_features(model_wrapper, args, batch_size=100, dataset=traind, text_key=y_train,\n",
        "                             layer=params['layer_param']['cls_layer'])\n",
        "if(isinstance(feats,list)):\n",
        "  feats=feats[0]\n",
        "feats=feats.detach().numpy()\n",
        "reduced_feat, labels, reducer, scaler = preprocess_features(feats, params, args, logger)\n",
        "print(reduced_feat)\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "train_stats, estimators = get_stats(reduced_feat, labels, cov_estim_name=args.cov_estimator, use_shared_cov=params['shared_cov'], params=params)\n",
        "naive_train_stats, naive_estimators = get_stats(reduced_feat, labels, cov_estim_name=\"None\", use_shared_cov=params['shared_cov'])\n",
        "all_train_stats = [naive_train_stats, train_stats]\n",
        "all_estimators = [naive_estimators, estimators]\n",
        "if args.visualize:\n",
        "    dir_name = os.path.dirname(args.log_path)\n",
        "    path_to_feat = os.path.join(dir_name, 'feats.txt')\n",
        "    feat_n_label = np.concatenate([reduced_feat, labels[:,np.newaxis]], axis=-1)\n",
        "    np.savetxt(path_to_feat, feat_n_label)\n",
        "    for cls_idx, mu_n_cov in enumerate(train_stats):\n",
        "      np.save(os.path.join(dir_name, f\"cls{cls_idx}-cov.npy\"), mu_n_cov[1])\n",
        "\n",
        "    for name, stat in zip(['naive', 'robust'], all_train_stats):\n",
        "      for idx, (mu, cov) in enumerate(stat):\n",
        "        spectrum = np.linalg.eigvals(cov)\n",
        "        path_to_csv = os.path.join(os.path.dirname(args.log_path), 'spectrum.csv')\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "          wr = csv.writer(f)\n",
        "          wr.writerow([name, max(spectrum), min(spectrum)])\n",
        "        kappa = max(spectrum) / min(spectrum)\n",
        "        plt.matshow(cov)\n",
        "        plt.title(f\"Cond.:{kappa:.3e} Max:{max(spectrum):.3e} Min: {min(spectrum):.3e}\")\n",
        "        cb = plt.colorbar()\n",
        "        cb.ax.tick_params(labelsize=14)\n",
        "        plt.savefig(os.path.join(os.path.dirname(args.log_path), f\"{name}-cls{idx}.png\"))\n",
        "    exit()\n",
        "loader = pd.DataFrame()\n",
        "loader['text'] = np.concatenate([adv_text, testd['text_key']])\n",
        "loader['result_type']=np.concatenate([np.ones(len(adv_text)), np.zeros(len(testd['text_key']))])\n",
        "\n",
        "for s in range(args.start_seed, args.end_seed+1):\n",
        "    logger.set_seed(s)\n",
        "\n",
        "    detector = Detector(model_wrapper, all_train_stats, loader, logger, params, (scaler, reducer, all_estimators, args.cov_estimator), use_val=args.use_val , dataset=args.dataset , seed=s)\n",
        "    if args.baseline:\n",
        "      detector.test_baseline_PPL(args.fpr_threshold)\n",
        "    else:\n",
        "      roc, tpr_at_fpr, metrics_dict,conf, testset = detector.test(args.fpr_threshold, args.pkl_test_path)\n",
        "\n",
        "\n",
        "# Convert metrics_dict to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict.items(), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)\n",
        "metrics_df.to_csv(datasetname+'roberta_test_data_evaluation_metrics.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2pH0El7d_qC"
      },
      "source": [
        "##BERT YELP POLARITY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djWo8J6Ddglp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pdb\n",
        "import glob\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define input variables\n",
        "dataset = \"yelp_polarity\"\n",
        "datasetname=\"yelp_polarity\"\n",
        "preprocess = \"standard\"\n",
        "data_type = \"standard\"\n",
        "target_model = \"textattack/bert-base-uncased-yelp-polarity\"\n",
        "model_type = None  # Fill in the desired value\n",
        "use_state_dict = False\n",
        "data_root_dir = 'attack-log/original'\n",
        "scenario = None  # Fill in the desired value\n",
        "include_fae = False\n",
        "unbalanced = False\n",
        "use_val = False\n",
        "cov_estimator = None  # Fill in the desired value\n",
        "pkl_test_path = \" \"\n",
        "pkl_val_path = \" \"\n",
        "attack_type = 'textfooler'\n",
        "exp_name = 'tmp'\n",
        "fpr_threshold = 0.10\n",
        "compute_bootstrap = False\n",
        "baseline = False\n",
        "visualize = False\n",
        "tune_params = False\n",
        "model_params_path = \"params/attention_key-exclude.json\"\n",
        "PCA_dim = None\n",
        "MCD_h = None\n",
        "ensemble = False\n",
        "adapt_ckpt = None\n",
        "gpu = '0'\n",
        "start_seed = 0\n",
        "end_seed = 0\n",
        "mnli_option = \"matched\"\n",
        "\n",
        "# Import libraries and modules\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "\n",
        "\n",
        "model_type = target_model.replace(\"/\", \"-\")\n",
        "if exp_name:\n",
        "    log_path = f\"runs/{dataset}/{exp_name}/{model_type}/{attack_type}\"\n",
        "else:\n",
        "    log_path = f\"runs/{dataset}/{model_type}/{attack_type}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.isdir(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "\n",
        "\n",
        "input_variables = {\n",
        "    \"dataset\": dataset,\n",
        "    \"preprocess\": \"standard\",\n",
        "    \"data_type\": \"standard\",\n",
        "    \"target_model\": target_model,\n",
        "    \"model_type\": None,  # Fill in the desired value\n",
        "    \"use_state_dict\": False,\n",
        "    \"data_root_dir\": 'attack-log/original',\n",
        "    \"scenario\": None,  # Fill in the desired value\n",
        "    \"include_fae\": False,\n",
        "    \"unbalanced\": False,\n",
        "    \"use_val\": False,\n",
        "    \"cov_estimator\": None,  # Fill in the desired value\n",
        "    \"pkl_test_path\": \" \",\n",
        "    \"pkl_val_path\": \" \",\n",
        "    \"attack_type\": 'textfooler',\n",
        "    \"exp_name\": 'tmp',\n",
        "    \"fpr_threshold\": 0.10,\n",
        "    \"compute_bootstrap\": False,\n",
        "    \"baseline\": False,\n",
        "    \"visualize\": False,\n",
        "    \"tune_params\": False,\n",
        "    \"model_params_path\": \"params/reduce_dim_100.json\",\n",
        "    \"PCA_dim\": None,\n",
        "    \"MCD_h\": None,\n",
        "    \"ensemble\": False,\n",
        "    \"adapt_ckpt\": None,\n",
        "    \"gpu\": '0',\n",
        "    \"start_seed\": 0,\n",
        "    \"end_seed\": 0,\n",
        "    \"mnli_option\": \"matched\"\n",
        "}\n",
        "\n",
        "    # Rest of the code remains unchanged\n",
        "logger = Logger('logs/')\n",
        "logger.log.info(input_variables)\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._dict = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._dict:\n",
        "            return self._dict[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "args=DotDict(input_variables)\n",
        "import transformers\n",
        "model_wrapper = BertWrapper(args, logger)\n",
        "model = model_wrapper.model\n",
        "tokenizer = model_wrapper.tokenizer\n",
        "\n",
        "model_name=target_model\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "clean_labels=np.zeros(len(clean_df))\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "adv_labels=np.ones(len(adv_df))\n",
        "\n",
        "train_data = np.concatenate((org_text, adv_text), axis=0)\n",
        "train_labels = np.concatenate((clean_labels, adv_labels), axis=0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dict = {\n",
        "    'text_key': org_text,\n",
        "    'label': clean_df['label']\n",
        "}\n",
        "with open(args.model_params_path, \"r\") as r:\n",
        "    params = json.load(r)\n",
        "    if args.PCA_dim:\n",
        "       params['reduce_dim']['dim'] = args.PCA_dim\n",
        "    if args.MCD_h:\n",
        "        params['h'] = float(args.MCD_h)\n",
        "    num_params = len(glob.glob(os.path.join('logs/', \"*.json\")))\n",
        "\n",
        "# Create a DataFrame\n",
        "train_dataframe = pd.DataFrame(data_dict)\n",
        "traind, testd, y_train, y_test = train_test_split(train_dataframe,train_dataframe['label'], stratify=train_dataframe['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "feats = get_train_features(model_wrapper, args, batch_size=100, dataset=traind, text_key=y_train,\n",
        "                             layer=params['layer_param']['cls_layer'])\n",
        "print(\"The types of feats is\", type(feats))\n",
        "print(feats)\n",
        "if(isinstance(feats,list)):\n",
        "  feats=feats[0]\n",
        "  print('here')\n",
        "feats=feats.detach().numpy()\n",
        "reduced_feat, labels, reducer, scaler = preprocess_features(feats, params, args, logger)\n",
        "print(reduced_feat)\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "train_stats, estimators = get_stats(reduced_feat, labels, cov_estim_name=args.cov_estimator, use_shared_cov=params['shared_cov'], params=params)\n",
        "naive_train_stats, naive_estimators = get_stats(reduced_feat, labels, cov_estim_name=\"None\", use_shared_cov=params['shared_cov'])\n",
        "all_train_stats = [naive_train_stats, train_stats]\n",
        "all_estimators = [naive_estimators, estimators]\n",
        "if args.visualize:\n",
        "    dir_name = os.path.dirname(args.log_path)\n",
        "    path_to_feat = os.path.join(dir_name, 'feats.txt')\n",
        "    feat_n_label = np.concatenate([reduced_feat, labels[:,np.newaxis]], axis=-1)\n",
        "    np.savetxt(path_to_feat, feat_n_label)\n",
        "    for cls_idx, mu_n_cov in enumerate(train_stats):\n",
        "      np.save(os.path.join(dir_name, f\"cls{cls_idx}-cov.npy\"), mu_n_cov[1])\n",
        "\n",
        "    for name, stat in zip(['naive', 'robust'], all_train_stats):\n",
        "      for idx, (mu, cov) in enumerate(stat):\n",
        "        spectrum = np.linalg.eigvals(cov)\n",
        "        path_to_csv = os.path.join(os.path.dirname(args.log_path), 'spectrum.csv')\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "          wr = csv.writer(f)\n",
        "          wr.writerow([name, max(spectrum), min(spectrum)])\n",
        "        kappa = max(spectrum) / min(spectrum)\n",
        "        plt.matshow(cov)\n",
        "        plt.title(f\"Cond.:{kappa:.3e} Max:{max(spectrum):.3e} Min: {min(spectrum):.3e}\")\n",
        "        cb = plt.colorbar()\n",
        "        cb.ax.tick_params(labelsize=14)\n",
        "        plt.savefig(os.path.join(os.path.dirname(args.log_path), f\"{name}-cls{idx}.png\"))\n",
        "    exit()\n",
        "loader = pd.DataFrame()\n",
        "loader['text'] = np.concatenate([adv_text, testd['text_key']])\n",
        "loader['result_type']=np.concatenate([np.ones(len(adv_text)), np.zeros(len(testd['text_key']))])\n",
        "\n",
        "for s in range(args.start_seed, args.end_seed+1):\n",
        "    logger.set_seed(s)\n",
        "\n",
        "    detector = Detector(model_wrapper, all_train_stats, loader, logger, params, (scaler, reducer, all_estimators, args.cov_estimator), use_val=args.use_val , dataset=args.dataset , seed=s)\n",
        "    if args.baseline:\n",
        "      detector.test_baseline_PPL(args.fpr_threshold)\n",
        "    else:\n",
        "      roc, tpr_at_fpr, metrics_dict,conf, testset = detector.test(args.fpr_threshold, args.pkl_test_path)\n",
        "\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "# Convert metrics_dict to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict.items(), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)\n",
        "metrics_df.to_csv(datasetname+'bert_test_data_evaluation_metrics.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9vhGylqoONt"
      },
      "source": [
        "##ROBERTA YELP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6JZQvdJm2Ts"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pdb\n",
        "import glob\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define input variables\n",
        "dataset = \"yelp_polarity\"\n",
        "datasetname=\"yelp_polarity\"\n",
        "preprocess = \"standard\"\n",
        "data_type = \"standard\"\n",
        "target_model = 'VictorSanh/roberta-base-finetuned-'+'yelp-polarity'\n",
        "model_type = None  # Fill in the desired value\n",
        "use_state_dict = False\n",
        "data_root_dir = 'attack-log/original'\n",
        "scenario = None  # Fill in the desired value\n",
        "include_fae = False\n",
        "unbalanced = False\n",
        "use_val = False\n",
        "cov_estimator = None  # Fill in the desired value\n",
        "pkl_test_path = \" \"\n",
        "pkl_val_path = \" \"\n",
        "attack_type = 'textfooler'\n",
        "exp_name = 'tmp'\n",
        "fpr_threshold = 0.10\n",
        "compute_bootstrap = False\n",
        "baseline = False\n",
        "visualize = False\n",
        "tune_params = False\n",
        "model_params_path = \"params/attention_key-exclude.json\"\n",
        "PCA_dim = None\n",
        "MCD_h = None\n",
        "ensemble = False\n",
        "adapt_ckpt = None\n",
        "gpu = '0'\n",
        "start_seed = 0\n",
        "end_seed = 0\n",
        "mnli_option = \"matched\"\n",
        "\n",
        "# Import libraries and modules\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "\n",
        "\n",
        "model_type = target_model.replace(\"/\", \"-\")\n",
        "if exp_name:\n",
        "    log_path = f\"runs/{dataset}/{exp_name}/{model_type}/{attack_type}\"\n",
        "else:\n",
        "    log_path = f\"runs/{dataset}/{model_type}/{attack_type}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.isdir(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "\n",
        "\n",
        "input_variables = {\n",
        "    \"dataset\": dataset,\n",
        "    \"preprocess\": \"standard\",\n",
        "    \"data_type\": \"standard\",\n",
        "    \"target_model\": target_model,\n",
        "    \"model_type\": None,  # Fill in the desired value\n",
        "    \"use_state_dict\": False,\n",
        "    \"data_root_dir\": 'attack-log/original',\n",
        "    \"scenario\": None,  # Fill in the desired value\n",
        "    \"include_fae\": False,\n",
        "    \"unbalanced\": False,\n",
        "    \"use_val\": False,\n",
        "    \"cov_estimator\": None,  # Fill in the desired value\n",
        "    \"pkl_test_path\": \" \",\n",
        "    \"pkl_val_path\": \" \",\n",
        "    \"attack_type\": 'textfooler',\n",
        "    \"exp_name\": 'tmp',\n",
        "    \"fpr_threshold\": 0.10,\n",
        "    \"compute_bootstrap\": False,\n",
        "    \"baseline\": False,\n",
        "    \"visualize\": False,\n",
        "    \"tune_params\": False,\n",
        "    \"model_params_path\": \"params/reduce_dim_100.json\",\n",
        "    \"PCA_dim\": None,\n",
        "    \"MCD_h\": None,\n",
        "    \"ensemble\": False,\n",
        "    \"adapt_ckpt\": None,\n",
        "    \"gpu\": '0',\n",
        "    \"start_seed\": 0,\n",
        "    \"end_seed\": 0,\n",
        "    \"mnli_option\": \"matched\"\n",
        "}\n",
        "\n",
        "    # Rest of the code remains unchanged\n",
        "logger = Logger('logs/')\n",
        "logger.log.info(input_variables)\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._dict = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._dict:\n",
        "            return self._dict[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "args=DotDict(input_variables)\n",
        "import transformers\n",
        "model_wrapper = BertWrapper(args, logger)\n",
        "model = model_wrapper.model\n",
        "tokenizer = model_wrapper.tokenizer\n",
        "\n",
        "model_name=target_model\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "clean_labels=np.zeros(len(clean_df))\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "adv_labels=np.ones(len(adv_df))\n",
        "\n",
        "train_data = np.concatenate((org_text, adv_text), axis=0)\n",
        "train_labels = np.concatenate((clean_labels, adv_labels), axis=0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dict = {\n",
        "    'text_key': org_text,\n",
        "    'label': clean_df['label']\n",
        "}\n",
        "with open(args.model_params_path, \"r\") as r:\n",
        "    params = json.load(r)\n",
        "    if args.PCA_dim:\n",
        "       params['reduce_dim']['dim'] = args.PCA_dim\n",
        "    if args.MCD_h:\n",
        "        params['h'] = float(args.MCD_h)\n",
        "    num_params = len(glob.glob(os.path.join('logs/', \"*.json\")))\n",
        "\n",
        "# Create a DataFrame\n",
        "train_dataframe = pd.DataFrame(data_dict)\n",
        "traind, testd, y_train, y_test = train_test_split(train_dataframe,train_dataframe['label'], stratify=train_dataframe['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "feats = get_train_features(model_wrapper, args, batch_size=100, dataset=traind, text_key=y_train,\n",
        "                             layer=params['layer_param']['cls_layer'])\n",
        "print(\"The types of feats is\", type(feats))\n",
        "print(feats)\n",
        "if(isinstance(feats,list)):\n",
        "  feats=feats[0]\n",
        "  print('here')\n",
        "feats=feats.detach().numpy()\n",
        "reduced_feat, labels, reducer, scaler = preprocess_features(feats, params, args, logger)\n",
        "print(reduced_feat)\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "train_stats, estimators = get_stats(reduced_feat, labels, cov_estim_name=args.cov_estimator, use_shared_cov=params['shared_cov'], params=params)\n",
        "naive_train_stats, naive_estimators = get_stats(reduced_feat, labels, cov_estim_name=\"None\", use_shared_cov=params['shared_cov'])\n",
        "all_train_stats = [naive_train_stats, train_stats]\n",
        "all_estimators = [naive_estimators, estimators]\n",
        "if args.visualize:\n",
        "    dir_name = os.path.dirname(args.log_path)\n",
        "    path_to_feat = os.path.join(dir_name, 'feats.txt')\n",
        "    feat_n_label = np.concatenate([reduced_feat, labels[:,np.newaxis]], axis=-1)\n",
        "    np.savetxt(path_to_feat, feat_n_label)\n",
        "    for cls_idx, mu_n_cov in enumerate(train_stats):\n",
        "      np.save(os.path.join(dir_name, f\"cls{cls_idx}-cov.npy\"), mu_n_cov[1])\n",
        "\n",
        "    for name, stat in zip(['naive', 'robust'], all_train_stats):\n",
        "      for idx, (mu, cov) in enumerate(stat):\n",
        "        spectrum = np.linalg.eigvals(cov)\n",
        "        path_to_csv = os.path.join(os.path.dirname(args.log_path), 'spectrum.csv')\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "          wr = csv.writer(f)\n",
        "          wr.writerow([name, max(spectrum), min(spectrum)])\n",
        "        kappa = max(spectrum) / min(spectrum)\n",
        "        plt.matshow(cov)\n",
        "        plt.title(f\"Cond.:{kappa:.3e} Max:{max(spectrum):.3e} Min: {min(spectrum):.3e}\")\n",
        "        cb = plt.colorbar()\n",
        "        cb.ax.tick_params(labelsize=14)\n",
        "        plt.savefig(os.path.join(os.path.dirname(args.log_path), f\"{name}-cls{idx}.png\"))\n",
        "    exit()\n",
        "loader = pd.DataFrame()\n",
        "loader['text'] = np.concatenate([adv_text, testd['text_key']])\n",
        "loader['result_type']=np.concatenate([np.ones(len(adv_text)), np.zeros(len(testd['text_key']))])\n",
        "\n",
        "for s in range(args.start_seed, args.end_seed+1):\n",
        "    logger.set_seed(s)\n",
        "\n",
        "    detector = Detector(model_wrapper, all_train_stats, loader, logger, params, (scaler, reducer, all_estimators, args.cov_estimator), use_val=args.use_val , dataset=args.dataset , seed=s)\n",
        "    if args.baseline:\n",
        "      detector.test_baseline_PPL(args.fpr_threshold)\n",
        "    else:\n",
        "      roc, tpr_at_fpr, metrics_dict,conf, testset = detector.test(args.fpr_threshold, args.pkl_test_path)\n",
        "\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "# Convert metrics_dict to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict.items(), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)\n",
        "metrics_df.to_csv(datasetname+'roberta_test_data_evaluation_metrics.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OchgEXe7esBa"
      },
      "outputs": [],
      "source": [
        "type(feats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXWafhzseeIF"
      },
      "source": [
        "##BERT SST2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt4x0JLGYF9_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pdb\n",
        "import glob\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define input variables\n",
        "dataset = \"sst2\"\n",
        "datasetname=\"sst2\"\n",
        "preprocess = \"standard\"\n",
        "data_type = \"standard\"\n",
        "target_model = \"textattack/bert-base-uncased-SST-2\"\n",
        "model_type = None  # Fill in the desired value\n",
        "use_state_dict = False\n",
        "data_root_dir = 'attack-log/original'\n",
        "scenario = None  # Fill in the desired value\n",
        "include_fae = False\n",
        "unbalanced = False\n",
        "use_val = False\n",
        "cov_estimator = None  # Fill in the desired value\n",
        "pkl_test_path = \" \"\n",
        "pkl_val_path = \" \"\n",
        "attack_type = 'textfooler'\n",
        "exp_name = 'tmp'\n",
        "fpr_threshold = 0.10\n",
        "compute_bootstrap = False\n",
        "baseline = False\n",
        "visualize = False\n",
        "tune_params = False\n",
        "model_params_path = \"params/attention_key-exclude.json\"\n",
        "PCA_dim = None\n",
        "MCD_h = None\n",
        "ensemble = False\n",
        "adapt_ckpt = None\n",
        "gpu = '0'\n",
        "start_seed = 0\n",
        "end_seed = 0\n",
        "mnli_option = \"matched\"\n",
        "\n",
        "# Import libraries and modules\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "\n",
        "\n",
        "model_type = target_model.replace(\"/\", \"-\")\n",
        "if exp_name:\n",
        "    log_path = f\"runs/{dataset}/{exp_name}/{model_type}/{attack_type}\"\n",
        "else:\n",
        "    log_path = f\"runs/{dataset}/{model_type}/{attack_type}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.isdir(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "\n",
        "\n",
        "input_variables = {\n",
        "    \"dataset\": dataset,\n",
        "    \"preprocess\": \"standard\",\n",
        "    \"data_type\": \"standard\",\n",
        "    \"target_model\": target_model,\n",
        "    \"model_type\": None,  # Fill in the desired value\n",
        "    \"use_state_dict\": False,\n",
        "    \"data_root_dir\": 'attack-log/original',\n",
        "    \"scenario\": None,  # Fill in the desired value\n",
        "    \"include_fae\": False,\n",
        "    \"unbalanced\": False,\n",
        "    \"use_val\": False,\n",
        "    \"cov_estimator\": None,  # Fill in the desired value\n",
        "    \"pkl_test_path\": \" \",\n",
        "    \"pkl_val_path\": \" \",\n",
        "    \"attack_type\": 'textfooler',\n",
        "    \"exp_name\": 'tmp',\n",
        "    \"fpr_threshold\": 0.10,\n",
        "    \"compute_bootstrap\": False,\n",
        "    \"baseline\": False,\n",
        "    \"visualize\": False,\n",
        "    \"tune_params\": False,\n",
        "    \"model_params_path\": \"params/reduce_dim_100.json\",\n",
        "    \"PCA_dim\": None,\n",
        "    \"MCD_h\": None,\n",
        "    \"ensemble\": False,\n",
        "    \"adapt_ckpt\": None,\n",
        "    \"gpu\": '0',\n",
        "    \"start_seed\": 0,\n",
        "    \"end_seed\": 0,\n",
        "    \"mnli_option\": \"matched\"\n",
        "}\n",
        "\n",
        "    # Rest of the code remains unchanged\n",
        "logger = Logger('logs/')\n",
        "logger.log.info(input_variables)\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._dict = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._dict:\n",
        "            return self._dict[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "args=DotDict(input_variables)\n",
        "import transformers\n",
        "model_wrapper = BertWrapper(args, logger)\n",
        "model = model_wrapper.model\n",
        "tokenizer = model_wrapper.tokenizer\n",
        "\n",
        "model_name=target_model\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "clean_labels=np.zeros(len(clean_df))\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['sentence']\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "adv_labels=np.ones(len(adv_df))\n",
        "\n",
        "train_data = np.concatenate((org_text, adv_text), axis=0)\n",
        "train_labels = np.concatenate((clean_labels, adv_labels), axis=0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dict = {\n",
        "    'text_key': org_text,\n",
        "    'label': clean_df['label']\n",
        "}\n",
        "with open(args.model_params_path, \"r\") as r:\n",
        "    params = json.load(r)\n",
        "    if args.PCA_dim:\n",
        "       params['reduce_dim']['dim'] = args.PCA_dim\n",
        "    if args.MCD_h:\n",
        "        params['h'] = float(args.MCD_h)\n",
        "    num_params = len(glob.glob(os.path.join('logs/', \"*.json\")))\n",
        "\n",
        "# Create a DataFrame\n",
        "train_dataframe = pd.DataFrame(data_dict)\n",
        "traind, testd, y_train, y_test = train_test_split(train_dataframe,train_dataframe['label'], stratify=train_dataframe['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "feats = get_train_features(model_wrapper, args, batch_size=100, dataset=traind, text_key=y_train,\n",
        "                             layer=params['layer_param']['cls_layer'])\n",
        "type(feats)\n",
        "if(isinstance(feats,list)):\n",
        "  feats=feats[0]\n",
        "\n",
        "feats=feats.detach().numpy()\n",
        "reduced_feat, labels, reducer, scaler = preprocess_features(feats, params, args, logger)\n",
        "print(reduced_feat)\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "train_stats, estimators = get_stats(reduced_feat, labels, cov_estim_name=args.cov_estimator, use_shared_cov=params['shared_cov'], params=params)\n",
        "naive_train_stats, naive_estimators = get_stats(reduced_feat, labels, cov_estim_name=\"None\", use_shared_cov=params['shared_cov'])\n",
        "all_train_stats = [naive_train_stats, train_stats]\n",
        "all_estimators = [naive_estimators, estimators]\n",
        "if args.visualize:\n",
        "    dir_name = os.path.dirname(args.log_path)\n",
        "    path_to_feat = os.path.join(dir_name, 'feats.txt')\n",
        "    feat_n_label = np.concatenate([reduced_feat, labels[:,np.newaxis]], axis=-1)\n",
        "    np.savetxt(path_to_feat, feat_n_label)\n",
        "    for cls_idx, mu_n_cov in enumerate(train_stats):\n",
        "      np.save(os.path.join(dir_name, f\"cls{cls_idx}-cov.npy\"), mu_n_cov[1])\n",
        "\n",
        "    for name, stat in zip(['naive', 'robust'], all_train_stats):\n",
        "      for idx, (mu, cov) in enumerate(stat):\n",
        "        spectrum = np.linalg.eigvals(cov)\n",
        "        path_to_csv = os.path.join(os.path.dirname(args.log_path), 'spectrum.csv')\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "          wr = csv.writer(f)\n",
        "          wr.writerow([name, max(spectrum), min(spectrum)])\n",
        "        kappa = max(spectrum) / min(spectrum)\n",
        "        plt.matshow(cov)\n",
        "        plt.title(f\"Cond.:{kappa:.3e} Max:{max(spectrum):.3e} Min: {min(spectrum):.3e}\")\n",
        "        cb = plt.colorbar()\n",
        "        cb.ax.tick_params(labelsize=14)\n",
        "        plt.savefig(os.path.join(os.path.dirname(args.log_path), f\"{name}-cls{idx}.png\"))\n",
        "    exit()\n",
        "loader = pd.DataFrame()\n",
        "loader['text'] = np.concatenate([adv_text, testd['text_key']])\n",
        "loader['result_type']=np.concatenate([np.ones(len(adv_text)), np.zeros(len(testd['text_key']))])\n",
        "\n",
        "for s in range(args.start_seed, args.end_seed+1):\n",
        "    logger.set_seed(s)\n",
        "\n",
        "    detector = Detector(model_wrapper, all_train_stats, loader, logger, params, (scaler, reducer, all_estimators, args.cov_estimator), use_val=args.use_val , dataset=args.dataset , seed=s)\n",
        "    if args.baseline:\n",
        "      detector.test_baseline_PPL(args.fpr_threshold)\n",
        "    else:\n",
        "      roc, tpr_at_fpr, metrics_dict,conf, testset = detector.test(args.fpr_threshold, args.pkl_test_path)\n",
        "\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "# Convert metrics_dict to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict.items(), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)\n",
        "metrics_df.to_csv(datasetname+'bert_test_data_evaluation_metrics.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK8gH6IYoTwy"
      },
      "source": [
        "##SST2 ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4oZHw8laDfL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pdb\n",
        "import glob\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define input variables\n",
        "dataset = \"sst2\"\n",
        "datasetname=\"sst2\"\n",
        "preprocess = \"standard\"\n",
        "data_type = \"standard\"\n",
        "target_model = \"textattack/roberta-base-SST-2\"\n",
        "model_type = None  # Fill in the desired value\n",
        "use_state_dict = False\n",
        "data_root_dir = 'attack-log/original'\n",
        "scenario = None  # Fill in the desired value\n",
        "include_fae = False\n",
        "unbalanced = False\n",
        "use_val = False\n",
        "cov_estimator = None  # Fill in the desired value\n",
        "pkl_test_path = \" \"\n",
        "pkl_val_path = \" \"\n",
        "attack_type = 'textfooler'\n",
        "exp_name = 'tmp'\n",
        "fpr_threshold = 0.10\n",
        "compute_bootstrap = False\n",
        "baseline = False\n",
        "visualize = False\n",
        "tune_params = False\n",
        "model_params_path = \"params/attention_key-exclude.json\"\n",
        "PCA_dim = None\n",
        "MCD_h = None\n",
        "ensemble = False\n",
        "adapt_ckpt = None\n",
        "gpu = '0'\n",
        "start_seed = 0\n",
        "end_seed = 0\n",
        "mnli_option = \"matched\"\n",
        "\n",
        "# Import libraries and modules\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "\n",
        "\n",
        "model_type = target_model.replace(\"/\", \"-\")\n",
        "if exp_name:\n",
        "    log_path = f\"runs/{dataset}/{exp_name}/{model_type}/{attack_type}\"\n",
        "else:\n",
        "    log_path = f\"runs/{dataset}/{model_type}/{attack_type}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not os.path.isdir(log_path):\n",
        "        os.makedirs(log_path)\n",
        "\n",
        "\n",
        "\n",
        "input_variables = {\n",
        "    \"dataset\": dataset,\n",
        "    \"preprocess\": \"standard\",\n",
        "    \"data_type\": \"standard\",\n",
        "    \"target_model\": target_model,\n",
        "    \"model_type\": None,  # Fill in the desired value\n",
        "    \"use_state_dict\": False,\n",
        "    \"data_root_dir\": 'attack-log/original',\n",
        "    \"scenario\": None,  # Fill in the desired value\n",
        "    \"include_fae\": False,\n",
        "    \"unbalanced\": False,\n",
        "    \"use_val\": False,\n",
        "    \"cov_estimator\": None,  # Fill in the desired value\n",
        "    \"pkl_test_path\": \" \",\n",
        "    \"pkl_val_path\": \" \",\n",
        "    \"attack_type\": 'textfooler',\n",
        "    \"exp_name\": 'tmp',\n",
        "    \"fpr_threshold\": 0.10,\n",
        "    \"compute_bootstrap\": False,\n",
        "    \"baseline\": False,\n",
        "    \"visualize\": False,\n",
        "    \"tune_params\": False,\n",
        "    \"model_params_path\": \"params/reduce_dim_100.json\",\n",
        "    \"PCA_dim\": None,\n",
        "    \"MCD_h\": None,\n",
        "    \"ensemble\": False,\n",
        "    \"adapt_ckpt\": None,\n",
        "    \"gpu\": '0',\n",
        "    \"start_seed\": 0,\n",
        "    \"end_seed\": 0,\n",
        "    \"mnli_option\": \"matched\"\n",
        "}\n",
        "\n",
        "    # Rest of the code remains unchanged\n",
        "logger = Logger('logs/')\n",
        "logger.log.info(input_variables)\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._dict = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._dict:\n",
        "            return self._dict[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "args=DotDict(input_variables)\n",
        "import transformers\n",
        "model_wrapper = BertWrapper(args, logger)\n",
        "model = model_wrapper.model\n",
        "tokenizer = model_wrapper.tokenizer\n",
        "\n",
        "model_name=target_model\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "clean_labels=np.zeros(len(clean_df))\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['sentence']\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "adv_labels=np.ones(len(adv_df))\n",
        "\n",
        "train_data = np.concatenate((org_text, adv_text), axis=0)\n",
        "train_labels = np.concatenate((clean_labels, adv_labels), axis=0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dict = {\n",
        "    'text_key': org_text,\n",
        "    'label': clean_df['label']\n",
        "}\n",
        "with open(args.model_params_path, \"r\") as r:\n",
        "    params = json.load(r)\n",
        "    if args.PCA_dim:\n",
        "       params['reduce_dim']['dim'] = args.PCA_dim\n",
        "    if args.MCD_h:\n",
        "        params['h'] = float(args.MCD_h)\n",
        "    num_params = len(glob.glob(os.path.join('logs/', \"*.json\")))\n",
        "\n",
        "# Create a DataFrame\n",
        "train_dataframe = pd.DataFrame(data_dict)\n",
        "traind, testd, y_train, y_test = train_test_split(train_dataframe,train_dataframe['label'], stratify=train_dataframe['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "feats = get_train_features(model_wrapper, args, batch_size=100, dataset=traind, text_key=y_train,\n",
        "                             layer=params['layer_param']['cls_layer'])\n",
        "type(feats)\n",
        "if(isinstance(feats,list)):\n",
        "  feats=feats[0]\n",
        "\n",
        "feats=feats.detach().numpy()\n",
        "reduced_feat, labels, reducer, scaler = preprocess_features(feats, params, args, logger)\n",
        "print(reduced_feat)\n",
        "from utils.detection import *\n",
        "from utils.dataset import *\n",
        "from utils.logger import *\n",
        "from utils.miscellaneous import *\n",
        "from models.wrapper import BertWrapper\n",
        "from Detector import Detector\n",
        "from AttackLoader import AttackLoader\n",
        "train_stats, estimators = get_stats(reduced_feat, labels, cov_estim_name=args.cov_estimator, use_shared_cov=params['shared_cov'], params=params)\n",
        "naive_train_stats, naive_estimators = get_stats(reduced_feat, labels, cov_estim_name=\"None\", use_shared_cov=params['shared_cov'])\n",
        "all_train_stats = [naive_train_stats, train_stats]\n",
        "all_estimators = [naive_estimators, estimators]\n",
        "if args.visualize:\n",
        "    dir_name = os.path.dirname(args.log_path)\n",
        "    path_to_feat = os.path.join(dir_name, 'feats.txt')\n",
        "    feat_n_label = np.concatenate([reduced_feat, labels[:,np.newaxis]], axis=-1)\n",
        "    np.savetxt(path_to_feat, feat_n_label)\n",
        "    for cls_idx, mu_n_cov in enumerate(train_stats):\n",
        "      np.save(os.path.join(dir_name, f\"cls{cls_idx}-cov.npy\"), mu_n_cov[1])\n",
        "\n",
        "    for name, stat in zip(['naive', 'robust'], all_train_stats):\n",
        "      for idx, (mu, cov) in enumerate(stat):\n",
        "        spectrum = np.linalg.eigvals(cov)\n",
        "        path_to_csv = os.path.join(os.path.dirname(args.log_path), 'spectrum.csv')\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "          wr = csv.writer(f)\n",
        "          wr.writerow([name, max(spectrum), min(spectrum)])\n",
        "        kappa = max(spectrum) / min(spectrum)\n",
        "        plt.matshow(cov)\n",
        "        plt.title(f\"Cond.:{kappa:.3e} Max:{max(spectrum):.3e} Min: {min(spectrum):.3e}\")\n",
        "        cb = plt.colorbar()\n",
        "        cb.ax.tick_params(labelsize=14)\n",
        "        plt.savefig(os.path.join(os.path.dirname(args.log_path), f\"{name}-cls{idx}.png\"))\n",
        "    exit()\n",
        "loader = pd.DataFrame()\n",
        "loader['text'] = np.concatenate([adv_text, testd['text_key']])\n",
        "loader['result_type']=np.concatenate([np.ones(len(adv_text)), np.zeros(len(testd['text_key']))])\n",
        "\n",
        "for s in range(args.start_seed, args.end_seed+1):\n",
        "    logger.set_seed(s)\n",
        "\n",
        "    detector = Detector(model_wrapper, all_train_stats, loader, logger, params, (scaler, reducer, all_estimators, args.cov_estimator), use_val=args.use_val , dataset=args.dataset , seed=s)\n",
        "    if args.baseline:\n",
        "      detector.test_baseline_PPL(args.fpr_threshold)\n",
        "    else:\n",
        "      roc, tpr_at_fpr, metrics_dict,conf, testset = detector.test(args.fpr_threshold, args.pkl_test_path)\n",
        "\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "# Convert metrics_dict to a DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict.items(), columns=['Metric', 'Value'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(metrics_df)\n",
        "metrics_df.to_csv(datasetname+'roberta_test_data_evaluation_metrics.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1O6Ztn7Ooy5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!git clone https://github.com/huberl/adversarial_shap_detect_Repl4NLP.git '/content/gdrive/My Drive/SHAPeLY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSq0RhvMO7we"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(f'/content/gdrive/My Drive/SHAPeLY/src/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk0cRL8AO_8K"
      },
      "outputs": [],
      "source": [
        "%cd '/content/gdrive/My Drive/SHAPeLY/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzzTuS1DPGmu"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1R5go46PKc1"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install textattack\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IShd6KNI9Um"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULtorReePOcS"
      },
      "outputs": [],
      "source": [
        "%cd '/content/gdrive/My Drive/SHAPeLY/src'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qHls7UNPRdR"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "from time import strftime\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap as shap\n",
        "import torch\n",
        "import transformers\n",
        "from textattack.models.helpers import LSTMForClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "logging.root.handlers = []\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
        "    level=logging.INFO,\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler('logs/log_{}.log'.format(strftime('%d-%m-%Y-%T'))),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "\n",
        "#def create_SHAP_signatures(model_name, dset_name, save_name=None):\n",
        "\n",
        "\n",
        "def parse_csv(csv_path):\n",
        "    project_dir = Path(__file__).resolve().parents[2]\n",
        "    df = pd.read_csv(os.path.join(project_dir, csv_path))\n",
        "\n",
        "    # Only return texts corresponding to successfull attacks\n",
        "    df = df.loc[df['result_type'] == 'Successful']\n",
        "    return df\n",
        "\n",
        "def pad_seq(seq, pad_len=512, pad_token=0):\n",
        "    return np.pad(seq[:pad_len], ((0, pad_len - seq[:pad_len].shape[0]), (0, 0)), 'constant',\n",
        "                  constant_values=pad_token)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx79QI4-KTkr"
      },
      "source": [
        "#SHAPLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaH8_Ag6s2Dv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!git clone https://github.com/huberl/adversarial_shap_detect_Repl4NLP.git '/content/gdrive/My Drive/SHAPeLY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD12rcCys2D7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(f'/content/gdrive/My Drive/SHAPeLY/src/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKBvfOtGs2D7"
      },
      "outputs": [],
      "source": [
        "%cd '/content/gdrive/My Drive/SHAPeLY/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zel8MtUs2D7"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68Q-NH1bs2D7"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install textattack\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnxU3FRAs2D7"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_U7BWIds2D7"
      },
      "outputs": [],
      "source": [
        "%cd '/content/gdrive/My Drive/SHAPeLY/src'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxJl2uTws2D7"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "from time import strftime\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shap as shap\n",
        "import torch\n",
        "import transformers\n",
        "from textattack.models.helpers import LSTMForClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "logging.root.handlers = []\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
        "    level=logging.INFO,\n",
        "    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "    handlers=[\n",
        "        logging.FileHandler('logs/log_{}.log'.format(strftime('%d-%m-%Y-%T'))),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/Dataset_Comparison'\n",
        "\n",
        "#def create_SHAP_signatures(model_name, dset_name, save_name=None):\n",
        "\n",
        "\n",
        "def parse_csv(csv_path):\n",
        "    project_dir = Path(__file__).resolve().parents[2]\n",
        "    df = pd.read_csv(os.path.join(project_dir, csv_path))\n",
        "\n",
        "    # Only return texts corresponding to successfull attacks\n",
        "    df = df.loc[df['result_type'] == 'Successful']\n",
        "    return df\n",
        "\n",
        "def pad_seq(seq, pad_len=512, pad_token=0):\n",
        "    return np.pad(seq[:pad_len], ((0, pad_len - seq[:pad_len].shape[0]), (0, 0)), 'constant',\n",
        "                  constant_values=pad_token)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD6ZhAmts2D7"
      },
      "source": [
        "##BERT IMBD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6GG9LJXWbXY"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import pickle,csv\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from pathlib import Path\n",
        "Path('data/SHAP_signatures/normal/').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/SHAP_signatures/adversarial/').mkdir(parents=True, exist_ok=True)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/Dataset_Comparison'\n",
        "logger.info('BERT + IMDB')\n",
        "datasetname='imdb'\n",
        "model_name='textattack/bert-base-uncased-imdb'\n",
        "save_name='bert_imdb'\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "if model_name.startswith('lstm'):\n",
        "    model = LSTMForClassification.from_pretrained(model_name)\n",
        "    tokenizer = model.tokenizer\n",
        "    masker = shap.maskers.Text(r\"\\W\")\n",
        "\n",
        "    def f(x):\n",
        "        tv = torch.tensor(\n",
        "            [tokenizer.encode(v) for v in x]).cuda()\n",
        "        model.cuda()\n",
        "        outputs = model(tv).detach().cpu().numpy()  # Remove [0] for LSTM\n",
        "        out = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "        #val = sp.special.logit(scores)\n",
        "        return out\n",
        "elif model_name.startswith('textattack'):   # Huggingface transformer\n",
        "    def f(x_batch):\n",
        "          tv = torch.tensor(\n",
        "              [tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x_batch]).cuda()\n",
        "          outputs = model(tv)[0].detach().cpu().numpy()\n",
        "          return (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    masker = tokenizer\n",
        "    # Indexing error is thrown at shap: _partition explain_row(). Seems like this does not matter\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "batch_size = 100\n",
        "shap_values_org={}\n",
        "shap_values_adv={}\n",
        "explainer = shap.Explainer(f, masker)\n",
        "org_data_path = 'data/SHAP_signatures/normal/'  # Specify your path here\n",
        "shap_values_org = np.empty(0, dtype=object)\n",
        "for i in range(0, len(org_text.to_list()), batch_size):\n",
        "    org_save_path = os.path.join(org_data_path, f'{save_name}_shap_values_org{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(org_save_path):\n",
        "        print(\"org Batch ID \", i)\n",
        "        batch = org_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_org = np.concatenate((shap_values_org, shap_values))\n",
        "        with open(org_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_org, file)\n",
        "\n",
        "        logging.info(f'Successfully saved orgersarial SHAP values to {org_save_path}')\n",
        "    else:\n",
        "        with open(org_save_path, 'rb') as file:\n",
        "              shap_values_org = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "# FOR ADVERSARIAL\n",
        "# Initialize shap_values_adv\n",
        "shap_values_adv = np.empty(0, dtype=object)\n",
        "adv_data_path = 'data/SHAP_signatures/adversarial/'  # Specify your path here\n",
        "\n",
        "for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "    adv_save_path = os.path.join(adv_data_path, f'{save_name}_shap_values_adv{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(adv_save_path):\n",
        "        print(\"Adv Batch ID \", i)\n",
        "        batch = adv_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_adv = np.concatenate((shap_values_adv, shap_values))\n",
        "        with open(adv_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_adv, file)\n",
        "\n",
        "        logging.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "    else:\n",
        "        with open(adv_save_path, 'rb') as file:\n",
        "              shap_values_adv = pickle.load(file)\n",
        "\n",
        "\n",
        "common_len = 512\n",
        "shap_values_adv_values = [explanation.values for explanation in shap_values_adv]\n",
        "shap_values_org_values = [explanation.values for explanation in shap_values_org]\n",
        "\n",
        "shap_vals_org = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_org_values]).reshape(-1, num_classes * common_len)\n",
        "shap_vals_adv = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_adv_values]).reshape(-1, num_classes * common_len)\n",
        "\n",
        "logger.info(f'Created {len(shap_vals_org)} original SHAP values with shape {shap_vals_org.shape} for {dset_name}')\n",
        "logger.info(f'Created {len(shap_vals_adv)} adversarial SHAP values with shape {shap_vals_adv.shape} for {dset_name}')\n",
        "\n",
        "\n",
        "org_save_path = f'data/SHAP_signatures/normal/{save_name}_shap_values_padded_org.npy'\n",
        "with open(org_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_org, f)\n",
        "\n",
        "logger.info(f'Successfully saved original SHAP values to {org_save_path}')\n",
        "\n",
        "\n",
        "# Save the shap_values_adv array using pickle\n",
        "adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_padded_adv.pkl'\n",
        "with open(adv_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_adv, f)\n",
        "logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "\n",
        "def label_attack(row):\n",
        "     if row['attack'].upper()=='NO':\n",
        "         return 0\n",
        "     else:\n",
        "         return 1\n",
        "\n",
        "\n",
        "\n",
        "data = np.concatenate((shap_vals_org, shap_vals_adv))\n",
        "org_labels = np.zeros(len(shap_vals_org), dtype=np.int16)\n",
        "adv_labels = np.ones(len(shap_vals_adv), dtype=np.int16)\n",
        "print(len(org_labels))\n",
        "print(len(adv_labels))\n",
        "labels = np.concatenate((org_labels, adv_labels))\n",
        "attack = np.concatenate((attack_org, attack_adv))\n",
        "\n",
        "# Create a dictionary with the columns\n",
        "df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(data.shape[1])])\n",
        "\n",
        "# Add attack and labels columns\n",
        "df['attack']=attack\n",
        "df['labels']=labels\n",
        "dropcol=['attack','labels']\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "specific_attacks=['No','bae','deepwordbug','pwws']\n",
        "traind, testd, y_train, y_test = train_test_split(\n",
        "            traindata, labels, stratify=traindata['attack'], test_size=0.30, random_state=42)\n",
        "\n",
        "        # Create a mask to filter specific attack types\n",
        "training_mask=traind['dataset_type'].isin(['test'])\n",
        "testdataclean=traind[training_mask]\n",
        "        #Train data only can training dataset, and specific training attacks\n",
        "traind=traind[~training_mask]  #No data is just train dataset\n",
        "\n",
        "mask = traind['attack'].isin(specific_attacks)\n",
        "\n",
        "        # Create separate dataframes for specific attacks and others\n",
        "test_df = traind[~mask] # all the attacks that are not in the traind\n",
        "traind = traind[mask]\n",
        "y_train = traind.apply(label_attack, axis=1)\n",
        "\n",
        "print(\"Training Attacks \",set(traind['attack']))\n",
        "print(\"Training set \",set(traind['dataset_type']))\n",
        "X_train = traind.drop(dropcol, axis=1)\n",
        "        # traindata=clean_dataset(traindata)\n",
        "X_train = X_train.fillna(0)\n",
        "X_train = np.float32(X_train)\n",
        "X_train = np.nan_to_num(\n",
        "            X_train, nan=-9999, posinf=33333333, neginf=33333333)\n",
        "\n",
        "testd = pd.concat([testd, test_df,testdataclean], axis=0, ignore_index=True)\n",
        "print(\"Testing set \",set(testd['dataset_type']))\n",
        "print(\"TEST Attacks \", set(testd['attack']))\n",
        "y_test=testd.apply(label_attack, axis=1)\n",
        "X_test = testd.drop(dropcol, axis=1)\n",
        "X_test = np.float32(X_test)\n",
        "X_test = np.nan_to_num(\n",
        "            X_test, nan=-9999, posinf=33333333, neginf=33333333)\n",
        "\n",
        "\n",
        "\n",
        "print(f'Size: {traind.shape}')\n",
        "\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(X_train, y_train)\n",
        "pkl_filename = 'models/'+save_name+'rf.pkl'\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(randomF, file)\n",
        "preds = randomF.predict(X_test)\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have defined y_test and preds\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "\n",
        "metrics_df.to_csv('models/'+save_name+'_test_data_evaluation_metrics.csv', index=False)\n",
        "Result_File='models/'+save_name+'Supervised_DetectorResult_Attack_wise.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['attack','labels'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = randomF.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrM5k0fSBpu6"
      },
      "source": [
        "##BERT YELP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyf8RQoJscqr"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maE442jwscr7"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9ZZGCWCBt1H"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import pickle,csv\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from pathlib import Path\n",
        "Path('data/SHAP_signatures/normal/').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/SHAP_signatures/adversarial/').mkdir(parents=True, exist_ok=True)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "\n",
        "logger.info('BERT + YELP')\n",
        "datasetname='yelp_polarity'\n",
        "model_name='textattack/bert-base-uncased-'+'yelp-polarity'\n",
        "save_name='bert_yelp'\n",
        "dset_name=datasetname\n",
        "\n",
        "print('filename ',savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "if model_name.startswith('lstm'):\n",
        "    model = LSTMForClassification.from_pretrained(model_name)\n",
        "    tokenizer = model.tokenizer\n",
        "    masker = shap.maskers.Text(r\"\\W\")\n",
        "\n",
        "    def f(x):\n",
        "        tv = torch.tensor(\n",
        "            [tokenizer.encode(v) for v in x]).cuda()\n",
        "        model.cuda()\n",
        "        outputs = model(tv).detach().cpu().numpy()  # Remove [0] for LSTM\n",
        "        out = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "        #val = sp.special.logit(scores)\n",
        "        return out\n",
        "elif model_name.startswith('textattack'):   # Huggingface transformer\n",
        "    def f(x_batch):\n",
        "          tv = torch.tensor(\n",
        "              [tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x_batch]).cuda()\n",
        "          outputs = model(tv)[0].detach().cpu().numpy()\n",
        "          return (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    masker = tokenizer\n",
        "    # Indexing error is thrown at shap: _partition explain_row(). Seems like this does not matter\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "batch_size = 100\n",
        "shap_values_org={}\n",
        "shap_values_adv={}\n",
        "explainer = shap.Explainer(f, masker)\n",
        "org_data_path = 'data/SHAP_signatures/normal/'  # Specify your path here\n",
        "shap_values_org = np.empty(0, dtype=object)\n",
        "for i in range(0, len(org_text.to_list()), batch_size):\n",
        "    org_save_path = os.path.join(org_data_path, f'{save_name}_shap_values_org{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(org_save_path):\n",
        "        print(\"org Batch ID \", i)\n",
        "        batch = org_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_org = np.concatenate((shap_values_org, shap_values))\n",
        "        with open(org_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_org, file)\n",
        "\n",
        "        logging.info(f'Successfully saved orgersarial SHAP values to {org_save_path}')\n",
        "    else:\n",
        "        with open(org_save_path, 'rb') as file:\n",
        "              shap_values_org = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# FOR ADVERSARIAL\n",
        "# Initialize shap_values_adv\n",
        "shap_values_adv = np.empty(0, dtype=object)\n",
        "adv_data_path = 'data/SHAP_signatures/adversarial/'  # Specify your path here\n",
        "\n",
        "for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "    adv_save_path = os.path.join(adv_data_path, f'{save_name}_shap_values_adv{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(adv_save_path):\n",
        "        print(\"Adv Batch ID \", i)\n",
        "        batch = adv_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_adv = np.concatenate((shap_values_adv, shap_values))\n",
        "        with open(adv_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_adv, file)\n",
        "\n",
        "        logging.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "    else:\n",
        "        with open(adv_save_path, 'rb') as file:\n",
        "              shap_values_adv = pickle.load(file)\n",
        "\n",
        "# for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "#       if not os.path.exists('data/SHAP_signatures/adversarial/'+save_name+'_shap_values_adv'+str(i)+'.npy'):\n",
        "#         print(\"Adv Batch ID \", i)\n",
        "#         batch = adv_text.to_list()[i:i+batch_size]\n",
        "#         shap_values = explainer(batch)\n",
        "#         for idx, shap_val in enumerate(shap_values):\n",
        "#                shap_values_adv[i + idx] = shap_values\n",
        "#         adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_adv'+str(i)+'.npy'\n",
        "#         np.save(adv_save_path, shap_values_adv)\n",
        "#         logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "#       else:\n",
        "#            shap_values_adv=np.load('data/SHAP_signatures/adversarial/'+save_name+'_shap_values_adv'+str(i)+'.npy',allow_pickle=True)\n",
        "\n",
        "common_len = 512\n",
        "shap_values_adv_values = [explanation.values for explanation in shap_values_adv]\n",
        "shap_values_org_values = [explanation.values for explanation in shap_values_org]\n",
        "\n",
        "shap_vals_org = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_org_values]).reshape(-1, num_classes * common_len)\n",
        "shap_vals_adv = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_adv_values]).reshape(-1, num_classes * common_len)\n",
        "\n",
        "logger.info(f'Created {len(shap_vals_org)} original SHAP values with shape {shap_vals_org.shape} for {dset_name}')\n",
        "logger.info(f'Created {len(shap_vals_adv)} adversarial SHAP values with shape {shap_vals_adv.shape} for {dset_name}')\n",
        "\n",
        "\n",
        "org_save_path = f'data/SHAP_signatures/normal/{save_name}_shap_values_padded_org.npy'\n",
        "with open(org_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_org, f)\n",
        "\n",
        "logger.info(f'Successfully saved original SHAP values to {org_save_path}')\n",
        "\n",
        "\n",
        "# Save the shap_values_adv array using pickle\n",
        "adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_padded_adv.pkl'\n",
        "with open(adv_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_adv, f)\n",
        "logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = np.concatenate((shap_vals_org, shap_vals_adv))\n",
        "org_labels = np.zeros(len(shap_vals_org), dtype=np.int16)\n",
        "adv_labels = np.ones(len(shap_vals_adv), dtype=np.int16)\n",
        "print(len(org_labels))\n",
        "print(len(adv_labels))\n",
        "labels = np.concatenate((org_labels, adv_labels))\n",
        "attack = np.concatenate((attack_org, attack_adv))\n",
        "\n",
        "# Create a dictionary with the columns\n",
        "df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(data.shape[1])])\n",
        "\n",
        "# Add attack and labels columns\n",
        "df['attack']=attack\n",
        "df['labels']=labels\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "\n",
        "traind, testd, y_train, y_test = train_test_split(df, df['labels'], stratify=df['attack'], test_size=0.2, random_state=42)\n",
        "X_train=traind.drop(columns=['attack','labels'])\n",
        "X_test=testd.drop(columns=['attack','labels'])\n",
        "\n",
        "print(f'Size: {traind.shape}')\n",
        "\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(X_train, y_train)\n",
        "pkl_filename = 'models/'+save_name+'rf.pkl'\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(randomF, file)\n",
        "preds = randomF.predict(X_test)\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have defined y_test and preds\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "\n",
        "metrics_df.to_csv('models/'+save_name+'_test_data_evaluation_metrics.csv', index=False)\n",
        "Result_File='models/'+save_name+'Supervised_DetectorResult_Attack_wise.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['attack','labels'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = randomF.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzd2XY7i6iel"
      },
      "source": [
        "##BERT AG_NEWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFmvrZcWJyTu"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import pickle,csv\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from pathlib import Path\n",
        "Path('data/SHAP_signatures/normal/').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/SHAP_signatures/adversarial/').mkdir(parents=True, exist_ok=True)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "\n",
        "logger.info('BERT + AGNEWS')\n",
        "datasetname='ag_news'\n",
        "model_name='textattack/bert-base-uncased-'+'ag-news'\n",
        "save_name='bert_agnews'\n",
        "dset_name=datasetname\n",
        "\n",
        "print('filename ',savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "if model_name.startswith('lstm'):\n",
        "    model = LSTMForClassification.from_pretrained(model_name)\n",
        "    tokenizer = model.tokenizer\n",
        "    masker = shap.maskers.Text(r\"\\W\")\n",
        "\n",
        "    def f(x):\n",
        "        tv = torch.tensor(\n",
        "            [tokenizer.encode(v) for v in x]).cuda()\n",
        "        model.cuda()\n",
        "        outputs = model(tv).detach().cpu().numpy()  # Remove [0] for LSTM\n",
        "        out = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "        #val = sp.special.logit(scores)\n",
        "        return out\n",
        "elif model_name.startswith('textattack'):   # Huggingface transformer\n",
        "    def f(x_batch):\n",
        "          tv = torch.tensor(\n",
        "              [tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x_batch]).cuda()\n",
        "          outputs = model(tv)[0].detach().cpu().numpy()\n",
        "          return (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    masker = tokenizer\n",
        "    # Indexing error is thrown at shap: _partition explain_row(). Seems like this does not matter\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "batch_size = 100\n",
        "shap_values_org={}\n",
        "shap_values_adv={}\n",
        "explainer = shap.Explainer(f, masker)\n",
        "org_data_path = 'data/SHAP_signatures/normal/'  # Specify your path here\n",
        "shap_values_org = np.empty(0, dtype=object)\n",
        "for i in range(0, len(org_text.to_list()), batch_size):\n",
        "    org_save_path = os.path.join(org_data_path, f'{save_name}_shap_values_org{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(org_save_path):\n",
        "        print(\"org Batch ID \", i)\n",
        "        batch = org_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_org = np.concatenate((shap_values_org, shap_values))\n",
        "        with open(org_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_org, file)\n",
        "\n",
        "        logging.info(f'Successfully saved orgersarial SHAP values to {org_save_path}')\n",
        "    else:\n",
        "        with open(org_save_path, 'rb') as file:\n",
        "              shap_values_org = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# FOR ADVERSARIAL\n",
        "# Initialize shap_values_adv\n",
        "shap_values_adv = np.empty(0, dtype=object)\n",
        "adv_data_path = 'data/SHAP_signatures/adversarial/'  # Specify your path here\n",
        "\n",
        "for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "    adv_save_path = os.path.join(adv_data_path, f'{save_name}_shap_values_adv{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(adv_save_path):\n",
        "        print(\"Adv Batch ID \", i)\n",
        "        batch = adv_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_adv = np.concatenate((shap_values_adv, shap_values))\n",
        "        with open(adv_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_adv, file)\n",
        "\n",
        "        logging.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "    else:\n",
        "        with open(adv_save_path, 'rb') as file:\n",
        "              shap_values_adv = pickle.load(file)\n",
        "\n",
        "# for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "#       if not os.path.exists('data/SHAP_signatures/adversarial/'+save_name+'_shap_values_adv'+str(i)+'.npy'):\n",
        "#         print(\"Adv Batch ID \", i)\n",
        "#         batch = adv_text.to_list()[i:i+batch_size]\n",
        "#         shap_values = explainer(batch)\n",
        "#         for idx, shap_val in enumerate(shap_values):\n",
        "#                shap_values_adv[i + idx] = shap_values\n",
        "#         adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_adv'+str(i)+'.npy'\n",
        "#         np.save(adv_save_path, shap_values_adv)\n",
        "#         logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "#       else:\n",
        "#            shap_values_adv=np.load('data/SHAP_signatures/adversarial/'+save_name+'_shap_values_adv'+str(i)+'.npy',allow_pickle=True)\n",
        "\n",
        "common_len = 512\n",
        "shap_values_adv_values = [explanation.values for explanation in shap_values_adv]\n",
        "shap_values_org_values = [explanation.values for explanation in shap_values_org]\n",
        "\n",
        "shap_vals_org = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_org_values]).reshape(-1, num_classes * common_len)\n",
        "shap_vals_adv = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_adv_values]).reshape(-1, num_classes * common_len)\n",
        "\n",
        "logger.info(f'Created {len(shap_vals_org)} original SHAP values with shape {shap_vals_org.shape} for {dset_name}')\n",
        "logger.info(f'Created {len(shap_vals_adv)} adversarial SHAP values with shape {shap_vals_adv.shape} for {dset_name}')\n",
        "\n",
        "\n",
        "org_save_path = f'data/SHAP_signatures/normal/{save_name}_shap_values_padded_org.npy'\n",
        "with open(org_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_org, f)\n",
        "\n",
        "logger.info(f'Successfully saved original SHAP values to {org_save_path}')\n",
        "\n",
        "\n",
        "# Save the shap_values_adv array using pickle\n",
        "adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_padded_adv.pkl'\n",
        "with open(adv_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_adv, f)\n",
        "logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = np.concatenate((shap_vals_org, shap_vals_adv))\n",
        "org_labels = np.zeros(len(shap_vals_org), dtype=np.int16)\n",
        "adv_labels = np.ones(len(shap_vals_adv), dtype=np.int16)\n",
        "print(len(org_labels))\n",
        "print(len(adv_labels))\n",
        "labels = np.concatenate((org_labels, adv_labels))\n",
        "attack = np.concatenate((attack_org, attack_adv))\n",
        "\n",
        "# Create a dictionary with the columns\n",
        "df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(data.shape[1])])\n",
        "\n",
        "# Add attack and labels columns\n",
        "df['attack']=attack\n",
        "df['labels']=labels\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "\n",
        "traind, testd, y_train, y_test = train_test_split(df, df['labels'], stratify=df['attack'], test_size=0.2, random_state=42)\n",
        "X_train=traind.drop(columns=['attack','labels'])\n",
        "X_test=testd.drop(columns=['attack','labels'])\n",
        "\n",
        "print(f'Size: {traind.shape}')\n",
        "\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(X_train, y_train)\n",
        "pkl_filename = 'models/'+save_name+'rf.pkl'\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(randomF, file)\n",
        "preds = randomF.predict(X_test)\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have defined y_test and preds\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "\n",
        "metrics_df.to_csv('models/'+save_name+'_test_data_evaluation_metrics.csv', index=False)\n",
        "Result_File='models/'+save_name+'Supervised_DetectorResult_Attack_wise.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['attack','labels'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = randomF.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h15M8O1-C6ky"
      },
      "source": [
        "##BERT SST2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xng_NAV1giEM"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import pickle,csv\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from pathlib import Path\n",
        "Path('data/SHAP_signatures/normal/').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/SHAP_signatures/adversarial/').mkdir(parents=True, exist_ok=True)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "\n",
        "logger.info('BERT + SST2')\n",
        "datasetname='sst2'\n",
        "model_name='textattack/bert-base-uncased-'+'SST-2'\n",
        "save_name='bert_sst2'\n",
        "dset_name=datasetname\n",
        "\n",
        "print('filename ',savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['sentence']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "if model_name.startswith('lstm'):\n",
        "    model = LSTMForClassification.from_pretrained(model_name)\n",
        "    tokenizer = model.tokenizer\n",
        "    masker = shap.maskers.Text(r\"\\W\")\n",
        "\n",
        "    def f(x):\n",
        "        tv = torch.tensor(\n",
        "            [tokenizer.encode(v) for v in x]).cuda()\n",
        "        model.cuda()\n",
        "        outputs = model(tv).detach().cpu().numpy()  # Remove [0] for LSTM\n",
        "        out = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "        #val = sp.special.logit(scores)\n",
        "        return out\n",
        "elif model_name.startswith('textattack'):   # Huggingface transformer\n",
        "    def f(x_batch):\n",
        "          tv = torch.tensor(\n",
        "              [tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x_batch]).cuda()\n",
        "          outputs = model(tv)[0].detach().cpu().numpy()\n",
        "          return (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    masker = tokenizer\n",
        "    # Indexing error is thrown at shap: _partition explain_row(). Seems like this does not matter\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "batch_size = 100\n",
        "shap_values_org={}\n",
        "shap_values_adv={}\n",
        "explainer = shap.Explainer(f, masker)\n",
        "org_data_path = 'data/SHAP_signatures/normal/'  # Specify your path here\n",
        "shap_values_org = np.empty(0, dtype=object)\n",
        "for i in range(0, len(org_text.to_list()), batch_size):\n",
        "    org_save_path = os.path.join(org_data_path, f'{save_name}_shap_values_org{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(org_save_path):\n",
        "        print(\"org Batch ID \", i)\n",
        "        batch = org_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_org = np.concatenate((shap_values_org, shap_values))\n",
        "        with open(org_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_org, file)\n",
        "\n",
        "        logging.info(f'Successfully saved orgersarial SHAP values to {org_save_path}')\n",
        "    else:\n",
        "        with open(org_save_path, 'rb') as file:\n",
        "              shap_values_org = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# FOR ADVERSARIAL\n",
        "# Initialize shap_values_adv\n",
        "shap_values_adv = np.empty(0, dtype=object)\n",
        "adv_data_path = 'data/SHAP_signatures/adversarial/'  # Specify your path here\n",
        "\n",
        "for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "    adv_save_path = os.path.join(adv_data_path, f'{save_name}_shap_values_adv{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(adv_save_path):\n",
        "        print(\"Adv Batch ID \", i)\n",
        "        batch = adv_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_adv = np.concatenate((shap_values_adv, shap_values))\n",
        "        with open(adv_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_adv, file)\n",
        "\n",
        "        logging.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "    else:\n",
        "        with open(adv_save_path, 'rb') as file:\n",
        "              shap_values_adv = pickle.load(file)\n",
        "\n",
        "# for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "#       if not os.path.exists('data/SHAP_signatures/adversarial/'+save_name+'_shap_values_adv'+str(i)+'.npy'):\n",
        "#         print(\"Adv Batch ID \", i)\n",
        "#         batch = adv_text.to_list()[i:i+batch_size]\n",
        "#         shap_values = explainer(batch)\n",
        "#         for idx, shap_val in enumerate(shap_values):\n",
        "#                shap_values_adv[i + idx] = shap_values\n",
        "#         adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_adv'+str(i)+'.npy'\n",
        "#         np.save(adv_save_path, shap_values_adv)\n",
        "#         logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "#       else:\n",
        "#            shap_values_adv=np.load('data/SHAP_signatures/adversarial/'+save_name+'_shap_values_adv'+str(i)+'.npy',allow_pickle=True)\n",
        "\n",
        "common_len = 512\n",
        "shap_values_adv_values = [explanation.values for explanation in shap_values_adv]\n",
        "shap_values_org_values = [explanation.values for explanation in shap_values_org]\n",
        "\n",
        "shap_vals_org = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_org_values]).reshape(-1, num_classes * common_len)\n",
        "shap_vals_adv = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_adv_values]).reshape(-1, num_classes * common_len)\n",
        "\n",
        "logger.info(f'Created {len(shap_vals_org)} original SHAP values with shape {shap_vals_org.shape} for {dset_name}')\n",
        "logger.info(f'Created {len(shap_vals_adv)} adversarial SHAP values with shape {shap_vals_adv.shape} for {dset_name}')\n",
        "\n",
        "\n",
        "org_save_path = f'data/SHAP_signatures/normal/{save_name}_shap_values_padded_org.npy'\n",
        "with open(org_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_org, f)\n",
        "\n",
        "logger.info(f'Successfully saved original SHAP values to {org_save_path}')\n",
        "\n",
        "\n",
        "# Save the shap_values_adv array using pickle\n",
        "adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_padded_adv.pkl'\n",
        "with open(adv_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_adv, f)\n",
        "logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = np.concatenate((shap_vals_org, shap_vals_adv))\n",
        "org_labels = np.zeros(len(shap_vals_org), dtype=np.int16)\n",
        "adv_labels = np.ones(len(shap_vals_adv), dtype=np.int16)\n",
        "print(len(org_labels))\n",
        "print(len(adv_labels))\n",
        "labels = np.concatenate((org_labels, adv_labels))\n",
        "attack = np.concatenate((attack_org, attack_adv))\n",
        "\n",
        "# Create a dictionary with the columns\n",
        "df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(data.shape[1])])\n",
        "\n",
        "# Add attack and labels columns\n",
        "df['attack']=attack\n",
        "df['labels']=labels\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "\n",
        "traind, testd, y_train, y_test = train_test_split(df, df['labels'], stratify=df['attack'], test_size=0.2, random_state=42)\n",
        "X_train=traind.drop(columns=['attack','labels'])\n",
        "X_test=testd.drop(columns=['attack','labels'])\n",
        "\n",
        "print(f'Size: {traind.shape}')\n",
        "\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(X_train, y_train)\n",
        "pkl_filename = 'models/'+save_name+'rf.pkl'\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(randomF, file)\n",
        "preds = randomF.predict(X_test)\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have defined y_test and preds\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "\n",
        "metrics_df.to_csv('models/'+save_name+'_test_data_evaluation_metrics.csv', index=False)\n",
        "Result_File='models/'+save_name+'Supervised_DetectorResult_Attack_wise.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['attack','labels'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = randomF.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1b3qyJwZsBl"
      },
      "source": [
        "## ROBERTA IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rV5OQ3G2UWf9"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import pickle,csv\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from pathlib import Path\n",
        "Path('data/SHAP_signatures/normal/').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/SHAP_signatures/adversarial/').mkdir(parents=True, exist_ok=True)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "logger.info('ROBERTA + IMDB')\n",
        "datasetname='imdb'\n",
        "model_name='textattack/roberta-base-imdb'\n",
        "save_name='roberta_imdb'\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "if model_name.startswith('lstm'):\n",
        "    model = LSTMForClassification.from_pretrained(model_name)\n",
        "    tokenizer = model.tokenizer\n",
        "    masker = shap.maskers.Text(r\"\\W\")\n",
        "\n",
        "    def f(x):\n",
        "        tv = torch.tensor(\n",
        "            [tokenizer.encode(v) for v in x]).cuda()\n",
        "        model.cuda()\n",
        "        outputs = model(tv).detach().cpu().numpy()  # Remove [0] for LSTM\n",
        "        out = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "        #val = sp.special.logit(scores)\n",
        "        return out\n",
        "elif model_name.startswith('textattack'):   # Huggingface transformer\n",
        "    def f(x_batch):\n",
        "          tv = torch.tensor(\n",
        "              [tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x_batch]).cuda()\n",
        "          outputs = model(tv)[0].detach().cpu().numpy()\n",
        "          return (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    masker = tokenizer\n",
        "    # Indexing error is thrown at shap: _partition explain_row(). Seems like this does not matter\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "batch_size = 100\n",
        "shap_values_org={}\n",
        "shap_values_adv={}\n",
        "explainer = shap.Explainer(f, masker)\n",
        "org_data_path = 'data/SHAP_signatures/normal/'  # Specify your path here\n",
        "shap_values_org = np.empty(0, dtype=object)\n",
        "for i in range(0, len(org_text.to_list()), batch_size):\n",
        "    org_save_path = os.path.join(org_data_path, f'{save_name}_shap_values_org{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(org_save_path):\n",
        "        print(\"org Batch ID \", i)\n",
        "        batch = org_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_org = np.concatenate((shap_values_org, shap_values))\n",
        "        with open(org_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_org, file)\n",
        "\n",
        "        logging.info(f'Successfully saved orgersarial SHAP values to {org_save_path}')\n",
        "    else:\n",
        "        with open(org_save_path, 'rb') as file:\n",
        "              shap_values_org = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "# FOR ADVERSARIAL\n",
        "# Initialize shap_values_adv\n",
        "shap_values_adv = np.empty(0, dtype=object)\n",
        "adv_data_path = 'data/SHAP_signatures/adversarial/'  # Specify your path here\n",
        "\n",
        "for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "    adv_save_path = os.path.join(adv_data_path, f'{save_name}_shap_values_adv{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(adv_save_path):\n",
        "        print(\"Adv Batch ID \", i)\n",
        "        batch = adv_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_adv = np.concatenate((shap_values_adv, shap_values))\n",
        "        with open(adv_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_adv, file)\n",
        "\n",
        "        logging.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "    else:\n",
        "        with open(adv_save_path, 'rb') as file:\n",
        "              shap_values_adv = pickle.load(file)\n",
        "\n",
        "\n",
        "common_len = 512\n",
        "shap_values_adv_values = [explanation.values for explanation in shap_values_adv]\n",
        "shap_values_org_values = [explanation.values for explanation in shap_values_org]\n",
        "\n",
        "shap_vals_org = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_org_values]).reshape(-1, num_classes * common_len)\n",
        "shap_vals_adv = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_adv_values]).reshape(-1, num_classes * common_len)\n",
        "\n",
        "logger.info(f'Created {len(shap_vals_org)} original SHAP values with shape {shap_vals_org.shape} for {dset_name}')\n",
        "logger.info(f'Created {len(shap_vals_adv)} adversarial SHAP values with shape {shap_vals_adv.shape} for {dset_name}')\n",
        "\n",
        "\n",
        "org_save_path = f'data/SHAP_signatures/normal/{save_name}_shap_values_padded_org.npy'\n",
        "with open(org_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_org, f)\n",
        "\n",
        "logger.info(f'Successfully saved original SHAP values to {org_save_path}')\n",
        "\n",
        "\n",
        "# Save the shap_values_adv array using pickle\n",
        "adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_padded_adv.pkl'\n",
        "with open(adv_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_adv, f)\n",
        "logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = np.concatenate((shap_vals_org, shap_vals_adv))\n",
        "org_labels = np.zeros(len(shap_vals_org), dtype=np.int16)\n",
        "adv_labels = np.ones(len(shap_vals_adv), dtype=np.int16)\n",
        "print(len(org_labels))\n",
        "print(len(adv_labels))\n",
        "labels = np.concatenate((org_labels, adv_labels))\n",
        "attack = np.concatenate((attack_org, attack_adv))\n",
        "\n",
        "# Create a dictionary with the columns\n",
        "df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(data.shape[1])])\n",
        "\n",
        "# Add attack and labels columns\n",
        "df['attack']=attack\n",
        "df['labels']=labels\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "\n",
        "traind, testd, y_train, y_test = train_test_split(df, df['labels'], stratify=df['attack'], test_size=0.2, random_state=42)\n",
        "X_train=traind.drop(columns=['attack','labels'])\n",
        "X_test=testd.drop(columns=['attack','labels'])\n",
        "\n",
        "print(f'Size: {traind.shape}')\n",
        "\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(X_train, y_train)\n",
        "pkl_filename = 'models/'+save_name+'rf.pkl'\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(randomF, file)\n",
        "preds = randomF.predict(X_test)\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have defined y_test and preds\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "\n",
        "metrics_df.to_csv('models/'+save_name+'_test_data_evaluation_metrics.csv', index=False)\n",
        "Result_File='models/'+save_name+'Supervised_DetectorResult_Attack_wise.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['attack','labels'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = randomF.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et0hnxkebwyU"
      },
      "source": [
        "##ROBERTA YELP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk9N1pJcpqj7"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import pickle,csv\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from pathlib import Path\n",
        "Path('data/SHAP_signatures/normal/').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/SHAP_signatures/adversarial/').mkdir(parents=True, exist_ok=True)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "logger.info('ROBERTA + YELP')\n",
        "datasetname='yelp_polarity'\n",
        "model_name='VictorSanh/roberta-base-finetuned-'+'yelp-polarity'\n",
        "save_name='roberta_yelp'\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "if model_name.startswith('lstm'):\n",
        "    model = LSTMForClassification.from_pretrained(model_name)\n",
        "    tokenizer = model.tokenizer\n",
        "    masker = shap.maskers.Text(r\"\\W\")\n",
        "\n",
        "    def f(x):\n",
        "        tv = torch.tensor(\n",
        "            [tokenizer.encode(v) for v in x]).cuda()\n",
        "        model.cuda()\n",
        "        outputs = model(tv).detach().cpu().numpy()  # Remove [0] for LSTM\n",
        "        out = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "        #val = sp.special.logit(scores)\n",
        "        return out\n",
        "else:   # Huggingface transformer\n",
        "    def f(x_batch):\n",
        "          tv = torch.tensor(\n",
        "              [tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x_batch]).cuda()\n",
        "          outputs = model(tv)[0].detach().cpu().numpy()\n",
        "          return (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    masker = tokenizer\n",
        "    # Indexing error is thrown at shap: _partition explain_row(). Seems like this does not matter\n",
        "batch_size = 100\n",
        "shap_values_org={}\n",
        "shap_values_adv={}\n",
        "explainer = shap.Explainer(f, masker)\n",
        "org_data_path = 'data/SHAP_signatures/normal/'  # Specify your path here\n",
        "shap_values_org = np.empty(0, dtype=object)\n",
        "for i in range(0, len(org_text.to_list()), batch_size):\n",
        "    org_save_path = os.path.join(org_data_path, f'{save_name}_shap_values_org{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(org_save_path):\n",
        "        print(\"org Batch ID \", i)\n",
        "        batch = org_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_org = np.concatenate((shap_values_org, shap_values))\n",
        "        with open(org_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_org, file)\n",
        "\n",
        "        logging.info(f'Successfully saved orgersarial SHAP values to {org_save_path}')\n",
        "    else:\n",
        "        with open(org_save_path, 'rb') as file:\n",
        "              shap_values_org = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "# FOR ADVERSARIAL\n",
        "# Initialize shap_values_adv\n",
        "shap_values_adv = np.empty(0, dtype=object)\n",
        "adv_data_path = 'data/SHAP_signatures/adversarial/'  # Specify your path here\n",
        "\n",
        "for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "    adv_save_path = os.path.join(adv_data_path, f'{save_name}_shap_values_adv{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(adv_save_path):\n",
        "        print(\"Adv Batch ID \", i)\n",
        "        batch = adv_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_adv = np.concatenate((shap_values_adv, shap_values))\n",
        "        with open(adv_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_adv, file)\n",
        "\n",
        "        logging.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "    else:\n",
        "        with open(adv_save_path, 'rb') as file:\n",
        "              shap_values_adv = pickle.load(file)\n",
        "\n",
        "\n",
        "common_len = 512\n",
        "shap_values_adv_values = [explanation.values for explanation in shap_values_adv]\n",
        "shap_values_org_values = [explanation.values for explanation in shap_values_org]\n",
        "\n",
        "shap_vals_org = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_org_values]).reshape(-1, num_classes * common_len)\n",
        "shap_vals_adv = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_adv_values]).reshape(-1, num_classes * common_len)\n",
        "\n",
        "logger.info(f'Created {len(shap_vals_org)} original SHAP values with shape {shap_vals_org.shape} for {dset_name}')\n",
        "logger.info(f'Created {len(shap_vals_adv)} adversarial SHAP values with shape {shap_vals_adv.shape} for {dset_name}')\n",
        "\n",
        "\n",
        "org_save_path = f'data/SHAP_signatures/normal/{save_name}_shap_values_padded_org.npy'\n",
        "with open(org_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_org, f)\n",
        "\n",
        "logger.info(f'Successfully saved original SHAP values to {org_save_path}')\n",
        "\n",
        "\n",
        "# Save the shap_values_adv array using pickle\n",
        "adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_padded_adv.pkl'\n",
        "with open(adv_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_adv, f)\n",
        "logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = np.concatenate((shap_vals_org, shap_vals_adv))\n",
        "org_labels = np.zeros(len(shap_vals_org), dtype=np.int16)\n",
        "adv_labels = np.ones(len(shap_vals_adv), dtype=np.int16)\n",
        "print(len(org_labels))\n",
        "print(len(adv_labels))\n",
        "labels = np.concatenate((org_labels, adv_labels))\n",
        "attack = np.concatenate((attack_org, attack_adv))\n",
        "\n",
        "# Create a dictionary with the columns\n",
        "df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(data.shape[1])])\n",
        "\n",
        "# Add attack and labels columns\n",
        "df['attack']=attack\n",
        "df['labels']=labels\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "\n",
        "traind, testd, y_train, y_test = train_test_split(df, df['labels'], stratify=df['attack'], test_size=0.2, random_state=42)\n",
        "X_train=traind.drop(columns=['attack','labels'])\n",
        "X_test=testd.drop(columns=['attack','labels'])\n",
        "\n",
        "print(f'Size: {traind.shape}')\n",
        "\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(X_train, y_train)\n",
        "pkl_filename = 'models/'+save_name+'rf.pkl'\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(randomF, file)\n",
        "preds = randomF.predict(X_test)\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have defined y_test and preds\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "\n",
        "metrics_df.to_csv('models/'+save_name+'_test_data_evaluation_metrics.csv', index=False)\n",
        "Result_File='models/'+save_name+'Supervised_DetectorResult_Attack_wise.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['attack','labels'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = randomF.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_W4xn-RtxBN"
      },
      "source": [
        "##ROBERTA SST2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWLqXUcmwcID"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import pickle,csv\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from pathlib import Path\n",
        "Path('data/SHAP_signatures/normal/').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/SHAP_signatures/adversarial/').mkdir(parents=True, exist_ok=True)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "logger.info('ROBERTA + sst2')\n",
        "datasetname='sst2'\n",
        "model_name='textattack/roberta-base-SST-2'\n",
        "save_name='roberta_sst2'\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['sentence']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "if model_name.startswith('lstm'):\n",
        "    model = LSTMForClassification.from_pretrained(model_name)\n",
        "    tokenizer = model.tokenizer\n",
        "    masker = shap.maskers.Text(r\"\\W\")\n",
        "\n",
        "    def f(x):\n",
        "        tv = torch.tensor(\n",
        "            [tokenizer.encode(v) for v in x]).cuda()\n",
        "        model.cuda()\n",
        "        outputs = model(tv).detach().cpu().numpy()  # Remove [0] for LSTM\n",
        "        out = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "        #val = sp.special.logit(scores)\n",
        "        return out\n",
        "elif model_name.startswith('textattack'):   # Huggingface transformer\n",
        "    def f(x_batch):\n",
        "          tv = torch.tensor(\n",
        "              [tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x_batch]).cuda()\n",
        "          outputs = model(tv)[0].detach().cpu().numpy()\n",
        "          return (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    masker = tokenizer\n",
        "    # Indexing error is thrown at shap: _partition explain_row(). Seems like this does not matter\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "batch_size = 100\n",
        "shap_values_org={}\n",
        "shap_values_adv={}\n",
        "explainer = shap.Explainer(f, masker)\n",
        "org_data_path = 'data/SHAP_signatures/normal/'  # Specify your path here\n",
        "shap_values_org = np.empty(0, dtype=object)\n",
        "for i in range(0, len(org_text.to_list()), batch_size):\n",
        "    org_save_path = os.path.join(org_data_path, f'{save_name}_shap_values_org{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(org_save_path):\n",
        "        print(\"org Batch ID \", i)\n",
        "        batch = org_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_org = np.concatenate((shap_values_org, shap_values))\n",
        "        with open(org_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_org, file)\n",
        "\n",
        "        logging.info(f'Successfully saved orgersarial SHAP values to {org_save_path}')\n",
        "    else:\n",
        "        with open(org_save_path, 'rb') as file:\n",
        "              shap_values_org = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "# FOR ADVERSARIAL\n",
        "# Initialize shap_values_adv\n",
        "shap_values_adv = np.empty(0, dtype=object)\n",
        "adv_data_path = 'data/SHAP_signatures/adversarial/'  # Specify your path here\n",
        "\n",
        "for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "    adv_save_path = os.path.join(adv_data_path, f'{save_name}_shap_values_adv{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(adv_save_path):\n",
        "        print(\"Adv Batch ID \", i)\n",
        "        batch = adv_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_adv = np.concatenate((shap_values_adv, shap_values))\n",
        "        with open(adv_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_adv, file)\n",
        "\n",
        "        logging.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "    else:\n",
        "        with open(adv_save_path, 'rb') as file:\n",
        "              shap_values_adv = pickle.load(file)\n",
        "\n",
        "\n",
        "common_len = 512\n",
        "shap_values_adv_values = [explanation.values for explanation in shap_values_adv]\n",
        "shap_values_org_values = [explanation.values for explanation in shap_values_org]\n",
        "\n",
        "shap_vals_org = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_org_values]).reshape(-1, num_classes * common_len)\n",
        "shap_vals_adv = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_adv_values]).reshape(-1, num_classes * common_len)\n",
        "\n",
        "logger.info(f'Created {len(shap_vals_org)} original SHAP values with shape {shap_vals_org.shape} for {dset_name}')\n",
        "logger.info(f'Created {len(shap_vals_adv)} adversarial SHAP values with shape {shap_vals_adv.shape} for {dset_name}')\n",
        "\n",
        "\n",
        "org_save_path = f'data/SHAP_signatures/normal/{save_name}_shap_values_padded_org.npy'\n",
        "with open(org_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_org, f)\n",
        "\n",
        "logger.info(f'Successfully saved original SHAP values to {org_save_path}')\n",
        "\n",
        "\n",
        "# Save the shap_values_adv array using pickle\n",
        "adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_padded_adv.pkl'\n",
        "with open(adv_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_adv, f)\n",
        "logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = np.concatenate((shap_vals_org, shap_vals_adv))\n",
        "org_labels = np.zeros(len(shap_vals_org), dtype=np.int16)\n",
        "adv_labels = np.ones(len(shap_vals_adv), dtype=np.int16)\n",
        "print(len(org_labels))\n",
        "print(len(adv_labels))\n",
        "labels = np.concatenate((org_labels, adv_labels))\n",
        "attack = np.concatenate((attack_org, attack_adv))\n",
        "\n",
        "# Create a dictionary with the columns\n",
        "df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(data.shape[1])])\n",
        "\n",
        "# Add attack and labels columns\n",
        "df['attack']=attack\n",
        "df['labels']=labels\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "\n",
        "traind, testd, y_train, y_test = train_test_split(df, df['labels'], stratify=df['attack'], test_size=0.2, random_state=42)\n",
        "X_train=traind.drop(columns=['attack','labels'])\n",
        "X_test=testd.drop(columns=['attack','labels'])\n",
        "\n",
        "print(f'Size: {traind.shape}')\n",
        "\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(X_train, y_train)\n",
        "pkl_filename = 'models/'+save_name+'rf.pkl'\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(randomF, file)\n",
        "preds = randomF.predict(X_test)\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have defined y_test and preds\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "\n",
        "metrics_df.to_csv('models/'+save_name+'_test_data_evaluation_metrics.csv', index=False)\n",
        "Result_File='models/'+save_name+'Supervised_DetectorResult_Attack_wise.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['attack','labels'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = randomF.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYj00Yvgt0ez"
      },
      "source": [
        "##ROBERTA AG_NEWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "15ISbBzO2TLJ"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import pickle,csv\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from pathlib import Path\n",
        "Path('data/SHAP_signatures/normal/').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/SHAP_signatures/adversarial/').mkdir(parents=True, exist_ok=True)\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "logger.info('ROBERTA + ag_news')\n",
        "datasetname='ag_news'\n",
        "model_name='textattack/roberta-base-ag-news'\n",
        "save_name='roberta_ag_news'\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "if model_name.startswith('lstm'):\n",
        "    model = LSTMForClassification.from_pretrained(model_name)\n",
        "    tokenizer = model.tokenizer\n",
        "    masker = shap.maskers.Text(r\"\\W\")\n",
        "\n",
        "    def f(x):\n",
        "        tv = torch.tensor(\n",
        "            [tokenizer.encode(v) for v in x]).cuda()\n",
        "        model.cuda()\n",
        "        outputs = model(tv).detach().cpu().numpy()  # Remove [0] for LSTM\n",
        "        out = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "        #val = sp.special.logit(scores)\n",
        "        return out\n",
        "elif model_name.startswith('textattack'):   # Huggingface transformer\n",
        "    def f(x_batch):\n",
        "          tv = torch.tensor(\n",
        "              [tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x_batch]).cuda()\n",
        "          outputs = model(tv)[0].detach().cpu().numpy()\n",
        "          return (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
        "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "    masker = tokenizer\n",
        "    # Indexing error is thrown at shap: _partition explain_row(). Seems like this does not matter\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "batch_size = 100\n",
        "shap_values_org={}\n",
        "shap_values_adv={}\n",
        "explainer = shap.Explainer(f, masker)\n",
        "org_data_path = 'data/SHAP_signatures/normal/'  # Specify your path here\n",
        "shap_values_org = np.empty(0, dtype=object)\n",
        "for i in range(0, len(org_text.to_list()), batch_size):\n",
        "    org_save_path = os.path.join(org_data_path, f'{save_name}_shap_values_org{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(org_save_path):\n",
        "        print(\"org Batch ID \", i)\n",
        "        batch = org_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_org = np.concatenate((shap_values_org, shap_values))\n",
        "        with open(org_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_org, file)\n",
        "\n",
        "        logging.info(f'Successfully saved orgersarial SHAP values to {org_save_path}')\n",
        "    else:\n",
        "        with open(org_save_path, 'rb') as file:\n",
        "              shap_values_org = pickle.load(file)\n",
        "\n",
        "\n",
        "\n",
        "# FOR ADVERSARIAL\n",
        "# Initialize shap_values_adv\n",
        "shap_values_adv = np.empty(0, dtype=object)\n",
        "adv_data_path = 'data/SHAP_signatures/adversarial/'  # Specify your path here\n",
        "\n",
        "for i in range(0, len(adv_text.to_list()), batch_size):\n",
        "    adv_save_path = os.path.join(adv_data_path, f'{save_name}_shap_values_adv{i}.pkl')\n",
        "\n",
        "    if not os.path.exists(adv_save_path):\n",
        "        print(\"Adv Batch ID \", i)\n",
        "        batch = adv_text.to_list()[i:i + batch_size]\n",
        "        shap_values = explainer(batch)\n",
        "        shap_values_adv = np.concatenate((shap_values_adv, shap_values))\n",
        "        with open(adv_save_path, 'wb') as file:\n",
        "               pickle.dump(shap_values_adv, file)\n",
        "\n",
        "        logging.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "    else:\n",
        "        with open(adv_save_path, 'rb') as file:\n",
        "              shap_values_adv = pickle.load(file)\n",
        "\n",
        "\n",
        "common_len = 512\n",
        "shap_values_adv_values = [explanation.values for explanation in shap_values_adv]\n",
        "shap_values_org_values = [explanation.values for explanation in shap_values_org]\n",
        "\n",
        "shap_vals_org = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_org_values]).reshape(-1, num_classes * common_len)\n",
        "shap_vals_adv = np.array([pad_seq(x, pad_len=common_len) for x in shap_values_adv_values]).reshape(-1, num_classes * common_len)\n",
        "\n",
        "logger.info(f'Created {len(shap_vals_org)} original SHAP values with shape {shap_vals_org.shape} for {dset_name}')\n",
        "logger.info(f'Created {len(shap_vals_adv)} adversarial SHAP values with shape {shap_vals_adv.shape} for {dset_name}')\n",
        "\n",
        "\n",
        "org_save_path = f'data/SHAP_signatures/normal/{save_name}_shap_values_padded_org.npy'\n",
        "with open(org_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_org, f)\n",
        "\n",
        "logger.info(f'Successfully saved original SHAP values to {org_save_path}')\n",
        "\n",
        "\n",
        "# Save the shap_values_adv array using pickle\n",
        "adv_save_path = f'data/SHAP_signatures/adversarial/{save_name}_shap_values_padded_adv.pkl'\n",
        "with open(adv_save_path, 'wb') as f:\n",
        "    pickle.dump(shap_vals_adv, f)\n",
        "logger.info(f'Successfully saved adversarial SHAP values to {adv_save_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = np.concatenate((shap_vals_org, shap_vals_adv))\n",
        "org_labels = np.zeros(len(shap_vals_org), dtype=np.int16)\n",
        "adv_labels = np.ones(len(shap_vals_adv), dtype=np.int16)\n",
        "print(len(org_labels))\n",
        "print(len(adv_labels))\n",
        "labels = np.concatenate((org_labels, adv_labels))\n",
        "attack = np.concatenate((attack_org, attack_adv))\n",
        "\n",
        "# Create a dictionary with the columns\n",
        "df = pd.DataFrame(data, columns=[f'col_{i}' for i in range(data.shape[1])])\n",
        "\n",
        "# Add attack and labels columns\n",
        "df['attack']=attack\n",
        "df['labels']=labels\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "\n",
        "traind, testd, y_train, y_test = train_test_split(df, df['labels'], stratify=df['attack'], test_size=0.2, random_state=42)\n",
        "X_train=traind.drop(columns=['attack','labels'])\n",
        "X_test=testd.drop(columns=['attack','labels'])\n",
        "\n",
        "print(f'Size: {traind.shape}')\n",
        "\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(X_train, y_train)\n",
        "pkl_filename = 'models/'+save_name+'rf.pkl'\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "                pickle.dump(randomF, file)\n",
        "preds = randomF.predict(X_test)\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Assuming you have defined y_test and preds\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "\n",
        "metrics_df.to_csv('models/'+save_name+'_test_data_evaluation_metrics.csv', index=False)\n",
        "Result_File='models/'+save_name+'Supervised_DetectorResult_Attack_wise.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['attack','labels'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = randomF.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvX4Hzt5t5Dz"
      },
      "source": [
        "#WDR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZl2iXwNxJp2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import importlib\n",
        "from copy import copy\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euh0vQiLz708"
      },
      "outputs": [],
      "source": [
        "hugging_face_model=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvvAVGm_wPl5"
      },
      "outputs": [],
      "source": [
        "def obtain_logits(samples, batch_size, model, tokenizer):\n",
        "    \"\"\"\n",
        "    For given samples and model, compute prediction logits.\n",
        "    Input data is splitted in batches.\n",
        "    \"\"\"\n",
        "    batches = [samples[i:i + batch_size] for i in range(0, len(samples), batch_size)]\n",
        "    logits = []\n",
        "\n",
        "    for i, b in enumerate(batches):\n",
        "        print(\"{}/{}\".format(i+1, len(batches)))\n",
        "        if hugging_face_model:\n",
        "            with torch.no_grad():\n",
        "                input = tokenizer(list(b), return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "                logits.append(model(**input).logits.cpu().numpy())\n",
        "        else:\n",
        "            logits.append(model(b))\n",
        "\n",
        "    return logits\n",
        "def compute_logits_difference(x, logits, y, model, tokenizer, idx, max_sentence_size=512):\n",
        "    start_time = time.time()\n",
        "    n_classes = len(logits[idx])\n",
        "    predicted_class = np.argmax(logits[idx]) # Predicted class for whole sentence using previously computed logits\n",
        "    class_logit = logits[idx][predicted_class] # Store this origianl prediction logit\n",
        "\n",
        "    split_sentence = x[idx].split(' ')[:max_sentence_size] # The tokenizer will only consider 512 words so we avoid computing innecessary logits\n",
        "\n",
        "    new_sentences = []\n",
        "\n",
        "    # Here, we replace each word by [UNK] and generate all sentences to consider\n",
        "    for i, word in enumerate(split_sentence):\n",
        "        new_sentence = copy(split_sentence)\n",
        "        new_sentence[i] = '[UNK]'\n",
        "        new_sentence = ' '.join(new_sentence)\n",
        "        new_sentences.append(new_sentence)\n",
        "\n",
        "    # We cannot run more than 350 predictions simultaneously because of resources.\n",
        "    # Split in batches if necessary.\n",
        "    # Compute logits for all replacements.\n",
        "    if len(new_sentences) > 200:\n",
        "        logits = []\n",
        "        batches = [new_sentences[i:i + 200] for i in range(0, len(new_sentences), 200)]\n",
        "        for b in batches:\n",
        "            if hugging_face_model: # Use hugging face predictions\n",
        "                batch = tokenizer(b, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "                with torch.no_grad():\n",
        "                    logits.append(model(**batch).logits)\n",
        "            else:\n",
        "                logits.append(model(b).to(device))\n",
        "\n",
        "        if hugging_face_model:\n",
        "            logits = torch.cat(logits)\n",
        "        else:\n",
        "            logits = np.concatenate( logits, axis=0 )\n",
        "            logits = torch.Tensor(logits)\n",
        "\n",
        "    else: # There's no need to split in batches\n",
        "        if hugging_face_model:\n",
        "            batch = tokenizer(new_sentences, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = model(**batch).logits\n",
        "            del batch\n",
        "        else:\n",
        "            logits = model(new_sentences)\n",
        "            logits = torch.Tensor(logits)\n",
        "\n",
        "\n",
        "    # Compute saliency\n",
        "    saliency = (class_logit - logits[:,predicted_class]).reshape(-1, 1)\n",
        "\n",
        "    # Append to logits for sorting\n",
        "    data = torch.cat((logits, saliency), 1)\n",
        "\n",
        "    # Sort by descending saliency\n",
        "    data = torch.stack(sorted(data, key=lambda a: a[n_classes], reverse=True))\n",
        "\n",
        "    # Remove saliency\n",
        "    data = data[:, :n_classes]\n",
        "\n",
        "    # Fix order: originallly predicted class, other classes\n",
        "    order = [predicted_class] + [i for i in range(n_classes) if i!=predicted_class]\n",
        "    data = torch.index_select(data, 1, torch.LongTensor(order).to(device))\n",
        "\n",
        "    # Compute difference between predicted class (always first column) and higher remaining logit\n",
        "    data = data[:, :1].flatten() - torch.max(data[:, 1:], dim=1).values.flatten()\n",
        "\n",
        "    del saliency\n",
        "    torch.cuda.empty_cache()\n",
        "    end_time = time.time()\n",
        "    print('Elapsed time ', end_time-start_time)\n",
        "    # Return only logits difference\n",
        "    return data.reshape(-1, 1), torch.Tensor([y[idx]]).to(device)\n",
        "\n",
        "def compute_logits_difference_padding(x, logits, y, model, tokenizer, idx, target_size=512):\n",
        "    \"\"\"\n",
        "    This function provides a wrapper for compute_logits_difference and includes padding to computations.\n",
        "    \"\"\"\n",
        "    data, y = compute_logits_difference(x, logits, y, model, tokenizer, idx, target_size)\n",
        "    data_size = min(512, data.shape[0])\n",
        "    target = torch.zeros(target_size, 1).to(device)\n",
        "    target[:data_size, :] = data\n",
        "\n",
        "    return target, y\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Text(Dataset):\n",
        "    \"\"\"\n",
        "    Dataloader following torch details. Each time we get an item, we will compute\n",
        "    the logits difference.\n",
        "    \"\"\"\n",
        "    def __init__(self, x , logits, y, attack, model, tokenizer, train=True, max_sentence_size=512):\n",
        "        self.logits = logits\n",
        "        self.y = y\n",
        "        self.x = x\n",
        "        self.attack=attack\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sentence_size = max_sentence_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data, y = compute_logits_difference_padding(self.x, self.logits, self.y, self.model, self.tokenizer, idx, self.max_sentence_size)\n",
        "        data = data[:, :1].unsqueeze(0)\n",
        "\n",
        "        return data, y, self.x[idx],self.attack[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sItdZqzvroo"
      },
      "source": [
        "##BERT IMBD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORWxUIOkt9Au"
      },
      "outputs": [],
      "source": [
        "import transformers,pickle\n",
        "wdr_path='/content/gdrive/My Drive/CompareTry/'\n",
        "datasetname='imdb'\n",
        "modelname='textattack/bert-base-uncased-imdb'\n",
        "filename=wdr_path+datasetname+'data_wdr_test_bert_output.csv'\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "datasetname='imdb'\n",
        "model_name='textattack/bert-base-uncased-imdb'\n",
        "save_name='bert_imdb'\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "attacks=np.concatenate((attack_org, attack_adv))\n",
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((org_text, adv_text))\n",
        "y = np.concatenate((np.zeros(len(org_text)), np.ones(len(adv_text))))\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(modelname).cuda()\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "# Compute logits for original sentences\n",
        "batch_size = 100\n",
        "original_logits = obtain_logits(org_text, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Compute logits for adversarial sentences\n",
        "batch_size = 100\n",
        "adversarial_logits = obtain_logits(adv_text, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, attacks,model, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=100)\n",
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and\n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "data_train = pd.DataFrame(columns=[i for i in range(512)]+['y_label', 'sentence','attack'])\n",
        "import time\n",
        "\n",
        "for i, (data, y_label, sentence,attack) in enumerate(train_loader):\n",
        "\n",
        "        print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "        for v in range(len(data)):\n",
        "            # Structure data and include in dataframe\n",
        "            row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v],attack[v]]))\n",
        "            #data_train = data_train.append(pd.DataFrame([row], columns=list(data_train)), ignore_index=True)\n",
        "            data_train = pd.concat([data_train, pd.DataFrame([row], columns=list(data_train))], ignore_index=True)\n",
        "            print(data_train)\n",
        "\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "         pickle.dump((logits,x,y,data_train),f)\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "         logits,x,y,data_train=pickle.load(f)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import csv\n",
        "traind, testd, y_train, y_test = train_test_split(data_train, data_train['y_label'], stratify=data_train['attack'], test_size=0.2, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_attack=traind['attack']\n",
        "test_attack=testd['attack']\n",
        "traind.drop(columns=['sentence','y_label','attack'], inplace=True)\n",
        "X_test=testd.drop(columns=['sentence','y_label','attack'])\n",
        "traind.columns = traind.columns.astype(str)\n",
        "testd.columns = testd.columns.astype(str)\n",
        "label_mapping = {'0.0': 0, '1.0': 1}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_test = y_test.map(label_mapping)\n",
        "#TRAIN XGBOOST\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "numeric_columns = traind.select_dtypes(include=['object']).columns\n",
        "traind[numeric_columns] = traind[numeric_columns].astype(float)  # Convert to float or int\n",
        "traind=traind.astype(float)\n",
        "numeric_columns = X_test.select_dtypes(include=['object']).columns\n",
        "X_test[numeric_columns] = X_test[numeric_columns].astype(float)  # Convert to float or int\n",
        "X_test=X_test.astype(float)\n",
        "xgb_model.fit(traind, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "model_file=wdr_path+save_name+'xgb'\n",
        "with open(model_file+'.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model,f)\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "file=wdr_path\n",
        "file_name = f\"{str(file)}{str(save_name)}_test_data_evaluation_metrics_results_xgb.csv\"\n",
        "metrics_df.to_csv(file_name, index=False)\n",
        "print(metrics_df)\n",
        "Result_File=wdr_path+save_name+'Supervised_DetectorResult_Attack_wise_WDR.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['sentence','y_label','attack'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    numeric_columns = X_Adv_attack.select_dtypes(include=['object']).columns\n",
        "                    X_Adv_attack[numeric_columns] = X_Adv_attack[numeric_columns].astype(float)  # Convert to float or int\n",
        "                    X_Adv_attack=X_Adv_attack.astype(float)\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = xgb_model.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsql1zA_B9v3"
      },
      "source": [
        "##ROBERTA IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TX_dfPUyATXl"
      },
      "outputs": [],
      "source": [
        "import time,csv\n",
        "import transformers,pickle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "wdr_path='/content/gdrive/My Drive/CompareTry/'\n",
        "datasetname='imdb'\n",
        "modelname='textattack/roberta-base-imdb'\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "datasetname='imdb'\n",
        "save_name='roberta_imdb'\n",
        "filename=wdr_path+save_name+'data_wdr_test_output.csv'\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "#INITIALIZATION\n",
        "# Concatenate all attacks\n",
        "attacks=np.concatenate((attack_org, attack_adv))\n",
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((org_text, adv_text))\n",
        "y = np.concatenate((np.zeros(len(org_text)), np.ones(len(adv_text))))\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(modelname).cuda()\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "# Compute logits for original sentences\n",
        "batch_size = 100\n",
        "original_logits = obtain_logits(org_text, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Compute logits for adversarial sentences\n",
        "batch_size = 100\n",
        "adversarial_logits = obtain_logits(adv_text, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, attacks,model, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=100)\n",
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and\n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "data_train = pd.DataFrame(columns=[i for i in range(512)]+['y_label', 'sentence','attack'])\n",
        "import time\n",
        "\n",
        "for i, (data, y_label, sentence,attack) in enumerate(train_loader):\n",
        "\n",
        "        print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "        for v in range(len(data)):\n",
        "            # Structure data and include in dataframe\n",
        "            row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v],attack[v]]))\n",
        "            #data_train = data_train.append(pd.DataFrame([row], columns=list(data_train)), ignore_index=True)\n",
        "            data_train = pd.concat([data_train, pd.DataFrame([row], columns=list(data_train))], ignore_index=True)\n",
        "            #print(data_train)\n",
        "\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "         pickle.dump((logits,x,y,data_train),f)\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "         logits,x,y,data_train=pickle.load(f)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import csv\n",
        "traind, testd, y_train, y_test = train_test_split(data_train, data_train['y_label'], stratify=data_train['attack'], test_size=0.2, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_attack=traind['attack']\n",
        "test_attack=testd['attack']\n",
        "traind.drop(columns=['sentence','y_label','attack'], inplace=True)\n",
        "X_test=testd.drop(columns=['sentence','y_label','attack'])\n",
        "traind.columns = traind.columns.astype(str)\n",
        "testd.columns = testd.columns.astype(str)\n",
        "label_mapping = {'0.0': 0, '1.0': 1}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_test = y_test.map(label_mapping)\n",
        "#TRAIN XGBOOST\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "numeric_columns = traind.select_dtypes(include=['object']).columns\n",
        "traind[numeric_columns] = traind[numeric_columns].astype(float)  # Convert to float or int\n",
        "traind=traind.astype(float)\n",
        "numeric_columns = X_test.select_dtypes(include=['object']).columns\n",
        "X_test[numeric_columns] = X_test[numeric_columns].astype(float)  # Convert to float or int\n",
        "X_test=X_test.astype(float)\n",
        "xgb_model.fit(traind, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "model_file=wdr_path+save_name+'xgb'\n",
        "with open(model_file+'.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model,f)\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "file=wdr_path\n",
        "file_name = f\"{str(file)}{str(save_name)}_test_data_evaluation_metrics_results_xgb.csv\"\n",
        "metrics_df.to_csv(file_name, index=False)\n",
        "print(metrics_df)\n",
        "Result_File=wdr_path+save_name+'Supervised_DetectorResult_Attack_wise_WDR.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['sentence','y_label','attack'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    numeric_columns = X_Adv_attack.select_dtypes(include=['object']).columns\n",
        "                    X_Adv_attack[numeric_columns] = X_Adv_attack[numeric_columns].astype(float)  # Convert to float or int\n",
        "                    X_Adv_attack=X_Adv_attack.astype(float)\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = xgb_model.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej2snizUCrK0"
      },
      "source": [
        "##BERT AGNEWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HGpJumdDAK5q"
      },
      "outputs": [],
      "source": [
        "import transformers,pickle\n",
        "wdr_path='/content/gdrive/My Drive/CompareTry/'\n",
        "datasetname='ag_news'\n",
        "modelname='textattack/bert-base-uncased-'+'ag-news'\n",
        "save_name='bert_agnews'\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "filename=wdr_path+save_name+'data_wdr_test_output.csv'\n",
        "\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "#INITIALIZATION\n",
        "# Concatenate all attacks\n",
        "attacks=np.concatenate((attack_org, attack_adv))\n",
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((org_text, adv_text))\n",
        "y = np.concatenate((np.zeros(len(org_text)), np.ones(len(adv_text))))\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(modelname).cuda()\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "# Compute logits for original sentences\n",
        "batch_size = 100\n",
        "original_logits = obtain_logits(org_text, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Compute logits for adversarial sentences\n",
        "batch_size = 100\n",
        "adversarial_logits = obtain_logits(adv_text, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, attacks,model, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=100)\n",
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and\n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "data_train = pd.DataFrame(columns=[i for i in range(512)]+['y_label', 'sentence','attack'])\n",
        "import time\n",
        "\n",
        "for i, (data, y_label, sentence,attack) in enumerate(train_loader):\n",
        "\n",
        "        print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "        for v in range(len(data)):\n",
        "            # Structure data and include in dataframe\n",
        "            row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v],attack[v]]))\n",
        "            #data_train = data_train.append(pd.DataFrame([row], columns=list(data_train)), ignore_index=True)\n",
        "            data_train = pd.concat([data_train, pd.DataFrame([row], columns=list(data_train))], ignore_index=True)\n",
        "            #print(data_train)\n",
        "\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "         pickle.dump((logits,x,y,data_train),f)\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "         logits,x,y,data_train=pickle.load(f)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import csv\n",
        "traind, testd, y_train, y_test = train_test_split(data_train, data_train['y_label'], stratify=data_train['attack'], test_size=0.2, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_attack=traind['attack']\n",
        "test_attack=testd['attack']\n",
        "traind.drop(columns=['sentence','y_label','attack'], inplace=True)\n",
        "X_test=testd.drop(columns=['sentence','y_label','attack'])\n",
        "traind.columns = traind.columns.astype(str)\n",
        "testd.columns = testd.columns.astype(str)\n",
        "label_mapping = {'0.0': 0, '1.0': 1}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_test = y_test.map(label_mapping)\n",
        "#TRAIN XGBOOST\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "numeric_columns = traind.select_dtypes(include=['object']).columns\n",
        "traind[numeric_columns] = traind[numeric_columns].astype(float)  # Convert to float or int\n",
        "traind=traind.astype(float)\n",
        "numeric_columns = X_test.select_dtypes(include=['object']).columns\n",
        "X_test[numeric_columns] = X_test[numeric_columns].astype(float)  # Convert to float or int\n",
        "X_test=X_test.astype(float)\n",
        "xgb_model.fit(traind, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "model_file=wdr_path+save_name+'xgb'\n",
        "with open(model_file+'.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model,f)\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "file=wdr_path\n",
        "file_name = f\"{str(file)}{str(save_name)}_test_data_evaluation_metrics_results_xgb.csv\"\n",
        "metrics_df.to_csv(file_name, index=False)\n",
        "print(metrics_df)\n",
        "Result_File=wdr_path+save_name+'Supervised_DetectorResult_Attack_wise_WDR.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['sentence','y_label','attack'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    numeric_columns = X_Adv_attack.select_dtypes(include=['object']).columns\n",
        "                    X_Adv_attack[numeric_columns] = X_Adv_attack[numeric_columns].astype(float)  # Convert to float or int\n",
        "                    X_Adv_attack=X_Adv_attack.astype(float)\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = xgb_model.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z-jhabbdlMr"
      },
      "outputs": [],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtbplznpcE5A"
      },
      "outputs": [],
      "source": [
        "attacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnk9w1hzbiEb"
      },
      "outputs": [],
      "source": [
        "testd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2EpmZZKg7Io"
      },
      "source": [
        "##ROBERTA AGNEWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vs4SqyqFg9gq"
      },
      "outputs": [],
      "source": [
        "import transformers,pickle\n",
        "wdr_path='/content/gdrive/My Drive/CompareTry/'\n",
        "datasetname='ag_news'\n",
        "modelname='textattack/roberta-base-ag-news'\n",
        "save_name='roberta_ag_news'\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "filename=wdr_path+save_name+'data_wdr_test_output.csv'\n",
        "\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "#INITIALIZATION\n",
        "# Concatenate all attacks\n",
        "attacks=np.concatenate((attack_org, attack_adv))\n",
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((org_text, adv_text))\n",
        "y = np.concatenate((np.zeros(len(org_text)), np.ones(len(adv_text))))\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(modelname).cuda()\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "# Compute logits for original sentences\n",
        "batch_size = 100\n",
        "original_logits = obtain_logits(org_text, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Compute logits for adversarial sentences\n",
        "batch_size = 100\n",
        "adversarial_logits = obtain_logits(adv_text, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, attacks,model, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=100)\n",
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and\n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "data_train = pd.DataFrame(columns=[i for i in range(512)]+['y_label', 'sentence','attack'])\n",
        "import time\n",
        "\n",
        "for i, (data, y_label, sentence,attack) in enumerate(train_loader):\n",
        "\n",
        "        print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "        for v in range(len(data)):\n",
        "            # Structure data and include in dataframe\n",
        "            row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v],attack[v]]))\n",
        "            #data_train = data_train.append(pd.DataFrame([row], columns=list(data_train)), ignore_index=True)\n",
        "            data_train = pd.concat([data_train, pd.DataFrame([row], columns=list(data_train))], ignore_index=True)\n",
        "            #print(data_train)\n",
        "\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "         pickle.dump((logits,x,y,data_train),f)\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "         logits,x,y,data_train=pickle.load(f)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import csv\n",
        "traind, testd, y_train, y_test = train_test_split(data_train, data_train['y_label'], stratify=data_train['attack'], test_size=0.2, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_attack=traind['attack']\n",
        "test_attack=testd['attack']\n",
        "traind.drop(columns=['sentence','y_label','attack'], inplace=True)\n",
        "X_test=testd.drop(columns=['sentence','y_label','attack'])\n",
        "traind.columns = traind.columns.astype(str)\n",
        "testd.columns = testd.columns.astype(str)\n",
        "label_mapping = {'0.0': 0, '1.0': 1}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_test = y_test.map(label_mapping)\n",
        "#TRAIN XGBOOST\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "numeric_columns = traind.select_dtypes(include=['object']).columns\n",
        "traind[numeric_columns] = traind[numeric_columns].astype(float)  # Convert to float or int\n",
        "traind=traind.astype(float)\n",
        "numeric_columns = X_test.select_dtypes(include=['object']).columns\n",
        "X_test[numeric_columns] = X_test[numeric_columns].astype(float)  # Convert to float or int\n",
        "X_test=X_test.astype(float)\n",
        "xgb_model.fit(traind, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "model_file=wdr_path+save_name+'xgb'\n",
        "with open(model_file+'.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model,f)\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "file=wdr_path\n",
        "file_name = f\"{str(file)}{str(save_name)}_test_data_evaluation_metrics_results_xgb.csv\"\n",
        "metrics_df.to_csv(file_name, index=False)\n",
        "print(metrics_df)\n",
        "Result_File=wdr_path+save_name+'Supervised_DetectorResult_Attack_wise_WDR.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['sentence','y_label','attack'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    numeric_columns = X_Adv_attack.select_dtypes(include=['object']).columns\n",
        "                    X_Adv_attack[numeric_columns] = X_Adv_attack[numeric_columns].astype(float)  # Convert to float or int\n",
        "                    X_Adv_attack=X_Adv_attack.astype(float)\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = xgb_model.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WP0SRy4QE3c"
      },
      "source": [
        "##BERT SST2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FYO1a6D0PZwp"
      },
      "outputs": [],
      "source": [
        "import transformers,pickle\n",
        "wdr_path='/content/gdrive/My Drive/CompareTry/'\n",
        "datasetname='sst2'\n",
        "modelname='textattack/bert-base-uncased-'+'SST-2'\n",
        "save_name='bert_sst2'\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "filename=wdr_path+save_name+'data_wdr_test_output.csv'\n",
        "\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['sentence']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "#INITIALIZATION\n",
        "# Concatenate all attacks\n",
        "attacks=np.concatenate((attack_org, attack_adv))\n",
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((org_text, adv_text))\n",
        "y = np.concatenate((np.zeros(len(org_text)), np.ones(len(adv_text))))\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(modelname).cuda()\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "# Compute logits for original sentences\n",
        "batch_size = 100\n",
        "original_logits = obtain_logits(org_text, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Compute logits for adversarial sentences\n",
        "batch_size = 100\n",
        "adversarial_logits = obtain_logits(adv_text, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, attacks,model, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=100)\n",
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and\n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "data_train = pd.DataFrame(columns=[i for i in range(512)]+['y_label', 'sentence','attack'])\n",
        "import time\n",
        "\n",
        "for i, (data, y_label, sentence,attack) in enumerate(train_loader):\n",
        "\n",
        "        print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "        for v in range(len(data)):\n",
        "            # Structure data and include in dataframe\n",
        "            row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v],attack[v]]))\n",
        "            #data_train = data_train.append(pd.DataFrame([row], columns=list(data_train)), ignore_index=True)\n",
        "            data_train = pd.concat([data_train, pd.DataFrame([row], columns=list(data_train))], ignore_index=True)\n",
        "            #print(data_train)\n",
        "\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "         pickle.dump((logits,x,y,data_train),f)\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "         logits,x,y,data_train=pickle.load(f)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import csv\n",
        "traind, testd, y_train, y_test = train_test_split(data_train, data_train['y_label'], stratify=data_train['attack'], test_size=0.2, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_attack=traind['attack']\n",
        "test_attack=testd['attack']\n",
        "traind.drop(columns=['sentence','y_label','attack'], inplace=True)\n",
        "X_test=testd.drop(columns=['sentence','y_label','attack'])\n",
        "traind.columns = traind.columns.astype(str)\n",
        "testd.columns = testd.columns.astype(str)\n",
        "label_mapping = {'0.0': 0, '1.0': 1}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_test = y_test.map(label_mapping)\n",
        "#TRAIN XGBOOST\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "numeric_columns = traind.select_dtypes(include=['object']).columns\n",
        "traind[numeric_columns] = traind[numeric_columns].astype(float)  # Convert to float or int\n",
        "traind=traind.astype(float)\n",
        "numeric_columns = X_test.select_dtypes(include=['object']).columns\n",
        "X_test[numeric_columns] = X_test[numeric_columns].astype(float)  # Convert to float or int\n",
        "X_test=X_test.astype(float)\n",
        "xgb_model.fit(traind, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "model_file=wdr_path+save_name+'xgb'\n",
        "with open(model_file+'.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model,f)\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "file=wdr_path\n",
        "file_name = f\"{str(file)}{str(save_name)}_test_data_evaluation_metrics_results_xgb.csv\"\n",
        "metrics_df.to_csv(file_name, index=False)\n",
        "print(metrics_df)\n",
        "Result_File=wdr_path+save_name+'Supervised_DetectorResult_Attack_wise_WDR.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['sentence','y_label','attack'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    numeric_columns = X_Adv_attack.select_dtypes(include=['object']).columns\n",
        "                    X_Adv_attack[numeric_columns] = X_Adv_attack[numeric_columns].astype(float)  # Convert to float or int\n",
        "                    X_Adv_attack=X_Adv_attack.astype(float)\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = xgb_model.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x125MW04mY6u"
      },
      "source": [
        "##ROBERTA SST2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XpVtC7aimaTB"
      },
      "outputs": [],
      "source": [
        "import transformers,pickle\n",
        "wdr_path='/content/gdrive/My Drive/CompareTry/'\n",
        "datasetname='sst2'\n",
        "modelname='textattack/roberta-base-SST-2'\n",
        "save_name='roberta_sst2'\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "filename=wdr_path+save_name+'data_wdr_test_output.csv'\n",
        "\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['sentence']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "#INITIALIZATION\n",
        "# Concatenate all attacks\n",
        "attacks=np.concatenate((attack_org, attack_adv))\n",
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((org_text, adv_text))\n",
        "y = np.concatenate((np.zeros(len(org_text)), np.ones(len(adv_text))))\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(modelname).cuda()\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "# Compute logits for original sentences\n",
        "batch_size = 100\n",
        "original_logits = obtain_logits(org_text, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Compute logits for adversarial sentences\n",
        "batch_size = 100\n",
        "adversarial_logits = obtain_logits(adv_text, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, attacks,model, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=100)\n",
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and\n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "data_train = pd.DataFrame(columns=[i for i in range(512)]+['y_label', 'sentence','attack'])\n",
        "import time\n",
        "\n",
        "for i, (data, y_label, sentence,attack) in enumerate(train_loader):\n",
        "\n",
        "        print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "        for v in range(len(data)):\n",
        "            # Structure data and include in dataframe\n",
        "            row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v],attack[v]]))\n",
        "            #data_train = data_train.append(pd.DataFrame([row], columns=list(data_train)), ignore_index=True)\n",
        "            data_train = pd.concat([data_train, pd.DataFrame([row], columns=list(data_train))], ignore_index=True)\n",
        "            #print(data_train)\n",
        "\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "         pickle.dump((logits,x,y,data_train),f)\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "         logits,x,y,data_train=pickle.load(f)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import csv\n",
        "traind, testd, y_train, y_test = train_test_split(data_train, data_train['y_label'], stratify=data_train['attack'], test_size=0.2, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_attack=traind['attack']\n",
        "test_attack=testd['attack']\n",
        "traind.drop(columns=['sentence','y_label','attack'], inplace=True)\n",
        "X_test=testd.drop(columns=['sentence','y_label','attack'])\n",
        "traind.columns = traind.columns.astype(str)\n",
        "testd.columns = testd.columns.astype(str)\n",
        "label_mapping = {'0.0': 0, '1.0': 1}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_test = y_test.map(label_mapping)\n",
        "#TRAIN XGBOOST\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "numeric_columns = traind.select_dtypes(include=['object']).columns\n",
        "traind[numeric_columns] = traind[numeric_columns].astype(float)  # Convert to float or int\n",
        "traind=traind.astype(float)\n",
        "numeric_columns = X_test.select_dtypes(include=['object']).columns\n",
        "X_test[numeric_columns] = X_test[numeric_columns].astype(float)  # Convert to float or int\n",
        "X_test=X_test.astype(float)\n",
        "xgb_model.fit(traind, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "model_file=wdr_path+save_name+'xgb'\n",
        "with open(model_file+'.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model,f)\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "file=wdr_path\n",
        "file_name = f\"{str(file)}{str(save_name)}_test_data_evaluation_metrics_results_xgb.csv\"\n",
        "metrics_df.to_csv(file_name, index=False)\n",
        "print(metrics_df)\n",
        "Result_File=wdr_path+save_name+'Supervised_DetectorResult_Attack_wise_WDR.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['sentence','y_label','attack'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    numeric_columns = X_Adv_attack.select_dtypes(include=['object']).columns\n",
        "                    X_Adv_attack[numeric_columns] = X_Adv_attack[numeric_columns].astype(float)  # Convert to float or int\n",
        "                    X_Adv_attack=X_Adv_attack.astype(float)\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = xgb_model.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvzXlDd4RYAm"
      },
      "source": [
        "##BERT YELP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lzktoky0RWeY"
      },
      "outputs": [],
      "source": [
        "import transformers,pickle\n",
        "wdr_path='/content/gdrive/My Drive/CompareTry/'\n",
        "datasetname='yelp_polarity'\n",
        "modelname='textattack/bert-base-uncased-'+'yelp-polarity'\n",
        "save_name='bert_yelp'\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "filename=wdr_path+save_name+'data_wdr_test_output.csv'\n",
        "\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_bert'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_bert'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "#INITIALIZATION\n",
        "# Concatenate all attacks\n",
        "attacks=np.concatenate((attack_org, attack_adv))\n",
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((org_text, adv_text))\n",
        "y = np.concatenate((np.zeros(len(org_text)), np.ones(len(adv_text))))\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(modelname).cuda()\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "# Compute logits for original sentences\n",
        "batch_size = 100\n",
        "original_logits = obtain_logits(org_text, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Compute logits for adversarial sentences\n",
        "batch_size = 100\n",
        "adversarial_logits = obtain_logits(adv_text, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, attacks,model, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=100)\n",
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and\n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "data_train = pd.DataFrame(columns=[i for i in range(512)]+['y_label', 'sentence','attack'])\n",
        "import time\n",
        "\n",
        "for i, (data, y_label, sentence,attack) in enumerate(train_loader):\n",
        "\n",
        "        print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "        for v in range(len(data)):\n",
        "            # Structure data and include in dataframe\n",
        "            row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v],attack[v]]))\n",
        "            #data_train = data_train.append(pd.DataFrame([row], columns=list(data_train)), ignore_index=True)\n",
        "            data_train = pd.concat([data_train, pd.DataFrame([row], columns=list(data_train))], ignore_index=True)\n",
        "            #print(data_train)\n",
        "\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "         pickle.dump((logits,x,y,data_train),f)\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "         logits,x,y,data_train=pickle.load(f)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import csv\n",
        "traind, testd, y_train, y_test = train_test_split(data_train, data_train['y_label'], stratify=data_train['attack'], test_size=0.2, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_attack=traind['attack']\n",
        "test_attack=testd['attack']\n",
        "traind.drop(columns=['sentence','y_label','attack'], inplace=True)\n",
        "X_test=testd.drop(columns=['sentence','y_label','attack'])\n",
        "traind.columns = traind.columns.astype(str)\n",
        "testd.columns = testd.columns.astype(str)\n",
        "label_mapping = {'0.0': 0, '1.0': 1}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_test = y_test.map(label_mapping)\n",
        "#TRAIN XGBOOST\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "numeric_columns = traind.select_dtypes(include=['object']).columns\n",
        "traind[numeric_columns] = traind[numeric_columns].astype(float)  # Convert to float or int\n",
        "traind=traind.astype(float)\n",
        "numeric_columns = X_test.select_dtypes(include=['object']).columns\n",
        "X_test[numeric_columns] = X_test[numeric_columns].astype(float)  # Convert to float or int\n",
        "X_test=X_test.astype(float)\n",
        "xgb_model.fit(traind, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "model_file=wdr_path+save_name+'xgb'\n",
        "with open(model_file+'.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model,f)\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "file=wdr_path\n",
        "file_name = f\"{str(file)}{str(save_name)}_test_data_evaluation_metrics_results_xgb.csv\"\n",
        "metrics_df.to_csv(file_name, index=False)\n",
        "print(metrics_df)\n",
        "Result_File=wdr_path+save_name+'Supervised_DetectorResult_Attack_wise_WDR.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['sentence','y_label','attack'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    numeric_columns = X_Adv_attack.select_dtypes(include=['object']).columns\n",
        "                    X_Adv_attack[numeric_columns] = X_Adv_attack[numeric_columns].astype(float)  # Convert to float or int\n",
        "                    X_Adv_attack=X_Adv_attack.astype(float)\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = xgb_model.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcnBNXaAmmgy"
      },
      "source": [
        "##ROBERTA YELP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ImlVGpavmoZV"
      },
      "outputs": [],
      "source": [
        "import transformers,pickle\n",
        "wdr_path='/content/gdrive/My Drive/CompareTry/'\n",
        "datasetname='yelp_polarity'\n",
        "modelname='VictorSanh/roberta-base-finetuned-'+'yelp-polarity'\n",
        "save_name='roberta_yelp'\n",
        "dset_name=datasetname\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/small_'\n",
        "filename=wdr_path+save_name+'data_wdr_test_output.csv'\n",
        "\n",
        "dset_name=datasetname\n",
        "print('filename ',savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df=pd.read_csv(savepath+dset_name+'_roberta'+'_clean_data.csv')\n",
        "clean_df['attack']='NO'\n",
        "attack_org=clean_df['attack']\n",
        "org_text = clean_df['text']\n",
        "print(len(org_text.tolist()))\n",
        "adv_df=pd.read_csv (savepath+dset_name+'_roberta'+'_adv_data.csv')\n",
        "adv_text = adv_df['perturbed_text']\n",
        "num_classes = 4 if dset_name == 'ag_news' else 2 #len(samples.ground_truth_output.unique())\n",
        "attack_adv=adv_df['attack']\n",
        "#INITIALIZATION\n",
        "# Concatenate all attacks\n",
        "attacks=np.concatenate((attack_org, attack_adv))\n",
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((org_text, adv_text))\n",
        "y = np.concatenate((np.zeros(len(org_text)), np.ones(len(adv_text))))\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(modelname).cuda()\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(modelname)\n",
        "\n",
        "# Compute logits for original sentences\n",
        "batch_size = 100\n",
        "original_logits = obtain_logits(org_text, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Compute logits for adversarial sentences\n",
        "batch_size = 100\n",
        "adversarial_logits = obtain_logits(adv_text, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])\n",
        "torch.cuda.empty_cache()\n",
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, attacks,model, tokenizer)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=100)\n",
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and\n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "data_train = pd.DataFrame(columns=[i for i in range(512)]+['y_label', 'sentence','attack'])\n",
        "import time\n",
        "\n",
        "for i, (data, y_label, sentence,attack) in enumerate(train_loader):\n",
        "\n",
        "        print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "        for v in range(len(data)):\n",
        "            # Structure data and include in dataframe\n",
        "            row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v],attack[v]]))\n",
        "            #data_train = data_train.append(pd.DataFrame([row], columns=list(data_train)), ignore_index=True)\n",
        "            data_train = pd.concat([data_train, pd.DataFrame([row], columns=list(data_train))], ignore_index=True)\n",
        "            #print(data_train)\n",
        "\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "         pickle.dump((logits,x,y,data_train),f)\n",
        "filename=wdr_path+save_name+'.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "         logits,x,y,data_train=pickle.load(f)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import csv\n",
        "traind, testd, y_train, y_test = train_test_split(data_train, data_train['y_label'], stratify=data_train['attack'], test_size=0.2, random_state=42)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_attack=traind['attack']\n",
        "test_attack=testd['attack']\n",
        "traind.drop(columns=['sentence','y_label','attack'], inplace=True)\n",
        "X_test=testd.drop(columns=['sentence','y_label','attack'])\n",
        "traind.columns = traind.columns.astype(str)\n",
        "testd.columns = testd.columns.astype(str)\n",
        "label_mapping = {'0.0': 0, '1.0': 1}\n",
        "y_train = y_train.map(label_mapping)\n",
        "y_test = y_test.map(label_mapping)\n",
        "#TRAIN XGBOOST\n",
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "numeric_columns = traind.select_dtypes(include=['object']).columns\n",
        "traind[numeric_columns] = traind[numeric_columns].astype(float)  # Convert to float or int\n",
        "traind=traind.astype(float)\n",
        "numeric_columns = X_test.select_dtypes(include=['object']).columns\n",
        "X_test[numeric_columns] = X_test[numeric_columns].astype(float)  # Convert to float or int\n",
        "X_test=X_test.astype(float)\n",
        "xgb_model.fit(traind, y_train)\n",
        "preds = xgb_model.predict(X_test)\n",
        "model_file=wdr_path+save_name+'xgb'\n",
        "with open(model_file+'.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb_model,f)\n",
        "\n",
        "# Calculate different evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_test, preds)\n",
        "mcc = matthews_corrcoef(y_test, preds)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "balanced_accuracy = balanced_accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "roc_auc = roc_auc_score(y_test, preds)\n",
        "\n",
        "# Calculate false positive rate (fpr) and false negative rate (fnr)\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics_dict = {\n",
        "    'Metric': ['MCC', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC', 'FPR', 'FNR'],\n",
        "    'Value': [mcc, accuracy, balanced_accuracy, precision, recall, f1, roc_auc, fpr, fnr]\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a pandas DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "file=wdr_path\n",
        "file_name = f\"{str(file)}{str(save_name)}_test_data_evaluation_metrics_results_xgb.csv\"\n",
        "metrics_df.to_csv(file_name, index=False)\n",
        "print(metrics_df)\n",
        "Result_File=wdr_path+save_name+'Supervised_DetectorResult_Attack_wise_WDR.csv'\n",
        "result=open(Result_File, 'a+' ,encoding='utf-8',newline='')\n",
        "result_csv= csv.writer(result)\n",
        "uniqueattack=dict(map(reversed, enumerate(set(testd['attack']))))\n",
        "for attack in uniqueattack.keys():\n",
        "                    print(\"ATTACK \",attack)\n",
        "                    X_Adv_attack=testd.loc[testd['attack'] == attack]\n",
        "                    X_Adv_attack=X_Adv_attack.drop(columns=['sentence','y_label','attack'], axis=1)\n",
        "                    if(attack.upper()!='NO'):\n",
        "                      X_Adv_Label=np.ones(len(X_Adv_attack))\n",
        "                    else:\n",
        "                      X_Adv_Label=np.zeros(len(X_Adv_attack))\n",
        "                    from sklearn.metrics import accuracy_score\n",
        "                    numeric_columns = X_Adv_attack.select_dtypes(include=['object']).columns\n",
        "                    X_Adv_attack[numeric_columns] = X_Adv_attack[numeric_columns].astype(float)  # Convert to float or int\n",
        "                    X_Adv_attack=X_Adv_attack.astype(float)\n",
        "                    # Assuming you have trained your model and obtained predictions\n",
        "                    y_pred = xgb_model.predict(X_Adv_attack)\n",
        "                    accuracy = accuracy_score(X_Adv_Label, y_pred)\n",
        "                    row=[len(X_Adv_attack),attack.upper(),datasetname.upper(),'bert',accuracy]\n",
        "                    result_csv.writerow(row)\n",
        "                    print(\"Attack: \" ,attack, \" accuracy \",accuracy)\n",
        "result.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xPfSRQF29Rwa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9J6cUyhS-LCu"
      },
      "outputs": [],
      "source": [
        "print(metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W0xH0Wo97llR"
      },
      "outputs": [],
      "source": [
        "preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EbU03mZf7UMS"
      },
      "outputs": [],
      "source": [
        "traind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYi5jGeWsjP1"
      },
      "outputs": [],
      "source": [
        "#MLMD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU7c32Wasmrx"
      },
      "source": [
        "#MLDM ASIA CCS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEfX1UWb0mZ4",
        "outputId": "d2ddd349-680d-43d2-87dc-d507662d935a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/gdrive/My Drive/MLDM' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mlmddetection/MLMDdetection.git '/content/gdrive/My Drive/MLDM/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koth7tpws3Dl",
        "outputId": "a405e744-febd-4c86-cd60-063a3d4bd5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/MLDM\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/My Drive/MLDM/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3MxPRdcdhlZ"
      },
      "outputs": [],
      "source": [
        "M_path='/content/gdrive/My Drive/MLDM/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCLuoywJvYlY",
        "outputId": "dacbc8c1-b2be-4feb-9bf3-c3647e76b780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ag_newsbertadv.pkl         ag_newsroberta540adv.pkl           yelp_polarityroberta117Benign.pkl\n",
            "ag_newsbertbenign_adv.pkl  ag_newsroberta541adv.pkl           yelp_polarityroberta118Benign.pkl\n",
            "ag_newsbertBenign.pkl      ag_newsroberta542adv.pkl           yelp_polarityroberta119Benign.pkl\n",
            "ag_newsroberta0adv.pkl     ag_newsroberta543adv.pkl           yelp_polarityroberta11Benign.pkl\n",
            "ag_newsroberta100adv.pkl   ag_newsroberta544adv.pkl           yelp_polarityroberta120Benign.pkl\n",
            "ag_newsroberta101adv.pkl   ag_newsroberta545adv.pkl           yelp_polarityroberta121Benign.pkl\n",
            "ag_newsroberta102adv.pkl   ag_newsroberta546adv.pkl           yelp_polarityroberta122Benign.pkl\n",
            "ag_newsroberta103adv.pkl   ag_newsroberta547adv.pkl           yelp_polarityroberta123Benign.pkl\n",
            "ag_newsroberta104adv.pkl   ag_newsroberta548adv.pkl           yelp_polarityroberta124Benign.pkl\n",
            "ag_newsroberta105adv.pkl   ag_newsroberta549adv.pkl           yelp_polarityroberta125Benign.pkl\n",
            "ag_newsroberta106adv.pkl   ag_newsroberta54adv.pkl            yelp_polarityroberta126Benign.pkl\n",
            "ag_newsroberta107adv.pkl   ag_newsroberta550adv.pkl           yelp_polarityroberta127Benign.pkl\n",
            "ag_newsroberta108adv.pkl   ag_newsroberta551adv.pkl           yelp_polarityroberta128Benign.pkl\n",
            "ag_newsroberta109adv.pkl   ag_newsroberta552adv.pkl           yelp_polarityroberta129Benign.pkl\n",
            "ag_newsroberta10adv.pkl    ag_newsroberta553adv.pkl           yelp_polarityroberta12Benign.pkl\n",
            "ag_newsroberta110adv.pkl   ag_newsroberta554adv.pkl           yelp_polarityroberta130Benign.pkl\n",
            "ag_newsroberta111adv.pkl   ag_newsroberta555adv.pkl           yelp_polarityroberta131Benign.pkl\n",
            "ag_newsroberta112adv.pkl   ag_newsroberta556adv.pkl           yelp_polarityroberta132Benign.pkl\n",
            "ag_newsroberta113adv.pkl   ag_newsroberta557adv.pkl           yelp_polarityroberta133Benign.pkl\n",
            "ag_newsroberta114adv.pkl   ag_newsroberta558adv.pkl           yelp_polarityroberta134Benign.pkl\n",
            "ag_newsroberta115adv.pkl   ag_newsroberta559adv.pkl           yelp_polarityroberta135Benign.pkl\n",
            "ag_newsroberta116adv.pkl   ag_newsroberta55adv.pkl            yelp_polarityroberta136Benign.pkl\n",
            "ag_newsroberta117adv.pkl   ag_newsroberta560adv.pkl           yelp_polarityroberta137Benign.pkl\n",
            "ag_newsroberta118adv.pkl   ag_newsroberta561adv.pkl           yelp_polarityroberta138Benign.pkl\n",
            "ag_newsroberta119adv.pkl   ag_newsroberta562adv.pkl           yelp_polarityroberta139Benign.pkl\n",
            "ag_newsroberta11adv.pkl    ag_newsroberta563adv.pkl           yelp_polarityroberta13Benign.pkl\n",
            "ag_newsroberta120adv.pkl   ag_newsroberta564adv.pkl           yelp_polarityroberta140Benign.pkl\n",
            "ag_newsroberta121adv.pkl   ag_newsroberta565adv.pkl           yelp_polarityroberta141Benign.pkl\n",
            "ag_newsroberta122adv.pkl   ag_newsroberta566adv.pkl           yelp_polarityroberta142Benign.pkl\n",
            "ag_newsroberta123adv.pkl   ag_newsroberta567adv.pkl           yelp_polarityroberta143Benign.pkl\n",
            "ag_newsroberta124adv.pkl   ag_newsroberta568adv.pkl           yelp_polarityroberta144Benign.pkl\n",
            "ag_newsroberta125adv.pkl   ag_newsroberta569adv.pkl           yelp_polarityroberta145Benign.pkl\n",
            "ag_newsroberta126adv.pkl   ag_newsroberta56adv.pkl            yelp_polarityroberta146Benign.pkl\n",
            "ag_newsroberta127adv.pkl   ag_newsroberta570adv.pkl           yelp_polarityroberta147Benign.pkl\n",
            "ag_newsroberta128adv.pkl   ag_newsroberta571adv.pkl           yelp_polarityroberta148Benign.pkl\n",
            "ag_newsroberta129adv.pkl   ag_newsroberta572adv.pkl           yelp_polarityroberta149Benign.pkl\n",
            "ag_newsroberta12adv.pkl    ag_newsroberta573adv.pkl           yelp_polarityroberta14Benign.pkl\n",
            "ag_newsroberta130adv.pkl   ag_newsroberta574adv.pkl           yelp_polarityroberta150Benign.pkl\n",
            "ag_newsroberta131adv.pkl   ag_newsroberta575adv.pkl           yelp_polarityroberta151Benign.pkl\n",
            "ag_newsroberta132adv.pkl   ag_newsroberta576adv.pkl           yelp_polarityroberta152Benign.pkl\n",
            "ag_newsroberta133adv.pkl   ag_newsroberta577adv.pkl           yelp_polarityroberta153Benign.pkl\n",
            "ag_newsroberta134adv.pkl   ag_newsroberta578adv.pkl           yelp_polarityroberta154Benign.pkl\n",
            "ag_newsroberta135adv.pkl   ag_newsroberta579adv.pkl           yelp_polarityroberta155Benign.pkl\n",
            "ag_newsroberta136adv.pkl   ag_newsroberta57adv.pkl            yelp_polarityroberta156Benign.pkl\n",
            "ag_newsroberta137adv.pkl   ag_newsroberta580adv.pkl           yelp_polarityroberta157Benign.pkl\n",
            "ag_newsroberta138adv.pkl   ag_newsroberta581adv.pkl           yelp_polarityroberta158Benign.pkl\n",
            "ag_newsroberta139adv.pkl   ag_newsroberta582adv.pkl           yelp_polarityroberta159Benign.pkl\n",
            "ag_newsroberta13adv.pkl    ag_newsroberta583adv.pkl           yelp_polarityroberta15Benign.pkl\n",
            "ag_newsroberta140adv.pkl   ag_newsroberta584adv.pkl           yelp_polarityroberta160Benign.pkl\n",
            "ag_newsroberta141adv.pkl   ag_newsroberta585adv.pkl           yelp_polarityroberta161Benign.pkl\n",
            "ag_newsroberta142adv.pkl   ag_newsroberta586adv.pkl           yelp_polarityroberta162Benign.pkl\n",
            "ag_newsroberta143adv.pkl   ag_newsroberta587adv.pkl           yelp_polarityroberta163Benign.pkl\n",
            "ag_newsroberta144adv.pkl   ag_newsroberta588adv.pkl           yelp_polarityroberta164Benign.pkl\n",
            "ag_newsroberta145adv.pkl   ag_newsroberta589adv.pkl           yelp_polarityroberta165Benign.pkl\n",
            "ag_newsroberta146adv.pkl   ag_newsroberta58adv.pkl            yelp_polarityroberta166Benign.pkl\n",
            "ag_newsroberta147adv.pkl   ag_newsroberta590adv.pkl           yelp_polarityroberta167Benign.pkl\n",
            "ag_newsroberta148adv.pkl   ag_newsroberta591adv.pkl           yelp_polarityroberta168Benign.pkl\n",
            "ag_newsroberta149adv.pkl   ag_newsroberta592adv.pkl           yelp_polarityroberta169Benign.pkl\n",
            "ag_newsroberta14adv.pkl    ag_newsroberta593adv.pkl           yelp_polarityroberta16Benign.pkl\n",
            "ag_newsroberta150adv.pkl   ag_newsroberta594adv.pkl           yelp_polarityroberta170Benign.pkl\n",
            "ag_newsroberta151adv.pkl   ag_newsroberta595adv.pkl           yelp_polarityroberta171Benign.pkl\n",
            "ag_newsroberta152adv.pkl   ag_newsroberta596adv.pkl           yelp_polarityroberta172Benign.pkl\n",
            "ag_newsroberta153adv.pkl   ag_newsroberta597adv.pkl           yelp_polarityroberta173Benign.pkl\n",
            "ag_newsroberta154adv.pkl   ag_newsroberta598adv.pkl           yelp_polarityroberta174Benign.pkl\n",
            "ag_newsroberta155adv.pkl   ag_newsroberta599adv.pkl           yelp_polarityroberta175Benign.pkl\n",
            "ag_newsroberta156adv.pkl   ag_newsroberta59adv.pkl            yelp_polarityroberta176Benign.pkl\n",
            "ag_newsroberta157adv.pkl   ag_newsroberta5adv.pkl             yelp_polarityroberta177Benign.pkl\n",
            "ag_newsroberta158adv.pkl   ag_newsroberta600adv.pkl           yelp_polarityroberta178Benign.pkl\n",
            "ag_newsroberta159adv.pkl   ag_newsroberta601adv.pkl           yelp_polarityroberta179Benign.pkl\n",
            "ag_newsroberta15adv.pkl    ag_newsroberta602adv.pkl           yelp_polarityroberta17Benign.pkl\n",
            "ag_newsroberta160adv.pkl   ag_newsroberta603adv.pkl           yelp_polarityroberta180Benign.pkl\n",
            "ag_newsroberta161adv.pkl   ag_newsroberta604adv.pkl           yelp_polarityroberta181Benign.pkl\n",
            "ag_newsroberta162adv.pkl   ag_newsroberta605adv.pkl           yelp_polarityroberta182Benign.pkl\n",
            "ag_newsroberta163adv.pkl   ag_newsroberta606adv.pkl           yelp_polarityroberta183Benign.pkl\n",
            "ag_newsroberta164adv.pkl   ag_newsroberta607adv.pkl           yelp_polarityroberta184Benign.pkl\n",
            "ag_newsroberta165adv.pkl   ag_newsroberta608adv.pkl           yelp_polarityroberta185Benign.pkl\n",
            "ag_newsroberta166adv.pkl   ag_newsroberta609adv.pkl           yelp_polarityroberta186Benign.pkl\n",
            "ag_newsroberta167adv.pkl   ag_newsroberta60adv.pkl            yelp_polarityroberta187Benign.pkl\n",
            "ag_newsroberta168adv.pkl   ag_newsroberta610adv.pkl           yelp_polarityroberta188Benign.pkl\n",
            "ag_newsroberta169adv.pkl   ag_newsroberta611adv.pkl           yelp_polarityroberta189Benign.pkl\n",
            "ag_newsroberta16adv.pkl    ag_newsroberta612adv.pkl           yelp_polarityroberta18Benign.pkl\n",
            "ag_newsroberta170adv.pkl   ag_newsroberta613adv.pkl           yelp_polarityroberta190Benign.pkl\n",
            "ag_newsroberta171adv.pkl   ag_newsroberta614adv.pkl           yelp_polarityroberta191Benign.pkl\n",
            "ag_newsroberta172adv.pkl   ag_newsroberta615adv.pkl           yelp_polarityroberta192Benign.pkl\n",
            "ag_newsroberta173adv.pkl   ag_newsroberta616adv.pkl           yelp_polarityroberta193Benign.pkl\n",
            "ag_newsroberta174adv.pkl   ag_newsroberta617adv.pkl           yelp_polarityroberta194Benign.pkl\n",
            "ag_newsroberta175adv.pkl   ag_newsroberta618adv.pkl           yelp_polarityroberta195Benign.pkl\n",
            "ag_newsroberta176adv.pkl   ag_newsroberta619adv.pkl           yelp_polarityroberta196Benign.pkl\n",
            "ag_newsroberta177adv.pkl   ag_newsroberta61adv.pkl            yelp_polarityroberta197Benign.pkl\n",
            "ag_newsroberta178adv.pkl   ag_newsroberta620adv.pkl           yelp_polarityroberta198Benign.pkl\n",
            "ag_newsroberta179adv.pkl   ag_newsroberta621adv.pkl           yelp_polarityroberta199Benign.pkl\n",
            "ag_newsroberta17adv.pkl    ag_newsroberta622adv.pkl           yelp_polarityroberta19Benign.pkl\n",
            "ag_newsroberta180adv.pkl   ag_newsroberta623adv.pkl           yelp_polarityroberta1Benign.pkl\n",
            "ag_newsroberta181adv.pkl   ag_newsroberta624adv.pkl           yelp_polarityroberta200Benign.pkl\n",
            "ag_newsroberta182adv.pkl   ag_newsroberta625adv.pkl           yelp_polarityroberta201Benign.pkl\n",
            "ag_newsroberta183adv.pkl   ag_newsroberta626adv.pkl           yelp_polarityroberta202Benign.pkl\n",
            "ag_newsroberta184adv.pkl   ag_newsroberta627adv.pkl           yelp_polarityroberta203Benign.pkl\n",
            "ag_newsroberta185adv.pkl   ag_newsroberta628adv.pkl           yelp_polarityroberta204Benign.pkl\n",
            "ag_newsroberta186adv.pkl   ag_newsroberta629adv.pkl           yelp_polarityroberta205Benign.pkl\n",
            "ag_newsroberta187adv.pkl   ag_newsroberta62adv.pkl            yelp_polarityroberta206Benign.pkl\n",
            "ag_newsroberta188adv.pkl   ag_newsroberta630adv.pkl           yelp_polarityroberta207Benign.pkl\n",
            "ag_newsroberta189adv.pkl   ag_newsroberta631adv.pkl           yelp_polarityroberta208Benign.pkl\n",
            "ag_newsroberta18adv.pkl    ag_newsroberta632adv.pkl           yelp_polarityroberta209Benign.pkl\n",
            "ag_newsroberta190adv.pkl   ag_newsroberta633adv.pkl           yelp_polarityroberta20Benign.pkl\n",
            "ag_newsroberta191adv.pkl   ag_newsroberta634adv.pkl           yelp_polarityroberta210Benign.pkl\n",
            "ag_newsroberta192adv.pkl   ag_newsroberta635adv.pkl           yelp_polarityroberta211Benign.pkl\n",
            "ag_newsroberta193adv.pkl   ag_newsroberta636adv.pkl           yelp_polarityroberta212Benign.pkl\n",
            "ag_newsroberta194adv.pkl   ag_newsroberta637adv.pkl           yelp_polarityroberta213Benign.pkl\n",
            "ag_newsroberta195adv.pkl   ag_newsroberta638adv.pkl           yelp_polarityroberta214Benign.pkl\n",
            "ag_newsroberta196adv.pkl   ag_newsroberta639adv.pkl           yelp_polarityroberta215Benign.pkl\n",
            "ag_newsroberta197adv.pkl   ag_newsroberta63adv.pkl            yelp_polarityroberta216Benign.pkl\n",
            "ag_newsroberta198adv.pkl   ag_newsroberta640adv.pkl           yelp_polarityroberta217Benign.pkl\n",
            "ag_newsroberta199adv.pkl   ag_newsroberta641adv.pkl           yelp_polarityroberta218Benign.pkl\n",
            "ag_newsroberta19adv.pkl    ag_newsroberta642adv.pkl           yelp_polarityroberta219Benign.pkl\n",
            "ag_newsroberta1adv.pkl     ag_newsroberta643adv.pkl           yelp_polarityroberta21Benign.pkl\n",
            "ag_newsroberta200adv.pkl   ag_newsroberta644adv.pkl           yelp_polarityroberta220Benign.pkl\n",
            "ag_newsroberta201adv.pkl   ag_newsroberta645adv.pkl           yelp_polarityroberta221Benign.pkl\n",
            "ag_newsroberta202adv.pkl   ag_newsroberta646adv.pkl           yelp_polarityroberta222Benign.pkl\n",
            "ag_newsroberta203adv.pkl   ag_newsroberta647adv.pkl           yelp_polarityroberta223Benign.pkl\n",
            "ag_newsroberta204adv.pkl   ag_newsroberta648adv.pkl           yelp_polarityroberta224Benign.pkl\n",
            "ag_newsroberta205adv.pkl   ag_newsroberta649adv.pkl           yelp_polarityroberta225Benign.pkl\n",
            "ag_newsroberta206adv.pkl   ag_newsroberta64adv.pkl            yelp_polarityroberta226Benign.pkl\n",
            "ag_newsroberta207adv.pkl   ag_newsroberta650adv.pkl           yelp_polarityroberta227Benign.pkl\n",
            "ag_newsroberta208adv.pkl   ag_newsroberta651adv.pkl           yelp_polarityroberta228Benign.pkl\n",
            "ag_newsroberta209adv.pkl   ag_newsroberta652adv.pkl           yelp_polarityroberta229Benign.pkl\n",
            "ag_newsroberta20adv.pkl    ag_newsroberta653adv.pkl           yelp_polarityroberta22Benign.pkl\n",
            "ag_newsroberta210adv.pkl   ag_newsroberta654adv.pkl           yelp_polarityroberta230Benign.pkl\n",
            "ag_newsroberta211adv.pkl   ag_newsroberta655adv.pkl           yelp_polarityroberta231Benign.pkl\n",
            "ag_newsroberta212adv.pkl   ag_newsroberta656adv.pkl           yelp_polarityroberta232Benign.pkl\n",
            "ag_newsroberta213adv.pkl   ag_newsroberta657adv.pkl           yelp_polarityroberta233Benign.pkl\n",
            "ag_newsroberta214adv.pkl   ag_newsroberta658adv.pkl           yelp_polarityroberta234Benign.pkl\n",
            "ag_newsroberta215adv.pkl   ag_newsroberta659adv.pkl           yelp_polarityroberta235Benign.pkl\n",
            "ag_newsroberta216adv.pkl   ag_newsroberta65adv.pkl            yelp_polarityroberta236Benign.pkl\n",
            "ag_newsroberta217adv.pkl   ag_newsroberta660adv.pkl           yelp_polarityroberta237Benign.pkl\n",
            "ag_newsroberta218adv.pkl   ag_newsroberta661adv.pkl           yelp_polarityroberta238Benign.pkl\n",
            "ag_newsroberta219adv.pkl   ag_newsroberta662adv.pkl           yelp_polarityroberta239Benign.pkl\n",
            "ag_newsroberta21adv.pkl    ag_newsroberta663adv.pkl           yelp_polarityroberta23Benign.pkl\n",
            "ag_newsroberta220adv.pkl   ag_newsroberta664adv.pkl           yelp_polarityroberta240Benign.pkl\n",
            "ag_newsroberta221adv.pkl   ag_newsroberta665adv.pkl           yelp_polarityroberta241Benign.pkl\n",
            "ag_newsroberta222adv.pkl   ag_newsroberta666adv.pkl           yelp_polarityroberta242Benign.pkl\n",
            "ag_newsroberta223adv.pkl   ag_newsroberta667adv.pkl           yelp_polarityroberta243Benign.pkl\n",
            "ag_newsroberta224adv.pkl   ag_newsroberta668adv.pkl           yelp_polarityroberta244Benign.pkl\n",
            "ag_newsroberta225adv.pkl   ag_newsroberta669adv.pkl           yelp_polarityroberta245Benign.pkl\n",
            "ag_newsroberta226adv.pkl   ag_newsroberta66adv.pkl            yelp_polarityroberta246Benign.pkl\n",
            "ag_newsroberta227adv.pkl   ag_newsroberta670adv.pkl           yelp_polarityroberta247Benign.pkl\n",
            "ag_newsroberta228adv.pkl   ag_newsroberta671adv.pkl           yelp_polarityroberta248Benign.pkl\n",
            "ag_newsroberta229adv.pkl   ag_newsroberta672adv.pkl           yelp_polarityroberta249Benign.pkl\n",
            "ag_newsroberta22adv.pkl    ag_newsroberta673adv.pkl           yelp_polarityroberta24Benign.pkl\n",
            "ag_newsroberta230adv.pkl   ag_newsroberta674adv.pkl           yelp_polarityroberta250Benign.pkl\n",
            "ag_newsroberta231adv.pkl   ag_newsroberta675adv.pkl           yelp_polarityroberta251Benign.pkl\n",
            "ag_newsroberta232adv.pkl   ag_newsroberta676adv.pkl           yelp_polarityroberta252Benign.pkl\n",
            "ag_newsroberta233adv.pkl   ag_newsroberta677adv.pkl           yelp_polarityroberta253Benign.pkl\n",
            "ag_newsroberta234adv.pkl   ag_newsroberta678adv.pkl           yelp_polarityroberta254Benign.pkl\n",
            "ag_newsroberta235adv.pkl   ag_newsroberta679adv.pkl           yelp_polarityroberta255Benign.pkl\n",
            "ag_newsroberta236adv.pkl   ag_newsroberta67adv.pkl            yelp_polarityroberta256Benign.pkl\n",
            "ag_newsroberta237adv.pkl   ag_newsroberta680adv.pkl           yelp_polarityroberta257Benign.pkl\n",
            "ag_newsroberta238adv.pkl   ag_newsroberta681adv.pkl           yelp_polarityroberta258Benign.pkl\n",
            "ag_newsroberta239adv.pkl   ag_newsroberta682adv.pkl           yelp_polarityroberta259Benign.pkl\n",
            "ag_newsroberta23adv.pkl    ag_newsroberta683adv.pkl           yelp_polarityroberta25Benign.pkl\n",
            "ag_newsroberta240adv.pkl   ag_newsroberta684adv.pkl           yelp_polarityroberta260Benign.pkl\n",
            "ag_newsroberta241adv.pkl   ag_newsroberta685adv.pkl           yelp_polarityroberta261Benign.pkl\n",
            "ag_newsroberta242adv.pkl   ag_newsroberta686adv.pkl           yelp_polarityroberta262Benign.pkl\n",
            "ag_newsroberta243adv.pkl   ag_newsroberta687adv.pkl           yelp_polarityroberta263Benign.pkl\n",
            "ag_newsroberta244adv.pkl   ag_newsroberta688adv.pkl           yelp_polarityroberta264Benign.pkl\n",
            "ag_newsroberta245adv.pkl   ag_newsroberta689adv.pkl           yelp_polarityroberta265Benign.pkl\n",
            "ag_newsroberta246adv.pkl   ag_newsroberta68adv.pkl            yelp_polarityroberta266Benign.pkl\n",
            "ag_newsroberta247adv.pkl   ag_newsroberta690adv.pkl           yelp_polarityroberta267Benign.pkl\n",
            "ag_newsroberta248adv.pkl   ag_newsroberta691adv.pkl           yelp_polarityroberta268Benign.pkl\n",
            "ag_newsroberta249adv.pkl   ag_newsroberta692adv.pkl           yelp_polarityroberta269Benign.pkl\n",
            "ag_newsroberta24adv.pkl    ag_newsroberta693adv.pkl           yelp_polarityroberta26Benign.pkl\n",
            "ag_newsroberta250adv.pkl   ag_newsroberta694adv.pkl           yelp_polarityroberta270Benign.pkl\n",
            "ag_newsroberta251adv.pkl   ag_newsroberta695adv.pkl           yelp_polarityroberta271Benign.pkl\n",
            "ag_newsroberta252adv.pkl   ag_newsroberta696adv.pkl           yelp_polarityroberta272Benign.pkl\n",
            "ag_newsroberta253adv.pkl   ag_newsroberta697adv.pkl           yelp_polarityroberta273Benign.pkl\n",
            "ag_newsroberta254adv.pkl   ag_newsroberta698adv.pkl           yelp_polarityroberta274Benign.pkl\n",
            "ag_newsroberta255adv.pkl   ag_newsroberta699adv.pkl           yelp_polarityroberta275Benign.pkl\n",
            "ag_newsroberta256adv.pkl   ag_newsroberta69adv.pkl            yelp_polarityroberta276Benign.pkl\n",
            "ag_newsroberta257adv.pkl   ag_newsroberta6adv.pkl             yelp_polarityroberta277Benign.pkl\n",
            "ag_newsroberta258adv.pkl   ag_newsroberta700adv.pkl           yelp_polarityroberta278Benign.pkl\n",
            "ag_newsroberta259adv.pkl   ag_newsroberta701adv.pkl           yelp_polarityroberta279Benign.pkl\n",
            "ag_newsroberta25adv.pkl    ag_newsroberta702adv.pkl           yelp_polarityroberta27Benign.pkl\n",
            "ag_newsroberta260adv.pkl   ag_newsroberta703adv.pkl           yelp_polarityroberta280Benign.pkl\n",
            "ag_newsroberta261adv.pkl   ag_newsroberta704adv.pkl           yelp_polarityroberta281Benign.pkl\n",
            "ag_newsroberta262adv.pkl   ag_newsroberta705adv.pkl           yelp_polarityroberta282Benign.pkl\n",
            "ag_newsroberta263adv.pkl   ag_newsroberta706adv.pkl           yelp_polarityroberta283Benign.pkl\n",
            "ag_newsroberta264adv.pkl   ag_newsroberta707adv.pkl           yelp_polarityroberta284Benign.pkl\n",
            "ag_newsroberta265adv.pkl   ag_newsroberta708adv.pkl           yelp_polarityroberta285Benign.pkl\n",
            "ag_newsroberta266adv.pkl   ag_newsroberta709adv.pkl           yelp_polarityroberta286Benign.pkl\n",
            "ag_newsroberta267adv.pkl   ag_newsroberta70adv.pkl            yelp_polarityroberta287Benign.pkl\n",
            "ag_newsroberta268adv.pkl   ag_newsroberta710adv.pkl           yelp_polarityroberta288Benign.pkl\n",
            "ag_newsroberta269adv.pkl   ag_newsroberta711adv.pkl           yelp_polarityroberta289Benign.pkl\n",
            "ag_newsroberta26adv.pkl    ag_newsroberta712adv.pkl           yelp_polarityroberta28Benign.pkl\n",
            "ag_newsroberta270adv.pkl   ag_newsroberta713adv.pkl           yelp_polarityroberta290Benign.pkl\n",
            "ag_newsroberta271adv.pkl   ag_newsroberta714adv.pkl           yelp_polarityroberta291Benign.pkl\n",
            "ag_newsroberta272adv.pkl   ag_newsroberta715adv.pkl           yelp_polarityroberta292Benign.pkl\n",
            "ag_newsroberta273adv.pkl   ag_newsroberta716adv.pkl           yelp_polarityroberta293Benign.pkl\n",
            "ag_newsroberta274adv.pkl   ag_newsroberta717adv.pkl           yelp_polarityroberta294Benign.pkl\n",
            "ag_newsroberta275adv.pkl   ag_newsroberta718adv.pkl           yelp_polarityroberta295Benign.pkl\n",
            "ag_newsroberta276adv.pkl   ag_newsroberta719adv.pkl           yelp_polarityroberta296Benign.pkl\n",
            "ag_newsroberta277adv.pkl   ag_newsroberta71adv.pkl            yelp_polarityroberta297Benign.pkl\n",
            "ag_newsroberta278adv.pkl   ag_newsroberta720adv.pkl           yelp_polarityroberta298Benign.pkl\n",
            "ag_newsroberta279adv.pkl   ag_newsroberta721adv.pkl           yelp_polarityroberta299Benign.pkl\n",
            "ag_newsroberta27adv.pkl    ag_newsroberta722adv.pkl           yelp_polarityroberta29Benign.pkl\n",
            "ag_newsroberta280adv.pkl   ag_newsroberta723adv.pkl           yelp_polarityroberta2Benign.pkl\n",
            "ag_newsroberta281adv.pkl   ag_newsroberta724adv.pkl           yelp_polarityroberta300Benign.pkl\n",
            "ag_newsroberta282adv.pkl   ag_newsroberta725adv.pkl           yelp_polarityroberta301Benign.pkl\n",
            "ag_newsroberta283adv.pkl   ag_newsroberta726adv.pkl           yelp_polarityroberta302Benign.pkl\n",
            "ag_newsroberta284adv.pkl   ag_newsroberta727adv.pkl           yelp_polarityroberta303Benign.pkl\n",
            "ag_newsroberta285adv.pkl   ag_newsroberta728adv.pkl           yelp_polarityroberta304Benign.pkl\n",
            "ag_newsroberta286adv.pkl   ag_newsroberta729adv.pkl           yelp_polarityroberta305Benign.pkl\n",
            "ag_newsroberta287adv.pkl   ag_newsroberta72adv.pkl            yelp_polarityroberta306Benign.pkl\n",
            "ag_newsroberta288adv.pkl   ag_newsroberta730adv.pkl           yelp_polarityroberta307Benign.pkl\n",
            "ag_newsroberta289adv.pkl   ag_newsroberta731adv.pkl           yelp_polarityroberta308Benign.pkl\n",
            "ag_newsroberta28adv.pkl    ag_newsroberta732adv.pkl           yelp_polarityroberta309Benign.pkl\n",
            "ag_newsroberta290adv.pkl   ag_newsroberta733adv.pkl           yelp_polarityroberta30Benign.pkl\n",
            "ag_newsroberta291adv.pkl   ag_newsroberta734adv.pkl           yelp_polarityroberta310Benign.pkl\n",
            "ag_newsroberta292adv.pkl   ag_newsroberta735adv.pkl           yelp_polarityroberta311Benign.pkl\n",
            "ag_newsroberta293adv.pkl   ag_newsroberta736adv.pkl           yelp_polarityroberta312Benign.pkl\n",
            "ag_newsroberta294adv.pkl   ag_newsroberta737adv.pkl           yelp_polarityroberta313Benign.pkl\n",
            "ag_newsroberta295adv.pkl   ag_newsroberta738adv.pkl           yelp_polarityroberta314Benign.pkl\n",
            "ag_newsroberta296adv.pkl   ag_newsroberta739adv.pkl           yelp_polarityroberta315Benign.pkl\n",
            "ag_newsroberta297adv.pkl   ag_newsroberta73adv.pkl            yelp_polarityroberta316Benign.pkl\n",
            "ag_newsroberta298adv.pkl   ag_newsroberta740adv.pkl           yelp_polarityroberta317Benign.pkl\n",
            "ag_newsroberta299adv.pkl   ag_newsroberta741adv.pkl           yelp_polarityroberta318Benign.pkl\n",
            "ag_newsroberta29adv.pkl    ag_newsroberta742adv.pkl           yelp_polarityroberta319Benign.pkl\n",
            "ag_newsroberta2adv.pkl     ag_newsroberta743adv.pkl           yelp_polarityroberta31Benign.pkl\n",
            "ag_newsroberta300adv.pkl   ag_newsroberta744adv.pkl           yelp_polarityroberta320Benign.pkl\n",
            "ag_newsroberta301adv.pkl   ag_newsroberta745adv.pkl           yelp_polarityroberta321Benign.pkl\n",
            "ag_newsroberta302adv.pkl   ag_newsroberta746adv.pkl           yelp_polarityroberta322Benign.pkl\n",
            "ag_newsroberta303adv.pkl   ag_newsroberta747adv.pkl           yelp_polarityroberta323Benign.pkl\n",
            "ag_newsroberta304adv.pkl   ag_newsroberta748adv.pkl           yelp_polarityroberta324Benign.pkl\n",
            "ag_newsroberta305adv.pkl   ag_newsroberta749adv.pkl           yelp_polarityroberta325Benign.pkl\n",
            "ag_newsroberta306adv.pkl   ag_newsroberta74adv.pkl            yelp_polarityroberta326Benign.pkl\n",
            "ag_newsroberta307adv.pkl   ag_newsroberta750adv.pkl           yelp_polarityroberta327Benign.pkl\n",
            "ag_newsroberta308adv.pkl   ag_newsroberta751adv.pkl           yelp_polarityroberta328Benign.pkl\n",
            "ag_newsroberta309adv.pkl   ag_newsroberta752adv.pkl           yelp_polarityroberta329Benign.pkl\n",
            "ag_newsroberta30adv.pkl    ag_newsroberta753adv.pkl           yelp_polarityroberta32Benign.pkl\n",
            "ag_newsroberta310adv.pkl   ag_newsroberta754adv.pkl           yelp_polarityroberta330Benign.pkl\n",
            "ag_newsroberta311adv.pkl   ag_newsroberta755adv.pkl           yelp_polarityroberta331Benign.pkl\n",
            "ag_newsroberta312adv.pkl   ag_newsroberta756adv.pkl           yelp_polarityroberta332Benign.pkl\n",
            "ag_newsroberta313adv.pkl   ag_newsroberta757adv.pkl           yelp_polarityroberta333Benign.pkl\n",
            "ag_newsroberta314adv.pkl   ag_newsroberta758adv.pkl           yelp_polarityroberta334Benign.pkl\n",
            "ag_newsroberta315adv.pkl   ag_newsroberta759adv.pkl           yelp_polarityroberta335Benign.pkl\n",
            "ag_newsroberta316adv.pkl   ag_newsroberta75adv.pkl            yelp_polarityroberta336Benign.pkl\n",
            "ag_newsroberta317adv.pkl   ag_newsroberta760adv.pkl           yelp_polarityroberta337Benign.pkl\n",
            "ag_newsroberta318adv.pkl   ag_newsroberta761adv.pkl           yelp_polarityroberta338Benign.pkl\n",
            "ag_newsroberta319adv.pkl   ag_newsroberta762adv.pkl           yelp_polarityroberta339Benign.pkl\n",
            "ag_newsroberta31adv.pkl    ag_newsroberta763adv.pkl           yelp_polarityroberta33Benign.pkl\n",
            "ag_newsroberta320adv.pkl   ag_newsroberta764adv.pkl           yelp_polarityroberta340Benign.pkl\n",
            "ag_newsroberta321adv.pkl   ag_newsroberta765adv.pkl           yelp_polarityroberta341Benign.pkl\n",
            "ag_newsroberta322adv.pkl   ag_newsroberta766adv.pkl           yelp_polarityroberta342Benign.pkl\n",
            "ag_newsroberta323adv.pkl   ag_newsroberta767adv.pkl           yelp_polarityroberta343Benign.pkl\n",
            "ag_newsroberta324adv.pkl   ag_newsroberta768adv.pkl           yelp_polarityroberta344Benign.pkl\n",
            "ag_newsroberta325adv.pkl   ag_newsroberta769adv.pkl           yelp_polarityroberta345Benign.pkl\n",
            "ag_newsroberta326adv.pkl   ag_newsroberta76adv.pkl            yelp_polarityroberta346Benign.pkl\n",
            "ag_newsroberta327adv.pkl   ag_newsroberta770adv.pkl           yelp_polarityroberta347Benign.pkl\n",
            "ag_newsroberta328adv.pkl   ag_newsroberta771adv.pkl           yelp_polarityroberta348Benign.pkl\n",
            "ag_newsroberta329adv.pkl   ag_newsroberta772adv.pkl           yelp_polarityroberta349Benign.pkl\n",
            "ag_newsroberta32adv.pkl    ag_newsroberta773adv.pkl           yelp_polarityroberta34Benign.pkl\n",
            "ag_newsroberta330adv.pkl   ag_newsroberta774adv.pkl           yelp_polarityroberta350Benign.pkl\n",
            "ag_newsroberta331adv.pkl   ag_newsroberta775adv.pkl           yelp_polarityroberta351Benign.pkl\n",
            "ag_newsroberta332adv.pkl   ag_newsroberta776adv.pkl           yelp_polarityroberta352Benign.pkl\n",
            "ag_newsroberta333adv.pkl   ag_newsroberta777adv.pkl           yelp_polarityroberta353Benign.pkl\n",
            "ag_newsroberta334adv.pkl   ag_newsroberta778adv.pkl           yelp_polarityroberta354Benign.pkl\n",
            "ag_newsroberta335adv.pkl   ag_newsroberta779adv.pkl           yelp_polarityroberta355Benign.pkl\n",
            "ag_newsroberta336adv.pkl   ag_newsroberta77adv.pkl            yelp_polarityroberta356Benign.pkl\n",
            "ag_newsroberta337adv.pkl   ag_newsroberta780adv.pkl           yelp_polarityroberta357Benign.pkl\n",
            "ag_newsroberta338adv.pkl   ag_newsroberta781adv.pkl           yelp_polarityroberta358Benign.pkl\n",
            "ag_newsroberta339adv.pkl   ag_newsroberta782adv.pkl           yelp_polarityroberta359Benign.pkl\n",
            "ag_newsroberta33adv.pkl    ag_newsroberta783adv.pkl           yelp_polarityroberta35Benign.pkl\n",
            "ag_newsroberta340adv.pkl   ag_newsroberta784adv.pkl           yelp_polarityroberta360Benign.pkl\n",
            "ag_newsroberta341adv.pkl   ag_newsroberta785adv.pkl           yelp_polarityroberta361Benign.pkl\n",
            "ag_newsroberta342adv.pkl   ag_newsroberta786adv.pkl           yelp_polarityroberta362Benign.pkl\n",
            "ag_newsroberta343adv.pkl   ag_newsroberta787adv.pkl           yelp_polarityroberta363Benign.pkl\n",
            "ag_newsroberta344adv.pkl   ag_newsroberta788adv.pkl           yelp_polarityroberta364Benign.pkl\n",
            "ag_newsroberta345adv.pkl   ag_newsroberta789adv.pkl           yelp_polarityroberta365Benign.pkl\n",
            "ag_newsroberta346adv.pkl   ag_newsroberta78adv.pkl            yelp_polarityroberta366Benign.pkl\n",
            "ag_newsroberta347adv.pkl   ag_newsroberta790adv.pkl           yelp_polarityroberta367Benign.pkl\n",
            "ag_newsroberta348adv.pkl   ag_newsroberta791adv.pkl           yelp_polarityroberta368Benign.pkl\n",
            "ag_newsroberta349adv.pkl   ag_newsroberta792adv.pkl           yelp_polarityroberta369Benign.pkl\n",
            "ag_newsroberta34adv.pkl    ag_newsroberta793adv.pkl           yelp_polarityroberta36Benign.pkl\n",
            "ag_newsroberta350adv.pkl   ag_newsroberta794adv.pkl           yelp_polarityroberta370Benign.pkl\n",
            "ag_newsroberta351adv.pkl   ag_newsroberta795adv.pkl           yelp_polarityroberta371Benign.pkl\n",
            "ag_newsroberta352adv.pkl   ag_newsroberta796adv.pkl           yelp_polarityroberta372Benign.pkl\n",
            "ag_newsroberta353adv.pkl   ag_newsroberta797adv.pkl           yelp_polarityroberta373Benign.pkl\n",
            "ag_newsroberta354adv.pkl   ag_newsroberta798adv.pkl           yelp_polarityroberta374Benign.pkl\n",
            "ag_newsroberta355adv.pkl   ag_newsroberta799adv.pkl           yelp_polarityroberta375Benign.pkl\n",
            "ag_newsroberta356adv.pkl   ag_newsroberta79adv.pkl            yelp_polarityroberta376Benign.pkl\n",
            "ag_newsroberta357adv.pkl   ag_newsroberta7adv.pkl             yelp_polarityroberta377Benign.pkl\n",
            "ag_newsroberta358adv.pkl   ag_newsroberta800adv.pkl           yelp_polarityroberta378Benign.pkl\n",
            "ag_newsroberta359adv.pkl   ag_newsroberta801adv.pkl           yelp_polarityroberta379Benign.pkl\n",
            "ag_newsroberta35adv.pkl    ag_newsroberta802adv.pkl           yelp_polarityroberta37Benign.pkl\n",
            "ag_newsroberta360adv.pkl   ag_newsroberta803adv.pkl           yelp_polarityroberta380Benign.pkl\n",
            "ag_newsroberta361adv.pkl   ag_newsroberta804adv.pkl           yelp_polarityroberta381Benign.pkl\n",
            "ag_newsroberta362adv.pkl   ag_newsroberta805adv.pkl           yelp_polarityroberta382Benign.pkl\n",
            "ag_newsroberta363adv.pkl   ag_newsroberta806adv.pkl           yelp_polarityroberta383Benign.pkl\n",
            "ag_newsroberta364adv.pkl   ag_newsroberta807adv.pkl           yelp_polarityroberta384Benign.pkl\n",
            "ag_newsroberta365adv.pkl   ag_newsroberta808adv.pkl           yelp_polarityroberta385Benign.pkl\n",
            "ag_newsroberta366adv.pkl   ag_newsroberta809adv.pkl           yelp_polarityroberta386Benign.pkl\n",
            "ag_newsroberta367adv.pkl   ag_newsroberta80adv.pkl            yelp_polarityroberta387Benign.pkl\n",
            "ag_newsroberta368adv.pkl   ag_newsroberta810adv.pkl           yelp_polarityroberta388Benign.pkl\n",
            "ag_newsroberta369adv.pkl   ag_newsroberta811adv.pkl           yelp_polarityroberta389Benign.pkl\n",
            "ag_newsroberta36adv.pkl    ag_newsroberta812adv.pkl           yelp_polarityroberta38Benign.pkl\n",
            "ag_newsroberta370adv.pkl   ag_newsroberta813adv.pkl           yelp_polarityroberta390Benign.pkl\n",
            "ag_newsroberta371adv.pkl   ag_newsroberta814adv.pkl           yelp_polarityroberta391Benign.pkl\n",
            "ag_newsroberta372adv.pkl   ag_newsroberta815adv.pkl           yelp_polarityroberta392Benign.pkl\n",
            "ag_newsroberta373adv.pkl   ag_newsroberta816adv.pkl           yelp_polarityroberta393Benign.pkl\n",
            "ag_newsroberta374adv.pkl   ag_newsroberta817adv.pkl           yelp_polarityroberta394Benign.pkl\n",
            "ag_newsroberta375adv.pkl   ag_newsroberta818adv.pkl           yelp_polarityroberta395Benign.pkl\n",
            "ag_newsroberta376adv.pkl   ag_newsroberta819adv.pkl           yelp_polarityroberta396Benign.pkl\n",
            "ag_newsroberta377adv.pkl   ag_newsroberta81adv.pkl            yelp_polarityroberta397Benign.pkl\n",
            "ag_newsroberta378adv.pkl   ag_newsroberta820adv.pkl           yelp_polarityroberta398Benign.pkl\n",
            "ag_newsroberta379adv.pkl   ag_newsroberta821adv.pkl           yelp_polarityroberta399Benign.pkl\n",
            "ag_newsroberta37adv.pkl    ag_newsroberta822adv.pkl           yelp_polarityroberta39Benign.pkl\n",
            "ag_newsroberta380adv.pkl   ag_newsroberta823adv.pkl           yelp_polarityroberta3Benign.pkl\n",
            "ag_newsroberta381adv.pkl   ag_newsroberta824adv.pkl           yelp_polarityroberta400Benign.pkl\n",
            "ag_newsroberta382adv.pkl   ag_newsroberta825adv.pkl           yelp_polarityroberta401Benign.pkl\n",
            "ag_newsroberta383adv.pkl   ag_newsroberta826adv.pkl           yelp_polarityroberta402Benign.pkl\n",
            "ag_newsroberta384adv.pkl   ag_newsroberta827adv.pkl           yelp_polarityroberta403Benign.pkl\n",
            "ag_newsroberta385adv.pkl   ag_newsroberta828adv.pkl           yelp_polarityroberta404Benign.pkl\n",
            "ag_newsroberta386adv.pkl   ag_newsroberta829adv.pkl           yelp_polarityroberta405Benign.pkl\n",
            "ag_newsroberta387adv.pkl   ag_newsroberta82adv.pkl            yelp_polarityroberta406Benign.pkl\n",
            "ag_newsroberta388adv.pkl   ag_newsroberta830adv.pkl           yelp_polarityroberta407Benign.pkl\n",
            "ag_newsroberta389adv.pkl   ag_newsroberta831adv.pkl           yelp_polarityroberta408Benign.pkl\n",
            "ag_newsroberta38adv.pkl    ag_newsroberta832adv.pkl           yelp_polarityroberta409Benign.pkl\n",
            "ag_newsroberta390adv.pkl   ag_newsroberta833adv.pkl           yelp_polarityroberta40Benign.pkl\n",
            "ag_newsroberta391adv.pkl   ag_newsroberta834adv.pkl           yelp_polarityroberta410Benign.pkl\n",
            "ag_newsroberta392adv.pkl   ag_newsroberta835adv.pkl           yelp_polarityroberta411Benign.pkl\n",
            "ag_newsroberta393adv.pkl   ag_newsroberta836adv.pkl           yelp_polarityroberta412Benign.pkl\n",
            "ag_newsroberta394adv.pkl   ag_newsroberta837adv.pkl           yelp_polarityroberta413Benign.pkl\n",
            "ag_newsroberta395adv.pkl   ag_newsroberta838adv.pkl           yelp_polarityroberta414Benign.pkl\n",
            "ag_newsroberta396adv.pkl   ag_newsroberta839adv.pkl           yelp_polarityroberta415Benign.pkl\n",
            "ag_newsroberta397adv.pkl   ag_newsroberta83adv.pkl            yelp_polarityroberta416Benign.pkl\n",
            "ag_newsroberta398adv.pkl   ag_newsroberta840adv.pkl           yelp_polarityroberta417Benign.pkl\n",
            "ag_newsroberta399adv.pkl   ag_newsroberta841adv.pkl           yelp_polarityroberta418Benign.pkl\n",
            "ag_newsroberta39adv.pkl    ag_newsroberta842adv.pkl           yelp_polarityroberta419Benign.pkl\n",
            "ag_newsroberta3adv.pkl     ag_newsroberta843adv.pkl           yelp_polarityroberta41Benign.pkl\n",
            "ag_newsroberta400adv.pkl   ag_newsroberta844adv.pkl           yelp_polarityroberta420Benign.pkl\n",
            "ag_newsroberta401adv.pkl   ag_newsroberta845adv.pkl           yelp_polarityroberta421Benign.pkl\n",
            "ag_newsroberta402adv.pkl   ag_newsroberta846adv.pkl           yelp_polarityroberta422Benign.pkl\n",
            "ag_newsroberta403adv.pkl   ag_newsroberta847adv.pkl           yelp_polarityroberta423Benign.pkl\n",
            "ag_newsroberta404adv.pkl   ag_newsroberta848adv.pkl           yelp_polarityroberta424Benign.pkl\n",
            "ag_newsroberta405adv.pkl   ag_newsroberta849adv.pkl           yelp_polarityroberta425Benign.pkl\n",
            "ag_newsroberta406adv.pkl   ag_newsroberta84adv.pkl            yelp_polarityroberta426Benign.pkl\n",
            "ag_newsroberta407adv.pkl   ag_newsroberta850adv.pkl           yelp_polarityroberta427Benign.pkl\n",
            "ag_newsroberta408adv.pkl   ag_newsroberta851adv.pkl           yelp_polarityroberta428Benign.pkl\n",
            "ag_newsroberta409adv.pkl   ag_newsroberta852adv.pkl           yelp_polarityroberta429Benign.pkl\n",
            "ag_newsroberta40adv.pkl    ag_newsroberta853adv.pkl           yelp_polarityroberta42Benign.pkl\n",
            "ag_newsroberta410adv.pkl   ag_newsroberta854adv.pkl           yelp_polarityroberta430Benign.pkl\n",
            "ag_newsroberta411adv.pkl   ag_newsroberta855adv.pkl           yelp_polarityroberta431Benign.pkl\n",
            "ag_newsroberta412adv.pkl   ag_newsroberta856adv.pkl           yelp_polarityroberta432Benign.pkl\n",
            "ag_newsroberta413adv.pkl   ag_newsroberta857adv.pkl           yelp_polarityroberta434Benign.pkl\n",
            "ag_newsroberta414adv.pkl   ag_newsroberta858adv.pkl           yelp_polarityroberta435Benign.pkl\n",
            "ag_newsroberta415adv.pkl   ag_newsroberta859adv.pkl           yelp_polarityroberta436Benign.pkl\n",
            "ag_newsroberta416adv.pkl   ag_newsroberta85adv.pkl            yelp_polarityroberta437Benign.pkl\n",
            "ag_newsroberta417adv.pkl   ag_newsroberta860adv.pkl           yelp_polarityroberta438Benign.pkl\n",
            "ag_newsroberta418adv.pkl   ag_newsroberta861adv.pkl           yelp_polarityroberta439Benign.pkl\n",
            "ag_newsroberta419adv.pkl   ag_newsroberta862adv.pkl           yelp_polarityroberta43Benign.pkl\n",
            "ag_newsroberta41adv.pkl    ag_newsroberta863adv.pkl           yelp_polarityroberta440Benign.pkl\n",
            "ag_newsroberta420adv.pkl   ag_newsroberta864adv.pkl           yelp_polarityroberta441Benign.pkl\n",
            "ag_newsroberta421adv.pkl   ag_newsroberta865adv.pkl           yelp_polarityroberta442Benign.pkl\n",
            "ag_newsroberta422adv.pkl   ag_newsroberta866adv.pkl           yelp_polarityroberta443Benign.pkl\n",
            "ag_newsroberta423adv.pkl   ag_newsroberta867adv.pkl           yelp_polarityroberta444Benign.pkl\n",
            "ag_newsroberta424adv.pkl   ag_newsroberta868adv.pkl           yelp_polarityroberta445Benign.pkl\n",
            "ag_newsroberta425adv.pkl   ag_newsroberta869adv.pkl           yelp_polarityroberta446Benign.pkl\n",
            "ag_newsroberta426adv.pkl   ag_newsroberta86adv.pkl            yelp_polarityroberta447Benign.pkl\n",
            "ag_newsroberta427adv.pkl   ag_newsroberta870adv.pkl           yelp_polarityroberta448Benign.pkl\n",
            "ag_newsroberta428adv.pkl   ag_newsroberta871adv.pkl           yelp_polarityroberta449Benign.pkl\n",
            "ag_newsroberta429adv.pkl   ag_newsroberta872adv.pkl           yelp_polarityroberta44Benign.pkl\n",
            "ag_newsroberta42adv.pkl    ag_newsroberta873adv.pkl           yelp_polarityroberta450Benign.pkl\n",
            "ag_newsroberta430adv.pkl   ag_newsroberta874adv.pkl           yelp_polarityroberta451Benign.pkl\n",
            "ag_newsroberta431adv.pkl   ag_newsroberta875adv.pkl           yelp_polarityroberta452Benign.pkl\n",
            "ag_newsroberta432adv.pkl   ag_newsroberta876adv.pkl           yelp_polarityroberta453Benign.pkl\n",
            "ag_newsroberta433adv.pkl   ag_newsroberta877adv.pkl           yelp_polarityroberta454Benign.pkl\n",
            "ag_newsroberta434adv.pkl   ag_newsroberta878adv.pkl           yelp_polarityroberta455Benign.pkl\n",
            "ag_newsroberta435adv.pkl   ag_newsroberta879adv.pkl           yelp_polarityroberta456Benign.pkl\n",
            "ag_newsroberta436adv.pkl   ag_newsroberta87adv.pkl            yelp_polarityroberta457Benign.pkl\n",
            "ag_newsroberta437adv.pkl   ag_newsroberta880adv.pkl           yelp_polarityroberta458Benign.pkl\n",
            "ag_newsroberta438adv.pkl   ag_newsroberta881adv.pkl           yelp_polarityroberta459Benign.pkl\n",
            "ag_newsroberta439adv.pkl   ag_newsroberta882adv.pkl           yelp_polarityroberta45Benign.pkl\n",
            "ag_newsroberta43adv.pkl    ag_newsroberta883adv.pkl           yelp_polarityroberta460Benign.pkl\n",
            "ag_newsroberta440adv.pkl   ag_newsroberta884adv.pkl           yelp_polarityroberta461Benign.pkl\n",
            "ag_newsroberta441adv.pkl   ag_newsroberta885adv.pkl           yelp_polarityroberta462Benign.pkl\n",
            "ag_newsroberta442adv.pkl   ag_newsroberta886adv.pkl           yelp_polarityroberta463Benign.pkl\n",
            "ag_newsroberta443adv.pkl   ag_newsroberta887adv.pkl           yelp_polarityroberta464Benign.pkl\n",
            "ag_newsroberta444adv.pkl   ag_newsroberta888adv.pkl           yelp_polarityroberta465Benign.pkl\n",
            "ag_newsroberta445adv.pkl   ag_newsroberta889adv.pkl           yelp_polarityroberta466Benign.pkl\n",
            "ag_newsroberta446adv.pkl   ag_newsroberta88adv.pkl            yelp_polarityroberta467Benign.pkl\n",
            "ag_newsroberta447adv.pkl   ag_newsroberta890adv.pkl           yelp_polarityroberta468Benign.pkl\n",
            "ag_newsroberta448adv.pkl   ag_newsroberta891adv.pkl           yelp_polarityroberta469Benign.pkl\n",
            "ag_newsroberta449adv.pkl   ag_newsroberta892adv.pkl           yelp_polarityroberta46Benign.pkl\n",
            "ag_newsroberta44adv.pkl    ag_newsroberta893adv.pkl           yelp_polarityroberta470Benign.pkl\n",
            "ag_newsroberta450adv.pkl   ag_newsroberta894adv.pkl           yelp_polarityroberta471Benign.pkl\n",
            "ag_newsroberta451adv.pkl   ag_newsroberta895adv.pkl           yelp_polarityroberta472Benign.pkl\n",
            "ag_newsroberta452adv.pkl   ag_newsroberta896adv.pkl           yelp_polarityroberta473Benign.pkl\n",
            "ag_newsroberta453adv.pkl   ag_newsroberta897adv.pkl           yelp_polarityroberta474Benign.pkl\n",
            "ag_newsroberta454adv.pkl   ag_newsroberta898adv.pkl           yelp_polarityroberta475Benign.pkl\n",
            "ag_newsroberta455adv.pkl   ag_newsroberta899adv.pkl           yelp_polarityroberta476Benign.pkl\n",
            "ag_newsroberta456adv.pkl   ag_newsroberta89adv.pkl            yelp_polarityroberta477Benign.pkl\n",
            "ag_newsroberta457adv.pkl   ag_newsroberta8adv.pkl             yelp_polarityroberta478Benign.pkl\n",
            "ag_newsroberta458adv.pkl   ag_newsroberta900adv.pkl           yelp_polarityroberta479Benign.pkl\n",
            "ag_newsroberta459adv.pkl   ag_newsroberta901adv.pkl           yelp_polarityroberta47Benign.pkl\n",
            "ag_newsroberta45adv.pkl    ag_newsroberta902adv.pkl           yelp_polarityroberta480Benign.pkl\n",
            "ag_newsroberta460adv.pkl   ag_newsroberta903adv.pkl           yelp_polarityroberta481Benign.pkl\n",
            "ag_newsroberta461adv.pkl   ag_newsroberta904adv.pkl           yelp_polarityroberta482Benign.pkl\n",
            "ag_newsroberta462adv.pkl   ag_newsroberta905adv.pkl           yelp_polarityroberta483Benign.pkl\n",
            "ag_newsroberta463adv.pkl   ag_newsroberta906adv.pkl           yelp_polarityroberta484Benign.pkl\n",
            "ag_newsroberta464adv.pkl   ag_newsroberta907adv.pkl           yelp_polarityroberta485Benign.pkl\n",
            "ag_newsroberta465adv.pkl   ag_newsroberta908adv.pkl           yelp_polarityroberta486Benign.pkl\n",
            "ag_newsroberta466adv.pkl   ag_newsroberta909adv.pkl           yelp_polarityroberta487Benign.pkl\n",
            "ag_newsroberta467adv.pkl   ag_newsroberta90adv.pkl            yelp_polarityroberta488Benign.pkl\n",
            "ag_newsroberta468adv.pkl   ag_newsroberta910adv.pkl           yelp_polarityroberta489Benign.pkl\n",
            "ag_newsroberta469adv.pkl   ag_newsroberta911adv.pkl           yelp_polarityroberta48Benign.pkl\n",
            "ag_newsroberta46adv.pkl    ag_newsroberta912adv.pkl           yelp_polarityroberta490Benign.pkl\n",
            "ag_newsroberta470adv.pkl   ag_newsroberta913adv.pkl           yelp_polarityroberta491Benign.pkl\n",
            "ag_newsroberta471adv.pkl   ag_newsroberta914adv.pkl           yelp_polarityroberta492Benign.pkl\n",
            "ag_newsroberta472adv.pkl   ag_newsroberta915adv.pkl           yelp_polarityroberta493Benign.pkl\n",
            "ag_newsroberta473adv.pkl   ag_newsroberta916adv.pkl           yelp_polarityroberta494Benign.pkl\n",
            "ag_newsroberta474adv.pkl   ag_newsroberta917adv.pkl           yelp_polarityroberta495Benign.pkl\n",
            "ag_newsroberta475adv.pkl   ag_newsroberta918adv.pkl           yelp_polarityroberta496Benign.pkl\n",
            "ag_newsroberta476adv.pkl   ag_newsroberta919adv.pkl           yelp_polarityroberta497Benign.pkl\n",
            "ag_newsroberta477adv.pkl   ag_newsroberta91adv.pkl            yelp_polarityroberta498Benign.pkl\n",
            "ag_newsroberta478adv.pkl   ag_newsroberta920adv.pkl           yelp_polarityroberta499Benign.pkl\n",
            "ag_newsroberta479adv.pkl   ag_newsroberta921adv.pkl           yelp_polarityroberta49Benign.pkl\n",
            "ag_newsroberta47adv.pkl    ag_newsroberta922adv.pkl           yelp_polarityroberta4Benign.pkl\n",
            "ag_newsroberta480adv.pkl   ag_newsroberta923adv.pkl           yelp_polarityroberta500Benign.pkl\n",
            "ag_newsroberta481adv.pkl   ag_newsroberta924adv.pkl           yelp_polarityroberta501Benign.pkl\n",
            "ag_newsroberta482adv.pkl   ag_newsroberta925adv.pkl           yelp_polarityroberta502Benign.pkl\n",
            "ag_newsroberta483adv.pkl   ag_newsroberta926adv.pkl           yelp_polarityroberta503Benign.pkl\n",
            "ag_newsroberta484adv.pkl   ag_newsroberta92adv.pkl            yelp_polarityroberta504Benign.pkl\n",
            "ag_newsroberta485adv.pkl   ag_newsroberta93adv.pkl            yelp_polarityroberta505Benign.pkl\n",
            "ag_newsroberta486adv.pkl   ag_newsroberta94adv.pkl            yelp_polarityroberta506Benign.pkl\n",
            "ag_newsroberta487adv.pkl   ag_newsroberta95adv.pkl            yelp_polarityroberta507Benign.pkl\n",
            "ag_newsroberta488adv.pkl   ag_newsroberta96adv.pkl            yelp_polarityroberta50Benign.pkl\n",
            "ag_newsroberta489adv.pkl   ag_newsroberta97adv.pkl            yelp_polarityroberta51Benign.pkl\n",
            "ag_newsroberta48adv.pkl    ag_newsroberta98adv.pkl            yelp_polarityroberta52Benign.pkl\n",
            "ag_newsroberta490adv.pkl   ag_newsroberta999Benign.pkl        yelp_polarityroberta53Benign.pkl\n",
            "ag_newsroberta491adv.pkl   ag_newsroberta99adv.pkl            yelp_polarityroberta54Benign.pkl\n",
            "ag_newsroberta492adv.pkl   ag_newsroberta9adv.pkl             yelp_polarityroberta55Benign.pkl\n",
            "ag_newsroberta493adv.pkl   ag_newsrobertabenign_adv.pkl       yelp_polarityroberta56Benign.pkl\n",
            "ag_newsroberta494adv.pkl   ag_newsrobertaBenign.pkl           yelp_polarityroberta57Benign.pkl\n",
            "ag_newsroberta495adv.pkl   classifier.py                      yelp_polarityroberta58Benign.pkl\n",
            "ag_newsroberta496adv.pkl   cnn.py                             yelp_polarityroberta59Benign.pkl\n",
            "ag_newsroberta497adv.pkl   detect.py                          yelp_polarityroberta5Benign.pkl\n",
            "ag_newsroberta498adv.pkl   ft_unm_model.py                    yelp_polarityroberta60Benign.pkl\n",
            "ag_newsroberta499adv.pkl   gen_adv.py                         yelp_polarityroberta61Benign.pkl\n",
            "ag_newsroberta49adv.pkl    get_adv.py                         yelp_polarityroberta62Benign.pkl\n",
            "ag_newsroberta4adv.pkl     imdbbert998Benign.pkl              yelp_polarityroberta63Benign.pkl\n",
            "ag_newsroberta500adv.pkl   imdbbertbenign_adv.pkl             yelp_polarityroberta64Benign.pkl\n",
            "ag_newsroberta501adv.pkl   imdbroberta995adv.pkl              yelp_polarityroberta65Benign.pkl\n",
            "ag_newsroberta502adv.pkl   imdbrobertabenign_adv.pkl          yelp_polarityroberta66Benign.pkl\n",
            "ag_newsroberta503adv.pkl   lstm.py                            yelp_polarityroberta67Benign.pkl\n",
            "ag_newsroberta504adv.pkl   miFunc_1.py                        yelp_polarityroberta68Benign.pkl\n",
            "ag_newsroberta505adv.pkl   mlp.py                             yelp_polarityroberta69Benign.pkl\n",
            "ag_newsroberta506adv.pkl   \u001b[0m\u001b[01;34m__pycache__\u001b[0m/                       yelp_polarityroberta6Benign.pkl\n",
            "ag_newsroberta507adv.pkl   README.md                          yelp_polarityroberta70Benign.pkl\n",
            "ag_newsroberta508adv.pkl   requirements.txt                   yelp_polarityroberta71Benign.pkl\n",
            "ag_newsroberta509adv.pkl   result_MLDM.csv                    yelp_polarityroberta72Benign.pkl\n",
            "ag_newsroberta50adv.pkl    result_MLDM_V.csv                  yelp_polarityroberta73Benign.pkl\n",
            "ag_newsroberta510adv.pkl   sst2bertadv.pkl                    yelp_polarityroberta74Benign.pkl\n",
            "ag_newsroberta511adv.pkl   sst2bertbenign_adv.pkl             yelp_polarityroberta75Benign.pkl\n",
            "ag_newsroberta512adv.pkl   sst2bertBenign.pkl                 yelp_polarityroberta76Benign.pkl\n",
            "ag_newsroberta513adv.pkl   sst2bertresults.pkl                yelp_polarityroberta77Benign.pkl\n",
            "ag_newsroberta514adv.pkl   sst2roberta999Benign.pkl           yelp_polarityroberta78Benign.pkl\n",
            "ag_newsroberta515adv.pkl   sst2robertaadv.pkl                 yelp_polarityroberta79Benign.pkl\n",
            "ag_newsroberta516adv.pkl   sst2robertabenign_adv.pkl          yelp_polarityroberta7Benign.pkl\n",
            "ag_newsroberta517adv.pkl   sst2robertaBenign.pkl              yelp_polarityroberta80Benign.pkl\n",
            "ag_newsroberta518adv.pkl   sst2robertaresults.pkl             yelp_polarityroberta81Benign.pkl\n",
            "ag_newsroberta519adv.pkl   victim.py                          yelp_polarityroberta82Benign.pkl\n",
            "ag_newsroberta51adv.pkl    xgb.py                             yelp_polarityroberta83Benign.pkl\n",
            "ag_newsroberta520adv.pkl   yelp_polaritybert995adv.pkl        yelp_polarityroberta84Benign.pkl\n",
            "ag_newsroberta521adv.pkl   yelp_polaritybert998Benign.pkl     yelp_polarityroberta85Benign.pkl\n",
            "ag_newsroberta522adv.pkl   yelp_polaritybertbenign_adv.pkl    yelp_polarityroberta86Benign.pkl\n",
            "ag_newsroberta523adv.pkl   yelp_polarityroberta0Benign.pkl    yelp_polarityroberta87Benign.pkl\n",
            "ag_newsroberta524adv.pkl   yelp_polarityroberta100Benign.pkl  yelp_polarityroberta88Benign.pkl\n",
            "ag_newsroberta525adv.pkl   yelp_polarityroberta101Benign.pkl  yelp_polarityroberta89Benign.pkl\n",
            "ag_newsroberta526adv.pkl   yelp_polarityroberta102Benign.pkl  yelp_polarityroberta8Benign.pkl\n",
            "ag_newsroberta527adv.pkl   yelp_polarityroberta103Benign.pkl  yelp_polarityroberta90Benign.pkl\n",
            "ag_newsroberta528adv.pkl   yelp_polarityroberta104Benign.pkl  yelp_polarityroberta91Benign.pkl\n",
            "ag_newsroberta529adv.pkl   yelp_polarityroberta105Benign.pkl  yelp_polarityroberta92Benign.pkl\n",
            "ag_newsroberta52adv.pkl    yelp_polarityroberta106Benign.pkl  yelp_polarityroberta93Benign.pkl\n",
            "ag_newsroberta530adv.pkl   yelp_polarityroberta107Benign.pkl  yelp_polarityroberta94Benign.pkl\n",
            "ag_newsroberta531adv.pkl   yelp_polarityroberta108Benign.pkl  yelp_polarityroberta95Benign.pkl\n",
            "ag_newsroberta532adv.pkl   yelp_polarityroberta109Benign.pkl  yelp_polarityroberta96Benign.pkl\n",
            "ag_newsroberta533adv.pkl   yelp_polarityroberta10Benign.pkl   yelp_polarityroberta97Benign.pkl\n",
            "ag_newsroberta534adv.pkl   yelp_polarityroberta110Benign.pkl  yelp_polarityroberta98Benign.pkl\n",
            "ag_newsroberta535adv.pkl   yelp_polarityroberta111Benign.pkl  yelp_polarityroberta995adv.pkl\n",
            "ag_newsroberta536adv.pkl   yelp_polarityroberta112Benign.pkl  yelp_polarityroberta999Benign.pkl\n",
            "ag_newsroberta537adv.pkl   yelp_polarityroberta113Benign.pkl  yelp_polarityroberta99Benign.pkl\n",
            "ag_newsroberta538adv.pkl   yelp_polarityroberta114Benign.pkl  yelp_polarityroberta9Benign.pkl\n",
            "ag_newsroberta539adv.pkl   yelp_polarityroberta115Benign.pkl  yelp_polarityrobertabenign_adv.pkl\n",
            "ag_newsroberta53adv.pkl    yelp_polarityroberta116Benign.pkl\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj-cVCFXvs6Y",
        "outputId": "e61cc32d-b089-46fc-da57-a8634e1d5ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-757a9555951e>:1: PendingDeprecationWarning: lib2to3 package is deprecated and may not be able to parse Python 3.10+\n",
            "  from lib2to3.pgen2 import token\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "textattack: Updating TextAttack package dependencies.\n",
            "textattack: Downloading NLTK required packages.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:671: ImportWarning: APICoreClientInfoImportHook.exec_module() not found; falling back to load_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if (distutils.version.LooseVersion(tf.__version__) <\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py:58: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  distutils.version.LooseVersion(required_tensorflow_version)):\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ],
      "source": [
        "from lib2to3.pgen2 import token\n",
        "\n",
        "# from shutil import register_unpack_format\n",
        "# from statistics import mode\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import textattack\n",
        "import torch\n",
        "import re\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from sklearn.svm import SVC\n",
        "from textattack.models.helpers import (GloveEmbeddingLayer,\n",
        "                                       LSTMForClassification,\n",
        "                                       WordCNNForClassification)\n",
        "from textattack.models.helpers.utils import load_cached_state_dict\n",
        "from textattack.models.tokenizers import glove_tokenizer\n",
        "from textattack.shared import utils\n",
        "from miFunc_1 import (mask_string,\n",
        "                      mlm_ummask,\n",
        "                      masked_str_token,\n",
        "                      get_mlm_um_sen,\n",
        "                      gap_infer_acc_f1)\n",
        "from classifier import euq_label,mean_mean_label,compute_score_difference_padding\n",
        "from victim import predict_class,load_base_victim_model\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "                        AlbertForMaskedLM, AlbertTokenizer,\n",
        "                        BertForMaskedLM, BertTokenizer, DistilBertModel,\n",
        "                        DistilBertTokenizer, RobertaForMaskedLM,\n",
        "                        RobertaTokenizer,\n",
        "                        AutoModelForSequenceClassification,AutoTokenizer)\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "#clean_df=pd.read_csv(savepath+datasetname+'_bert'+'_clean_data.csv')\n",
        "def get_adv(path):\n",
        "\n",
        "      x_benigns=pd.read_csv(path+'_clean_data.csv')\n",
        "      x_advs=pd.read_csv(path+'_x_advs.txt')\n",
        "      return x_benigns,x_advs\n",
        "\n",
        "def write_metric(x, file_name):\n",
        "    with open(file_name, \"w\") as f:\n",
        "        x_t = x.tolist()\n",
        "        f.write(str(x_t))\n",
        "\n",
        "\n",
        "def get_ben_adv_metric(path):\n",
        "    def re_all(path):\n",
        "        with open(path, \"r\") as f:\n",
        "            data_al= f.readlines()\n",
        "        return data_al\n",
        "    data_t= re_all(path)\n",
        "    data = eval(data_t[0])\n",
        "    return data\n",
        "\n",
        "\n",
        "def write_um_sentences(x, file_name):\n",
        "    with open(file_name, \"w\") as f:\n",
        "       for idx in range(len(x)):\n",
        "            f.write(str(x[idx] )+ '\\n')\n",
        "\n",
        "def get_um_sentences_list(path):\n",
        "    data=[]\n",
        "    with open(path, \"r\") as f:\n",
        "         data_ = f.readlines()\n",
        "    for dd in data_:\n",
        "        dd_t =eval(dd)\n",
        "        data.append(dd_t)\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mlz09q1zJ5M"
      },
      "source": [
        "##Victim model BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nRPQvZFwZZC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854,
          "referenced_widgets": [
            "f315ba1cc0b3457d80b1abbfe5f6fc5e",
            "5dbb161b3839446fb0e535cf0c23a0e8",
            "3e3920fc40c34d0092105e60b3f88957",
            "059e655f22e441d3952fd76674227fb0",
            "225ae5b976ed44df90ae0d74762f45b4",
            "d94f92a4838547a8b6dc0c8adda2d5b9",
            "bc0c5be1956940a7a45e37a46dbb1560",
            "0a6b2dba5dff45d3aacc296d0097a555",
            "3fefacf8b4a045d596a1e02b95c8d828",
            "a6ca550c69a84539b7bece89265a2a0f",
            "56f82cce2b824ed381063229ed0045b1",
            "e8793587c4634505b225a8b907ad46c1",
            "fe5368387e604452ab72af193997cb39",
            "255d499f3a69435b92afab81b74c2e5e",
            "f649bdc4f6ec4a1aa617ec5ff571c639",
            "42bb816262e44d30a7db7af33296c655",
            "b3a1ccc3e4da423f922338c7783aba6b",
            "c0df99ffc1e5401796c18ddead34dd82",
            "93fed13940f8459d995503c08dff78b2",
            "7949e3efa5394354a526c65254374776",
            "eaf6327b86c84172ab1e7891ada13195",
            "998abde92597400b957c1505b8d9db87",
            "af79e577c50148b98c6893d7545eba7c",
            "e06250eab263411b89418bcd4fe989ee",
            "58d23455fede4b5888536b2c052c2131",
            "a14857cf26d74732bd289c0874006a3e",
            "895b5427f3da4001a45f250f62469b79",
            "1d10a7a30294473e88c39b019f91eb74",
            "5c3e9188d9a449c7a091aa148031e99a",
            "931c1a7a42e24148864df49cc4852d67",
            "34244de9ccf34f49815f5fc92cd55f87",
            "0fd78a3a76004638a842e45bc76a84cc",
            "9728f46dc4c3486c91e6f4fcf9da294e",
            "2959eb6c7b42498ebec6ddcd75b7b01d",
            "535cf33f18654dd9b74cd8b1d8e43b74",
            "9cf978f6d6094661afb2d4cdfd8af75f",
            "2d2d5ba22453479783894929f57b728c",
            "bc627b72c924482798ff8ec751b32475",
            "bb507e5872da4fc49f520cc703059cbe",
            "3cc3dd2798614efa9912ef8f458fe817",
            "ba512d83b11b4dc99686bbf4ed2c74c1",
            "30dae50f020b441a8602336c00e54e24",
            "beddf4da962548dabcec8480e350d7d1",
            "6137a8f1162a475fa39ca30e0b44f812",
            "b8bcdf89089e4eafbd7103375d4ba081",
            "5b18471f5f904338890b036ae8c618e6",
            "dd5e36da842443c4a13dfe9142ec7d40",
            "3fc495602e1042208095f1877723bbd7",
            "5993791d71344181b4bf7f019ea7fb8a",
            "1fc7ae38833c494e8069d733c4af68cd",
            "8384c3d427b9460788d91f0ab78e3f6d",
            "acf2cf7b32644b988c10d8d4a2096583",
            "eeea40cc9ff44243883c20f311f1a7fe",
            "f3d67bc038ce46beb813c7a75da3f3d2",
            "7edd9f2c7e9c4402845b105031878864",
            "3455cbc02d2f4c8bb95f5ab36ffaf6f3",
            "6ad504eb2f1045e49665314f0b920cf2",
            "50d4bcadab5045a88329ec5f10c560f3",
            "925eead75fd2493db5eb70afd8f5a0f4",
            "77a43f6e154545359b0753c8af0adc3a",
            "d8a98b9a570c41bcabfdc457fd9aeb7e",
            "230767cacd294c4c997cdedd2764920b",
            "840e1b105b2849c9a7b7aff81e6c4cfc",
            "a580a46f456f47348c30b419b0b534c2",
            "36abbc6d4761417d86580f1a418875ed",
            "56421f07508c43e4a77675ccb142ef40",
            "8bb0e8afcab648b0947acb97b963bbc2",
            "192eb42953e0429cad0ac960c04e9f6a",
            "1cecf34235944c898f22668af2624bf5",
            "8566a4bff01941c9b8aac11d5b4dab4b",
            "89c974b3303b443396c81c02a134524e",
            "e99f1f85c6de47f581e1e04e33600cad",
            "8345dd42315e4bd89a4e6bbabb763607",
            "9e4e0f898c284b828c98d284e634b8a1",
            "8ee52b455d814c079dda967df5e5296d",
            "8513925d320b4f75a0a00f6fbc93871b",
            "352399f8a9cf4c4cb10ba420b000cc10",
            "c62642110d4b4909925fdc50c01d9203",
            "20893aa06c61494d90639c2bc42131af",
            "a51e8d9671024cee90ac828dbc3056ce",
            "eec159cc78604860ac7cc0b405bfe092",
            "891c5d994fa34743ba7a59eb12ed00de",
            "3f160aaa1ad14d7191497df4ce4d4838",
            "0fe79100e8dc4b749edf0bf4d0248ef3",
            "63a8899a57c84e4aafa31f4f8277ab4c",
            "749f00f81e6242b0bde909f04985f47d",
            "59f958ee2a484d909b2b5c45e0a38da3",
            "852a4479674b41b0b33e7d4ad8585c38",
            "fd114717ad8543b4bd14fb51bf2795d2",
            "a4b0f842d62f48f7a38ecc59352dd45e",
            "d22e5e8d480b4b9cb7551ce0efdfa251",
            "b9ece7a6f0144b318104778210358c9e",
            "485786ea5ffd4fc48de67fe8b2ff46d3",
            "15cf5fe7abbf4a52829e9a10f96fec8d",
            "743434f592564b7bb244d50036151fb5",
            "2fc61ef5b5b2429fa4a781936d740d3b",
            "aa900c6ec65948b586c57f9f85d91f62",
            "2f94f4ed175147b38be6ab338c5ebffa",
            "10a9d2bcacac4bb98af07276f39dd82e",
            "7276bc9a99084a6a875b05ae83db75f0",
            "97d63b279fd744b291cd396b810fe077",
            "b17e4c7537d943ae9d07b5d964b1d684",
            "3bb41ff6450545b2baf0866a1d9cdbb1",
            "7eb32cbdc79e4f96b49560849d37f28f",
            "8b8967b193b845daa89d7d2ea84eee4c",
            "407b05b4f5fc4e5ea170d97133a8753a",
            "3d414d62d93947b29048aecad15ce578",
            "c460dcce23ce4be98c021ebfced02410",
            "62edb871ed1e499495c61bc9b084d989",
            "a267cc805bca4138b53ef8edfcc844f0"
          ]
        },
        "outputId": "9ffd1a71-9a6a-48bc-b718-28c7bd829677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f315ba1cc0b3457d80b1abbfe5f6fc5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8793587c4634505b225a8b907ad46c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af79e577c50148b98c6893d7545eba7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2959eb6c7b42498ebec6ddcd75b7b01d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8bcdf89089e4eafbd7103375d4ba081"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/511 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3455cbc02d2f4c8bb95f5ab36ffaf6f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bb0e8afcab648b0947acb97b963bbc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c62642110d4b4909925fdc50c01d9203"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd114717ad8543b4bd14fb51bf2795d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7276bc9a99084a6a875b05ae83db75f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1000 [00:25<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7f34de1b86f4>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m               \u001b[0mall_ben_um_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mum_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m               \u001b[0mum_sen_logits_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mum_sen_conf_socres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mum_sen_label\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mum_sentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhuggingface_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m               \u001b[0mall_ben_logits_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mum_sen_logits_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m               \u001b[0mall_ben_um_sentence_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mum_sen_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/MLDM/victim.py\u001b[0m in \u001b[0;36mpredict_class\u001b[0;34m(um_sentence_list, model_cls, tokenizer_cls, huggingface_model)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mlogits_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mscore_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import pickle,csv\n",
        "# Set the values for the arguments\n",
        "class Args:\n",
        "    tn = 3\n",
        "\n",
        "    unm_model = 'roberta-base'\n",
        "    hug = True\n",
        "    victim = 'bert'\n",
        "    mfre = 1\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "import pickle\n",
        "def load_model(modelname):\n",
        "    model = BertForSequenceClassification.from_pretrained(modelname).to(device)\n",
        "    tokenizer = BertTokenizer.from_pretrained(modelname,use_fast=True, add_prefix_space=True)\n",
        "    average_sentence_length=19\n",
        "    model.eval()\n",
        "    return model, tokenizer\n",
        "\n",
        "Datapath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "# Record the start time\n",
        "import time\n",
        "Overall_start_time = time.time()\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/1K_Dataset/small_'\n",
        "editfeaturepath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "datasetnames=['imdb']\n",
        "victimmodel='bert'\n",
        "#datasetnames=['imdb','yelp_polarity','sst2','ag_news\n",
        "modelpath='textattack/bert-base-uncased-'\n",
        "\n",
        "batch_size = 32  # Set your desired batch size\n",
        "\n",
        "for i,datasetname in enumerate(datasetnames):\n",
        "    if(datasetname=='ag_news'):\n",
        "        modelname=modelpath+'ag-news'\n",
        "    elif datasetname=='yelp_polarity':\n",
        "       modelname=modelpath+'yelp-polarity'\n",
        "    elif datasetname=='sst2':\n",
        "       modelname=modelpath+'SST-2'\n",
        "    else:\n",
        "       modelname=modelpath+datasetname\n",
        "\n",
        "    args = Args()\n",
        "\n",
        "    candidate_token_num=args.tn\n",
        "    huggingface_model=args.hug\n",
        "    ma_fre=args.mfre\n",
        "\n",
        "    # Load masked language models\n",
        "    if args.unm_model=='roberta-base':\n",
        "        tokenizer=RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "        model = RobertaForMaskedLM.from_pretrained(\"roberta-base\")\n",
        "    elif args.unm_model=='bert-base-uncased':\n",
        "        tokenizer=RobertaTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        model = RobertaForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "    else:\n",
        "        tokenizer=RobertaTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "        model = RobertaForMaskedLM.from_pretrained(\"albert-base-v2\")\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Load detection file\n",
        "    detection_file = ''\n",
        "\n",
        "    # LOAD VICTIM MODEL\n",
        "    model_cls,tokenizer_cls=load_model(modelname)\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model_cls = nn.DataParallel(model_cls)\n",
        "        model_cls = model_cls.to(device)\n",
        "\n",
        "\n",
        "    path=savepath+datasetname+'_'+victimmodel\n",
        "    benigns=pd.read_csv(path+'_clean_data.csv')\n",
        "    advs=pd.read_csv(path+'_adv_data.csv')\n",
        "    if(datasetname!='sst2'):\n",
        "         x_benigns=list(benigns['text'])\n",
        "    else:\n",
        "      x_benigns=list(benigns['sentence'])\n",
        "    x_advs=list(advs['perturbed_text'])\n",
        "\n",
        "    all_ben_masked_str=[]\n",
        "    all_ben_masked_str_tokens=[]\n",
        "    all_ben_um_sentence=[]\n",
        "    all_ben_um_sentence_label=[]\n",
        "    all_ben_euq_labels=[]\n",
        "    all_ben_logits_out=[]\n",
        "    n=1000\n",
        "    elapse_time=[]\n",
        "    # padding_socre_diff_f=[]\n",
        "    # x_benigns, x_advs = get_adv(detect)\n",
        "    rand_index =np.random.choice(len(x_benigns),n)\n",
        "    file_path=datasetname+victimmodel+str(len(x_benigns)-1)+'Benign.pkl'\n",
        "    if os.path.exists(file_path):\n",
        "           with open(file_path, 'rb') as file:\n",
        "              loaded_data = pickle.load(file)\n",
        "        # Process the loaded data as needed\n",
        "              all_ben_logits_out, all_ben_um_sentence_label, all_ben_euq_labels,elapse_time = loaded_data\n",
        "              print(\"org\",str(len(x_benigns)-1))\n",
        "    else:\n",
        "      for idx in tqdm(range(n)):\n",
        "          file_path=datasetname+victimmodel+str(idx)+'Benign.pkl'\n",
        "          if os.path.exists(file_path):\n",
        "            with open(file_path, 'rb') as file:\n",
        "                loaded_data = pickle.load(file)\n",
        "          # Process the loaded data as needed\n",
        "                 all_ben_logits_out, all_ben_um_sentence_label, all_ben_euq_labels,elapse_time = loaded_data\n",
        "                print(\"org\",idx)\n",
        "          else:\n",
        "            start_time = time.time()\n",
        "            orig_str=x_benigns[idx]\n",
        "            if(len(orig_str.split(' '))>1):\n",
        "              # masked_str=rand_mask_string(orig_str,tokenizer,ma_fre)\n",
        "              masked_str=mask_string(orig_str,tokenizer)\n",
        "              all_ben_masked_str.append(masked_str)\n",
        "\n",
        "              masked_str=mask_string(orig_str,tokenizer)\n",
        "              all_ben_masked_str.append(masked_str)\n",
        "\n",
        "              masked_str_tokens = masked_str_token(masked_str,model,tokenizer)\n",
        "              all_ben_masked_str_tokens.append(masked_str_tokens)\n",
        "\n",
        "              um_sentence = get_mlm_um_sen(masked_str,masked_str_tokens,3)\n",
        "              all_ben_um_sentence.append(um_sentence)\n",
        "\n",
        "              um_sen_logits_out,um_sen_conf_socres,um_sen_label= predict_class(um_sentence,model_cls,tokenizer_cls,huggingface_model)\n",
        "              all_ben_logits_out.append(um_sen_logits_out)\n",
        "              all_ben_um_sentence_label.append(um_sen_label)\n",
        "\n",
        "              #distinguishable score\n",
        "              # _,orig_str_sorce,_= predict_class([orig_str],model_cls,tokenizer_cls)\n",
        "              # padding_socre_diff=compute_score_difference_padding(orig_str_sorce,um_sen_conf_socres)\n",
        "              # padding_socre_diff = padding_socre_diff[:,:1].unsqueeze(0)\n",
        "\n",
        "              # padding_socre_diff_sig  = padding_socre_diff.cpu().numpy().flatten().tolist()\n",
        "              # padding_socre_diff_f.append(padding_socre_diff_sig)\n",
        "\n",
        "              euq_labels= euq_label(orig_str,um_sen_label,model_cls,tokenizer_cls,candidate_token_num,huggingface_model)\n",
        "              all_ben_euq_labels.append(euq_labels)\n",
        "              end_time = time.time()\n",
        "              elapsed_time = end_time - start_time\n",
        "              print(\"time taken \",elapsed_time)\n",
        "              elapse_time.append(elapsed_time)\n",
        "              with open(file_path, 'wb') as file:\n",
        "                pickle.dump([all_ben_logits_out,all_ben_um_sentence_label,all_ben_euq_labels,elapse_time], file)\n",
        "    all_adv_masked_str=[]\n",
        "    all_adv_masked_str_tokens=[]\n",
        "    all_adv_um_sentence=[]\n",
        "    all_adv_um_sentence_label=[]\n",
        "    all_adv_euq_labels=[]\n",
        "    all_adv_logits_out=[]\n",
        "    n=len(x_advs)\n",
        "\n",
        "    file_path=datasetname+victimmodel+str(len(x_advs)-1)+'adv.pkl'\n",
        "    if os.path.exists(file_path):\n",
        "           with open(file_path, 'rb') as file:\n",
        "              loaded_data = pickle.load(file)\n",
        "              # Process the loaded data as needed\n",
        "              all_adv_logits_out,all_adv_um_sentence_label,all_adv_euq_labels,elapse_time = loaded_data\n",
        "           print(\"adv\",len(x_advs)-1)\n",
        "    else:\n",
        "     for idx in tqdm(range(n)):\n",
        "      file_path=datasetname+victimmodel+str(idx)+'adv.pkl'\n",
        "      if os.path.exists(file_path):\n",
        "          with open(file_path, 'rb') as file:\n",
        "              loaded_data = pickle.load(file)\n",
        "        # Process the loaded data as needed\n",
        "          all_adv_logits_out,all_adv_um_sentence_label,all_adv_euq_labels,elapse_time = loaded_data\n",
        "          print(\"adv\",idx)\n",
        "      else:\n",
        "          start_time = time.time()\n",
        "          orig_str=x_advs[idx]\n",
        "          if(len(orig_str.split(' '))>1):\n",
        "            # masked_str=rand_mask_string(orig_str,tokenizer,ma_fre)\n",
        "            masked_str=mask_string(orig_str,tokenizer)\n",
        "            all_adv_masked_str.append(masked_str)\n",
        "\n",
        "            masked_str=mask_string(orig_str,tokenizer)\n",
        "            all_adv_masked_str.append(masked_str)\n",
        "\n",
        "            masked_str_tokens = masked_str_token(masked_str,model,tokenizer)\n",
        "            all_adv_masked_str_tokens.append(masked_str_tokens)\n",
        "\n",
        "            um_sentence = get_mlm_um_sen(masked_str,masked_str_tokens,3)\n",
        "            all_adv_um_sentence.append(um_sentence)\n",
        "\n",
        "            um_sen_logits_out,um_sen_conf_socres,um_sen_label= predict_class(um_sentence,model_cls,tokenizer_cls,huggingface_model)\n",
        "            all_adv_logits_out.append(um_sen_logits_out)\n",
        "            all_adv_um_sentence_label.append(um_sen_label)\n",
        "\n",
        "            #distinguishable score\n",
        "            # _,orig_str_sorce,_= predict_class([orig_str],model_cls,tokenizer_cls)\n",
        "            # padding_socre_diff=compute_score_difference_padding(orig_str_sorce,um_sen_conf_socres)\n",
        "            # padding_socre_diff = padding_socre_diff[:,:1].unsqueeze(0)\n",
        "\n",
        "\n",
        "            # padding_socre_diff_sig  = padding_socre_diff.cpu().numpy().flatten().tolist()\n",
        "            # padding_socre_diff_f.append(padding_socre_diff_sig)\n",
        "\n",
        "            euq_labels= euq_label(orig_str,um_sen_label,model_cls,tokenizer_cls,candidate_token_num,huggingface_model)\n",
        "            all_adv_euq_labels.append(euq_labels)\n",
        "            end_time = time.time()\n",
        "            elapsed_time = end_time - start_time\n",
        "            elapse_time.append(elapsed_time)\n",
        "            with open(file_path, 'wb') as file:\n",
        "              pickle.dump([all_adv_logits_out,all_adv_um_sentence_label,all_adv_euq_labels,elapse_time], file)\n",
        "\n",
        "    if os.path.exists(datasetname+victimmodel+'benign_adv.pkl'):\n",
        "      with open(datasetname+victimmodel+'benign_adv.pkl', 'rb') as file:\n",
        "        loaded_data = pickle.load(file)\n",
        "        # Process the loaded data as needed\n",
        "        ben_metric, adv_metric = loaded_data\n",
        "    else:\n",
        "      ben_metric=mean_mean_label(all_ben_euq_labels)\n",
        "      adv_metric=mean_mean_label(all_adv_euq_labels)\n",
        "      with open(datasetname+victimmodel+'benign_adv.pkl', 'wb') as file:\n",
        "            pickle.dump([ben_metric,adv_metric], file)\n",
        "    metrics=gap_infer_acc_f1(ben_metric, adv_metric)\n",
        "    # print('unmask model:',args.unm_model)\n",
        "    # print('candidate_token_num:',candidate_token_num)\n",
        "    # print(\"mask frequency is :\",ma_fre)\n",
        "    # print('test config:',detection_file)\n",
        "    # print('********')\n",
        "    # print('gap_a:',gap_a,\"ACC:\",acc,\"gap_f:\",gap_f,'F1:',f1)\n",
        "    print(metrics)\n",
        "\n",
        "    with open(M_path+'result_MLDM.csv', 'a+', newline='') as csv_file:\n",
        "      writer = csv.writer(csv_file)\n",
        "\n",
        "        # Write header\n",
        "      header=['datasetname', 'victimmodel','elapsed_time']\n",
        "      header.extend(list(metrics[4].keys()))\n",
        "      writer.writerow(header)\n",
        "      mean_elapsed_time = sum(elapse_time) / len(elapse_time)\n",
        "\n",
        "      row=[datasetname, victimmodel,mean_elapsed_time]\n",
        "      row.extend(list(metrics[4].values()))\n",
        "      writer.writerow(row)\n",
        "\n",
        "\n",
        "Overall_elapsed_time = time.time() - Overall_start_time\n",
        "print(f'Overall processing time: {Overall_elapsed_time:.2f} seconds.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def ATTACK_WISE(test_metric,ADV,attack=1):\n",
        "\n",
        "\n",
        "#     acc=0\n",
        "#     gap_a=0\n",
        "#     gap_f=0\n",
        "#     f1=0\n",
        "#     if(attack==1):\n",
        "#       uniqueattack = dict(map(reversed, enumerate(set(ADV))))\n",
        "#           #print(uniqueattack)\n",
        "#       for attack in uniqueattack.keys():\n",
        "\n",
        "#                   target = []\n",
        "#                   conf = []\n",
        "#                   mask = ADV['attack'] == attack\n",
        "\n",
        "\n",
        "#                   train_test_metric = test_metric[mask]\n",
        "#                   print(len(train_test_metric))\n",
        "#                   y_true = np.ones(len(train_test_metric))\n",
        "#                   from sklearn.metrics import accuracy_score\n",
        "\n",
        "#                   train_test_meritc_sort = np.sort(train_test_metric)\n",
        "#                   for trs in train_test_meritc_sort:\n",
        "#                       y_pred_t = np.where(train_test_metric>=trs,0,1)\n",
        "#                       gap_t = trs\n",
        "#                       tn,fp,fn,tp= confusion_matrix(y_true,y_pred_t).ravel()\n",
        "#                       acc_t = (tn+tp)/(tn+fp+fn+tp)\n",
        "#                       if acc_t >=acc:\n",
        "#                           acc=acc_t\n",
        "#                           gap_a = gap_t\n",
        "#                       else:\n",
        "#                           acc=acc\n",
        "#                           gap_a = gap_a\n",
        "\n",
        "#                       if ((tp+fp)==0) or ((tp+fn)==0):\n",
        "#                           continue\n",
        "#                       else:\n",
        "#                           p = tp/(tp+fp)\n",
        "#                           r =tp/(tp+fn)\n",
        "#                       f1_t = (2*p*r)/(p+r)\n",
        "#                       if f1_t>=f1:\n",
        "#                           f1=f1_t\n",
        "#                           gap_f=gap_t\n",
        "#                       else:\n",
        "#                           f1=f1\n",
        "#                           gap_f=gap_f\n",
        "\n",
        "#                   #\\tau\n",
        "#                   y_pred_a = np.where(train_test_metric>=gap_a,0,1)\n",
        "#                   accuracy_a = accuracy_score(y_true, y_pred_a)\n",
        "#                   y_pred_f = np.where(train_test_metric>=gap_f,0,1)\n",
        "#                   accuracy_f = accuracy_score(y_true, y_pred_f)\n",
        "\n",
        "#                   print(\"attack \",accuracy_a,\" \",accuracy_f)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "def ATTACK_WISE(test_metric, ADV, attack_column='attack'):\n",
        "    acc = 0\n",
        "    gap_a = 0\n",
        "    gap_f = 0\n",
        "    f1 = 0\n",
        "    metrics=[]\n",
        "    unique_attacks = ADV[attack_column].unique()\n",
        "    for attack in unique_attacks:\n",
        "        mask = ADV[attack_column] == attack\n",
        "        train_test_metric = test_metric[mask]\n",
        "        y_true = np.ones(len(train_test_metric))\n",
        "\n",
        "        train_test_metric_sort = np.sort(train_test_metric)\n",
        "        for trs in train_test_metric_sort:\n",
        "            y_pred_t = np.where(train_test_metric >= trs, 0, 1)\n",
        "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred_t).ravel()\n",
        "            acc_t = (tn + tp) / (tn + fp + fn + tp)\n",
        "\n",
        "            if acc_t >= acc:\n",
        "                acc = acc_t\n",
        "                gap_a = trs\n",
        "\n",
        "            if tp + fp > 0 and tp + fn > 0:\n",
        "                p = tp / (tp + fp)\n",
        "                r = tp / (tp + fn)\n",
        "                f1_t = 2 * p * r / (p + r) if p + r > 0 else 0\n",
        "                if f1_t >= f1:\n",
        "                    f1 = f1_t\n",
        "                    gap_f = trs\n",
        "\n",
        "        y_pred_a = np.where(train_test_metric >= gap_a, 0, 1)\n",
        "        accuracy_a = accuracy_score(y_true, y_pred_a)\n",
        "        y_pred_f = np.where(train_test_metric >= gap_f, 0, 1)\n",
        "        accuracy_f = accuracy_score(y_true, y_pred_f)\n",
        "        with open(M_path+'result_MLDM_final.csv', 'a+', newline='') as csv_file:\n",
        "                  writer = csv.writer(csv_file)\n",
        "\n",
        "                  #     # Write header\n",
        "\n",
        "\n",
        "                  header=['datasetname', 'victimmodel']\n",
        "\n",
        "                  writer.writerow(header)\n",
        "                  row=[datasetname, victimmodel,attack,accuracy_a]\n",
        "\n",
        "                  writer.writerow(row)\n",
        "\n",
        "        print(f\"Attack {attack}: Accuracy A = {accuracy_a}, Accuracy F = {accuracy_f}\")\n",
        "\n",
        "    return accuracy_a,accuracy_f\n"
      ],
      "metadata": {
        "id": "SoNaYcp2yHtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import csv\n",
        "datasets=['imdb','yelp_polarity','sst2','ag_news']\n",
        "victimmodels=['roberta','bert']\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/1K_Dataset/small_'\n",
        "for datasetname in datasets:\n",
        "  for victimmodel in victimmodels:\n",
        "    print(datasetname)\n",
        "    if os.path.exists(datasetname+victimmodel+'benign_adv.pkl'):\n",
        "          with open(datasetname+victimmodel+'benign_adv.pkl', 'rb') as file:\n",
        "            loaded_data = pickle.load(file)\n",
        "            # Process the loaded data as needed\n",
        "            ben_metric, adv_metric = loaded_data\n",
        "            path=savepath+datasetname+'_'+victimmodel\n",
        "            benigns=pd.read_csv(path+'_clean_data.csv')\n",
        "\n",
        "\n",
        "            advs=pd.read_csv(path+'_adv_data.csv')\n",
        "            advs= advs.iloc[:len(adv_metric)]\n",
        "\n",
        "            advs=advs.dropna()\n",
        "            print(len(adv_metric), \" \", len(advs))\n",
        "\n",
        "\n",
        "            metrics=ATTACK_WISE(adv_metric,advs)\n",
        "            # # print('unmask model:',args.unm_model)\n",
        "            # # print('candidate_token_num:',candidate_token_num)\n",
        "            # # print(\"mask frequency is :\",ma_fre)\n",
        "            # # print('test config:',detection_file)\n",
        "            # # print('********')\n",
        "            # # print('gap_a:',gap_a,\"ACC:\",acc,\"gap_f:\",gap_f,'F1:',f1)\n",
        "            # print(metrics)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #   Overall_elapsed_time = time.time() - Overall_start_time\n",
        "            #   print(f'Overall processing time: {Overall_elapsed_time:.2f} seconds.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx_sIrcuc9qa",
        "outputId": "8c96b827-7222-4602-f688-02d6c4f1a863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdb\n",
            "996   996\n",
            "Attack textbugger: Accuracy A = 0.5783132530120482, Accuracy F = 0.5783132530120482\n",
            "Attack textfooler: Accuracy A = 0.5602409638554217, Accuracy F = 0.5602409638554217\n",
            "Attack deepwordbug: Accuracy A = 0.6265060240963856, Accuracy F = 0.6265060240963856\n",
            "Attack pwws: Accuracy A = 0.5240963855421686, Accuracy F = 0.5240963855421686\n",
            "Attack bae: Accuracy A = 0.5843373493975904, Accuracy F = 0.5843373493975904\n",
            "Attack tf-adj: Accuracy A = 0.27710843373493976, Accuracy F = 0.27710843373493976\n",
            "imdb\n",
            "996   996\n",
            "Attack textbugger: Accuracy A = 0.4819277108433735, Accuracy F = 0.4819277108433735\n",
            "Attack textfooler: Accuracy A = 0.5, Accuracy F = 0.5\n",
            "Attack deepwordbug: Accuracy A = 0.45180722891566266, Accuracy F = 0.45180722891566266\n",
            "Attack pwws: Accuracy A = 0.45180722891566266, Accuracy F = 0.45180722891566266\n",
            "Attack bae: Accuracy A = 0.4879518072289157, Accuracy F = 0.4879518072289157\n",
            "Attack tf-adj: Accuracy A = 0.2891566265060241, Accuracy F = 0.2891566265060241\n",
            "yelp_polarity\n",
            "996   996\n",
            "Attack textbugger: Accuracy A = 0.463855421686747, Accuracy F = 0.463855421686747\n",
            "Attack textfooler: Accuracy A = 0.5542168674698795, Accuracy F = 0.5542168674698795\n",
            "Attack deepwordbug: Accuracy A = 0.5783132530120482, Accuracy F = 0.5783132530120482\n",
            "Attack pwws: Accuracy A = 0.4759036144578313, Accuracy F = 0.4759036144578313\n",
            "Attack bae: Accuracy A = 0.4759036144578313, Accuracy F = 0.4759036144578313\n",
            "Attack tf-adj: Accuracy A = 0.1566265060240964, Accuracy F = 0.1566265060240964\n",
            "yelp_polarity\n",
            "992   992\n",
            "Attack textbugger: Accuracy A = 0.5301204819277109, Accuracy F = 0.5301204819277109\n",
            "Attack textfooler: Accuracy A = 0.5843373493975904, Accuracy F = 0.5843373493975904\n",
            "Attack deepwordbug: Accuracy A = 0.5481927710843374, Accuracy F = 0.5481927710843374\n",
            "Attack pwws: Accuracy A = 0.5240963855421686, Accuracy F = 0.5240963855421686\n",
            "Attack bae: Accuracy A = 0.4457831325301205, Accuracy F = 0.4457831325301205\n",
            "Attack tf-adj: Accuracy A = 0.20987654320987653, Accuracy F = 0.20987654320987653\n",
            "sst2\n",
            "996   996\n",
            "Attack textbugger: Accuracy A = 0.018072289156626505, Accuracy F = 0.018072289156626505\n",
            "Attack textfooler: Accuracy A = 0.030120481927710843, Accuracy F = 0.030120481927710843\n",
            "Attack deepwordbug: Accuracy A = 0.04819277108433735, Accuracy F = 0.04819277108433735\n",
            "Attack pwws: Accuracy A = 0.012048192771084338, Accuracy F = 0.012048192771084338\n",
            "Attack bae: Accuracy A = 0.030120481927710843, Accuracy F = 0.030120481927710843\n",
            "Attack tf-adj: Accuracy A = 0.018072289156626505, Accuracy F = 0.018072289156626505\n",
            "sst2\n",
            "996   996\n",
            "Attack textbugger: Accuracy A = 0.7891566265060241, Accuracy F = 0.7891566265060241\n",
            "Attack textfooler: Accuracy A = 0.8674698795180723, Accuracy F = 0.8674698795180723\n",
            "Attack deepwordbug: Accuracy A = 0.8493975903614458, Accuracy F = 0.8493975903614458\n",
            "Attack pwws: Accuracy A = 0.8493975903614458, Accuracy F = 0.8493975903614458\n",
            "Attack bae: Accuracy A = 0.7108433734939759, Accuracy F = 0.7108433734939759\n",
            "Attack tf-adj: Accuracy A = 0.5180722891566265, Accuracy F = 0.5180722891566265\n",
            "ag_news\n",
            "996   996\n",
            "Attack textbugger: Accuracy A = 0.4397590361445783, Accuracy F = 0.4397590361445783\n",
            "Attack textfooler: Accuracy A = 0.4397590361445783, Accuracy F = 0.4397590361445783\n",
            "Attack deepwordbug: Accuracy A = 0.4036144578313253, Accuracy F = 0.4036144578313253\n",
            "Attack pwws: Accuracy A = 0.3855421686746988, Accuracy F = 0.3855421686746988\n",
            "Attack bae: Accuracy A = 0.21686746987951808, Accuracy F = 0.21686746987951808\n",
            "Attack tf-adj: Accuracy A = 0.1746987951807229, Accuracy F = 0.1746987951807229\n",
            "ag_news\n",
            "996   996\n",
            "Attack textbugger: Accuracy A = 0.5060240963855421, Accuracy F = 0.5060240963855421\n",
            "Attack textfooler: Accuracy A = 0.45180722891566266, Accuracy F = 0.45180722891566266\n",
            "Attack deepwordbug: Accuracy A = 0.5180722891566265, Accuracy F = 0.5180722891566265\n",
            "Attack pwws: Accuracy A = 0.4397590361445783, Accuracy F = 0.4397590361445783\n",
            "Attack bae: Accuracy A = 0.1927710843373494, Accuracy F = 0.1927710843373494\n",
            "Attack tf-adj: Accuracy A = 0.14457831325301204, Accuracy F = 0.14457831325301204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "def ATTACK_WISE_Benign(test_metric, ADV):\n",
        "    acc = 0\n",
        "    gap_a = 0\n",
        "    gap_f = 0\n",
        "    f1 = 0\n",
        "    metrics=[]\n",
        "    mask = ADV['type'] == 'test'\n",
        "    train_test_metric = test_metric[mask]\n",
        "    y_true = np.zeros(len(train_test_metric))\n",
        "    print(len(y_true))\n",
        "    train_test_metric_sort = np.sort(train_test_metric)\n",
        "    for trs in train_test_metric_sort:\n",
        "            y_pred_t = np.where(train_test_metric >= trs, 0, 1)\n",
        "            cm = confusion_matrix(y_true, y_pred_t)\n",
        "\n",
        "            if cm.shape == (1, 1):\n",
        "                # Only one class present in y_true and y_pred_t\n",
        "                if y_true[0] == 0:  # Assuming 0 is the negative class\n",
        "                    tn = cm[0, 0]\n",
        "                    fp = fn = tp = 0\n",
        "                else:\n",
        "                    tp = cm[0, 0]\n",
        "                    tn = fp = fn = 0\n",
        "            else:\n",
        "                tn, fp, fn, tp = cm.ravel()\n",
        "            acc_t = (tn + tp) / (tn + fp + fn + tp)\n",
        "\n",
        "            if acc_t >= acc:\n",
        "                acc = acc_t\n",
        "                gap_a = trs\n",
        "\n",
        "            if tp + fp > 0 and tp + fn > 0:\n",
        "                p = tp / (tp + fp)\n",
        "                r = tp / (tp + fn)\n",
        "                f1_t = 2 * p * r / (p + r) if p + r > 0 else 0\n",
        "                if f1_t >= f1:\n",
        "                    f1 = f1_t\n",
        "                    gap_f = trs\n",
        "\n",
        "    y_pred_a = np.where(train_test_metric >= gap_a, 0, 1)\n",
        "    accuracy_a = accuracy_score(y_true, y_pred_a)\n",
        "    y_pred_f = np.where(train_test_metric >= gap_f, 0, 1)\n",
        "    accuracy_f = accuracy_score(y_true, y_pred_f)\n",
        "    with open(M_path+'result_MLDM_final.csv', 'a+', newline='') as csv_file:\n",
        "                  writer = csv.writer(csv_file)\n",
        "\n",
        "                  #     # Write header\n",
        "\n",
        "\n",
        "                  header=['datasetname', 'victimmodel']\n",
        "\n",
        "                  writer.writerow(header)\n",
        "                  row=[datasetname, victimmodel,'NO',accuracy_a]\n",
        "\n",
        "                  writer.writerow(row)\n",
        "\n",
        "                  print(f\"Attack No: Accuracy A = {accuracy_a}, Accuracy F = {accuracy_f}\")\n",
        "\n",
        "    return accuracy_a,accuracy_f\n"
      ],
      "metadata": {
        "id": "pdk-N0iyh25Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import csv\n",
        "datasets=['imdb','sst2','ag_news','yelp_polarity']\n",
        "victimmodels=['roberta','bert']\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/1K_Dataset/small_'\n",
        "for datasetname in datasets:\n",
        "  for victimmodel in victimmodels:\n",
        "    print(datasetname)\n",
        "    if os.path.exists(datasetname+victimmodel+'benign_adv.pkl'):\n",
        "          with open(datasetname+victimmodel+'benign_adv.pkl', 'rb') as file:\n",
        "            loaded_data = pickle.load(file)\n",
        "            # Process the loaded data as needed\n",
        "            ben_metric, adv_metric = loaded_data\n",
        "            path=savepath+datasetname+'_'+victimmodel\n",
        "            benigns=pd.read_csv(path+'_clean_data.csv')\n",
        "\n",
        "\n",
        "\n",
        "            metrics=ATTACK_WISE_Benign(ben_metric,benigns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "hVET0RqziZIt",
        "outputId": "3b6fb29e-e1fa-4672-f83c-27fce70b1027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdb\n",
            "500\n",
            "Attack No: Accuracy A = 1.0, Accuracy F = 1.0\n",
            "imdb\n",
            "500\n",
            "Attack No: Accuracy A = 1.0, Accuracy F = 1.0\n",
            "sst2\n",
            "500\n",
            "Attack No: Accuracy A = 1.0, Accuracy F = 1.0\n",
            "sst2\n",
            "500\n",
            "Attack No: Accuracy A = 1.0, Accuracy F = 1.0\n",
            "ag_news\n",
            "500\n",
            "Attack No: Accuracy A = 1.0, Accuracy F = 1.0\n",
            "ag_news\n",
            "500\n",
            "Attack No: Accuracy A = 1.0, Accuracy F = 1.0\n",
            "yelp_polarity\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "boolean index did not match indexed array along dimension 0; dimension is 999 but corresponding boolean dimension is 1000",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-ffbcf2fe5334>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mATTACK_WISE_Benign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mben_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbenigns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-d6988daae2f1>\u001b[0m in \u001b[0;36mATTACK_WISE_Benign\u001b[0;34m(test_metric, ADV)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mADV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_test_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_metric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_test_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 999 but corresponding boolean dimension is 1000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_metric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNAHGCPgdedi",
        "outputId": "481d348c-5913-4e43-f248-465dd287332e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99706314, 1.        , 0.9877193 , 1.        , 1.        ,\n",
              "       0.98971722, 1.        , 0.98933333, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.99404762, 0.98560606,\n",
              "       0.96176226, 0.99702381, 0.99341564, 0.9952381 , 1.        ,\n",
              "       1.        , 0.99180328, 0.99404762, 0.98556999, 1.        ,\n",
              "       0.99752475, 0.99527187, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99731183,\n",
              "       1.        , 0.9978903 , 0.99676375, 1.        , 1.        ,\n",
              "       1.        , 0.96438746, 1.        , 1.        , 1.        ,\n",
              "       0.99765258, 0.99295775, 0.92083333, 0.99869281, 1.        ,\n",
              "       0.96880131, 1.        , 0.98245614, 1.        , 0.68055556,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.99652778, 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.99924242, 1.        , 0.75308642,\n",
              "       0.98325723, 0.99507995, 1.        , 0.97709924, 0.97802198,\n",
              "       0.98933333, 0.99782135, 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.84662577, 1.        , 0.99425287, 1.        ,\n",
              "       1.        , 0.96240602, 0.54942529, 0.84671533, 1.        ,\n",
              "       0.99555556, 0.65858041, 1.        , 0.97333333, 1.        ,\n",
              "       0.99700599, 0.88429752, 1.        , 1.        , 1.        ,\n",
              "       0.95238095, 0.96969697, 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.84313725, 0.99298246, 0.99007937, 0.98062016,\n",
              "       1.        , 0.99656357, 0.99834574, 1.        , 0.99747475,\n",
              "       1.        , 0.99821747, 0.99847095, 1.        , 0.99814815,\n",
              "       1.        , 0.99099099, 1.        , 1.        , 0.99829932,\n",
              "       0.99462366, 0.76068376, 1.        , 0.55430712, 0.69275362,\n",
              "       1.        , 1.        , 0.80392157, 0.96168582, 1.        ,\n",
              "       0.77386197, 0.99303136, 1.        , 1.        , 0.99773243,\n",
              "       0.99847793, 0.96376812, 1.        , 1.        , 0.99444444,\n",
              "       1.        , 0.99733333, 0.95673077, 0.99180328, 1.        ,\n",
              "       0.99534451, 1.        , 1.        , 0.99019608, 0.98198198,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.9974359 , 0.99367089, 0.98095238, 1.        ,\n",
              "       1.        , 1.        , 0.99728997, 1.        , 0.9954023 ,\n",
              "       0.68303571, 0.9648318 , 1.        , 1.        , 1.        ,\n",
              "       0.90112994, 0.94520548, 1.        , 1.        , 0.98958333,\n",
              "       0.93939394, 0.99801587, 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.99833333, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.98484848, 0.99269006, 1.        ,\n",
              "       1.        , 1.        , 0.90126382, 0.87234043, 0.99815838,\n",
              "       0.77304965, 1.        , 1.        , 0.98518519, 1.        ,\n",
              "       0.98356808, 0.98039216, 1.        , 0.9715847 , 0.99259259,\n",
              "       1.        , 0.9984127 , 0.70212766, 0.98148148, 1.        ,\n",
              "       1.        , 1.        , 0.9877836 , 0.98039216, 0.99585921,\n",
              "       0.73287671, 0.98780488, 1.        , 0.97471264, 1.        ,\n",
              "       1.        , 0.98703704, 0.99885057, 0.81420765, 0.99435028,\n",
              "       0.9929078 , 0.9005848 , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.90223249, 0.9955157 , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.99659864, 0.75075075,\n",
              "       1.        , 0.99652778, 1.        , 0.90935673, 1.        ,\n",
              "       0.80076628, 1.        , 1.        , 0.93045564, 0.99485597,\n",
              "       1.        , 1.        , 0.96636086, 1.        , 1.        ,\n",
              "       1.        , 0.99844237, 1.        , 1.        , 0.9985444 ,\n",
              "       0.99280576, 1.        , 0.7761194 , 0.99702381, 0.87435897,\n",
              "       0.98351001, 1.        , 1.        , 0.80952381, 1.        ,\n",
              "       1.        , 0.98556999, 1.        , 0.98963731, 1.        ,\n",
              "       1.        , 0.99614644, 0.94252874, 0.99387577, 0.99776286,\n",
              "       1.        , 1.        , 0.86594203, 0.91641182, 0.995671  ,\n",
              "       1.        , 0.99428571, 1.        , 1.        , 1.        ,\n",
              "       0.91772152, 0.99521531, 0.98181818, 1.        , 1.        ,\n",
              "       0.84045584, 0.99382716, 1.        , 0.99730458, 1.        ,\n",
              "       0.98125   , 1.        , 1.        , 0.8968254 , 0.99198718,\n",
              "       1.        , 1.        , 0.98245614, 1.        , 0.97484277,\n",
              "       0.9921875 , 1.        , 0.97777778, 0.98135198, 1.        ,\n",
              "       0.98939929, 1.        , 0.94674556, 0.99792961, 1.        ,\n",
              "       0.9785575 , 0.99259259, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99537037,\n",
              "       0.93518519, 1.        , 0.99832916, 1.        , 0.96266667,\n",
              "       0.96732026, 0.99637681, 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.77935382, 0.96176226, 0.99103139, 0.91423948,\n",
              "       0.98095238, 0.99288256, 0.99751244, 0.99726776, 1.        ,\n",
              "       0.98556999, 1.        , 0.99752475, 0.98108747, 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.9009009 , 1.        ,\n",
              "       1.        , 0.99731183, 1.        , 0.93881857, 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.97435897, 1.        ,\n",
              "       1.        , 1.        , 0.99530516, 0.99061033, 0.94583333,\n",
              "       0.99869281, 0.9973545 , 0.97865353, 0.78503788, 0.99749373,\n",
              "       1.        , 1.        , 0.99827288, 1.        , 1.        ,\n",
              "       0.99776286, 0.99801587, 1.        , 0.99635701, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99924242,\n",
              "       1.        , 0.8617284 , 0.94117647, 1.        , 1.        ,\n",
              "       0.90330789, 0.99650044, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.68302658, 1.        ,\n",
              "       1.        , 0.99724518, 1.        , 0.8524173 , 0.99655172,\n",
              "       0.94647202, 1.        , 1.        , 0.97214735, 0.98550725,\n",
              "       1.        , 1.        , 1.        , 0.99719888, 1.        ,\n",
              "       0.96514161, 1.        , 0.95238095, 0.99350649, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.99612403, 1.        , 1.        , 0.99751861,\n",
              "       1.        , 0.99494949, 1.        , 1.        , 0.9969419 ,\n",
              "       1.        , 1.        , 1.        , 0.9954955 , 0.99393939,\n",
              "       1.        , 0.99829932, 0.99463807, 0.92592593, 1.        ,\n",
              "       0.76779026, 0.93913043, 1.        , 1.        , 0.80392157,\n",
              "       0.99224806, 1.        , 0.9989899 , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.97826087, 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.99733333, 0.86217949,\n",
              "       1.        , 0.98312236, 0.99255121, 0.99774775, 0.99652778,\n",
              "       0.96875   , 1.        , 1.        , 1.        , 0.99587203,\n",
              "       0.99862826, 1.        , 1.        , 1.        , 0.93459916,\n",
              "       1.        , 0.99748428, 1.        , 1.        , 0.89159892,\n",
              "       1.        , 0.87816092, 0.99702381, 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.92937853, 0.98173516, 1.        ,\n",
              "       1.        , 0.953125  , 0.95670996, 0.99801587, 0.98412698,\n",
              "       0.98907104, 1.        , 0.85131894, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.58585859,\n",
              "       0.99415205, 0.99059829, 1.        , 1.        , 0.99921011,\n",
              "       0.96926714, 0.99907919, 0.94609929, 1.        , 1.        ,\n",
              "       0.91111111, 1.        , 1.        , 0.95588235, 1.        ,\n",
              "       0.96721311, 0.99259259, 1.        , 1.        , 0.9787234 ,\n",
              "       0.94444444, 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.95642702, 1.        , 0.73287671, 0.98780488, 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.86111111, 1.        ,\n",
              "       0.81420765, 0.96986817, 0.94680851, 0.99707602, 1.        ,\n",
              "       1.        , 1.        , 0.99561404, 0.98691301, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.99886621, 0.98798799, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.85823755, 1.        , 1.        ,\n",
              "       0.93045564, 0.99485597, 0.96517413, 0.99731183, 0.9969419 ,\n",
              "       1.        , 1.        , 0.98746867, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.99199199, 0.96517413,\n",
              "       1.        , 0.87435897, 0.99882214, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.98556999, 1.        ,\n",
              "       0.9974026 , 1.        , 1.        , 0.97495183, 0.99281609,\n",
              "       0.8377193 , 0.98657718, 1.        , 1.        , 0.95652174,\n",
              "       0.98878695, 0.98484848, 1.        , 0.99809524, 1.        ,\n",
              "       1.        , 1.        , 0.99578059, 0.9984051 , 0.98181818,\n",
              "       1.        , 1.        , 0.99906103, 0.99794239, 1.        ,\n",
              "       0.99281222, 0.92777778, 1.        , 1.        , 0.95778748,\n",
              "       0.9968254 , 0.99038462, 1.        , 1.        , 0.92982456,\n",
              "       1.        , 0.97484277, 0.94618056, 1.        , 0.97777778,\n",
              "       0.97668998, 1.        , 0.98939929, 1.        , 0.91518738,\n",
              "       1.        , 1.        , 0.97660819, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.95663957, 1.        , 0.99770115, 0.71875   , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.93079096, 0.99771689,\n",
              "       1.        , 1.        , 0.99479167, 0.96969697, 0.99801587,\n",
              "       1.        , 1.        , 1.        , 0.99520384, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.98484848, 0.94005848, 1.        , 1.        , 1.        ,\n",
              "       0.98736177, 0.70685579, 0.99905303, 0.93900709, 1.        ,\n",
              "       1.        , 0.95555556, 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.9420765 , 0.91481481, 1.        , 1.        ,\n",
              "       0.92907801, 0.97222222, 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.98039216, 0.99585921, 0.73287671, 0.98780488,\n",
              "       1.        , 0.84597701, 1.        , 1.        , 0.96481481,\n",
              "       0.99885057, 0.81420765, 0.99435028, 0.85815603, 0.75438596,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99921569,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.99206349, 0.99399399, 1.        , 1.        ,\n",
              "       1.        , 0.96491228, 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.93045564, 0.99485597, 1.        , 0.92473118,\n",
              "       0.99388379, 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.86754003, 1.        , 0.998999  ,\n",
              "       0.99751244, 0.99404762, 0.87435897, 0.95877503, 1.        ,\n",
              "       1.        , 0.88095238, 1.        , 1.        , 0.98556999,\n",
              "       1.        , 0.99741602, 0.89215686, 1.        , 1.        ,\n",
              "       0.94252874, 0.9991453 , 0.99552573, 1.        , 1.        ,\n",
              "       0.98671498, 0.98674822, 0.97186147, 1.        , 0.99809524,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.98883573,\n",
              "       0.98181818, 0.99368687, 1.        , 0.99903101, 0.97942387,\n",
              "       1.        , 0.96765499, 0.96944444, 0.99791667, 0.99439776,\n",
              "       1.        , 0.97619048, 0.96314103, 1.        , 0.99906103,\n",
              "       0.99561404, 1.        , 0.97484277, 0.94704861, 1.        ,\n",
              "       0.97777778, 0.95571096, 1.        , 0.99882214, 0.64636752,\n",
              "       0.98224852, 0.99585921, 0.997669  , 0.92202729, 0.99753086,\n",
              "       1.        , 1.        , 0.99399399, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99702381,\n",
              "       0.97859327, 1.        , 1.        , 1.        , 0.99011299,\n",
              "       1.        , 1.        , 0.9988466 , 1.        , 0.96103896,\n",
              "       0.99801587, 0.99206349, 1.        , 1.        , 0.99760192,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.99494949, 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.99159664, 0.9858156 , 1.        , 0.9787234 ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99765258,\n",
              "       1.        , 1.        , 0.92568306, 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.99074074, 1.        , 1.        ,\n",
              "       1.        , 0.70020325, 0.9869281 , 1.        , 0.73287671,\n",
              "       0.98780488, 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.81420765, 1.        , 1.        ,\n",
              "       0.97076023, 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.99554367, 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.92063492, 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.98830409, 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.93045564, 0.99485597, 1.        ,\n",
              "       0.96774194, 0.95718654, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.87435897, 0.9811543 ,\n",
              "       1.        , 1.        , 1.        , 0.99838969, 1.        ,\n",
              "       0.98556999, 1.        , 0.98008658, 1.        , 1.        ,\n",
              "       1.        , 0.98275862, 1.        , 0.99776286, 1.        ,\n",
              "       1.        , 0.93115942, 0.90286299, 0.61904762, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.99043062, 0.98181818, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.81746032, 0.98237179, 1.        ,\n",
              "       1.        , 0.99561404, 1.        , 0.97484277, 0.91383812,\n",
              "       1.        , 0.97777778, 0.66200466, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.99610136,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Bx2sLEPwRc2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import csv\n",
        "with open(M_path+'result_MLDM_ATTACK_WISE.csv', 'a+', newline='') as csv_file:\n",
        "      writer = csv.writer(csv_file)\n",
        "\n",
        "        # Write header\n",
        "      header=['datasetname', 'victimmodel','elapsed_time']\n",
        "      header.extend(list(metrics[4].keys()))\n",
        "      writer.writerow(header)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      row=[datasetname, victimmodel,mean_elapsed_time]\n",
        "      row.extend(list(metrics[4].values()))\n",
        "      writer.writerow(row)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W0oHdJcH7j0"
      },
      "outputs": [],
      "source": [
        "print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXfrmObDjTKQ"
      },
      "outputs": [],
      "source": [
        "with open(M_path+'result_MLDM.csv', 'a+', newline='') as csv_file:\n",
        "      print('open')\n",
        "      writer = csv.writer(csv_file)\n",
        "\n",
        "        # Write header\n",
        "      header=['datasetname', 'victimmodel','elapsed_time']\n",
        "      header.extend(list(metrics[4].keys()))\n",
        "      writer.writerow(header)\n",
        "      mean_elapsed_time = sum(elapse_time) / len(elapse_time)\n",
        "\n",
        "      row=[datasetname, victimmodel,mean_elapsed_time]\n",
        "      row.extend(list(metrics[4].values()))\n",
        "      writer.writerow(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqwxkKqajZxt"
      },
      "outputs": [],
      "source": [
        "path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuUPwcVBiu6M"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open(path+'result_MLDM.csv', 'a+', newline='') as csv_file:\n",
        "      writer = csv.writer(csv_file)\n",
        "\n",
        "        # Write header\n",
        "      header=['datasetname', 'victimmodel','elapsed_time']\n",
        "      header.extend(list(metrics[4].keys()))\n",
        "      writer.writerow(header)\n",
        "      mean_elapsed_time = sum(elapse_time) / len(elapse_time)\n",
        "\n",
        "      row=[datasetname, victimmodel,mean_elapsed_time]\n",
        "      row.extend(list(metrics[4].values()))\n",
        "      writer.writerow(row)\n",
        "\n",
        "\n",
        "Overall_elapsed_time = time.time() - Overall_start_time\n",
        "print(f'Overall processing time: {Overall_elapsed_time:.2f} seconds.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhlvVibXh0rS"
      },
      "source": [
        "##ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASGLum2Ug_Qe",
        "outputId": "a5f604a0-411f-426a-e916-6c88e8d8de79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def load_model(modelname):\n",
        "  model = RobertaForSequenceClassification.from_pretrained(modelname).to(device)\n",
        "  tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-large\")\n",
        "  average_sentence_length=19\n",
        "  model.eval()\n",
        "  return model, tokenizer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "3c5d7cb7f18b492f9a716833b292cbd0",
            "e0c9be22ac914e7b81711322d7329533",
            "34989980549246a0a5b280ff060810cc",
            "0717091e30d6403081aaac154b49c641",
            "925761ab3a7b47d08342d5f5acd27337",
            "fd5a90c8b152453ab5791ffeb6b17a31",
            "4596b61e83f7405caa535bf37d78958a",
            "a801c68a375b465cbb62539d7e266a01",
            "06944db9f4f84ed4b408a98a479d226c",
            "2bf245f26ae74c03977a7d47d49eb48d",
            "a32ba4b40dde49548fdc81e4bcd6efe4"
          ]
        },
        "id": "bqU7NRzTe1ph",
        "outputId": "5212b67b-bbc8-46e8-d22c-dcaba784c5e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c5d7cb7f18b492f9a716833b292cbd0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0c9be22ac914e7b81711322d7329533",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34989980549246a0a5b280ff060810cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0717091e30d6403081aaac154b49c641",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "925761ab3a7b47d08342d5f5acd27337",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd5a90c8b152453ab5791ffeb6b17a31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/559 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4596b61e83f7405caa535bf37d78958a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at textattack/roberta-base-imdb were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a801c68a375b465cbb62539d7e266a01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06944db9f4f84ed4b408a98a479d226c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bf245f26ae74c03977a7d47d49eb48d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a32ba4b40dde49548fdc81e4bcd6efe4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "org 999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1/192 [00:01<05:33,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$$$$LOADING\n",
            "adv 804\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 154/192 [58:58<18:20, 28.97s/it]"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import pickle\n",
        "import pickle,csv\n",
        "# Set the values for the arguments\n",
        "class Args:\n",
        "    tn = 3\n",
        "\n",
        "    unm_model = 'roberta-base'\n",
        "    hug = True\n",
        "    victim = 'roberta'\n",
        "    mfre = 1\n",
        "from transformers import RobertaForSequenceClassification,RobertaTokenizerFast\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "Datapath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "# Record the start time\n",
        "import time\n",
        "Overall_start_time = time.time()\n",
        "savepath='/content/gdrive/My Drive/CompareTry/benchmark_datasets/1K_Dataset/small_'\n",
        "editfeaturepath='/content/gdrive/My Drive/CompareTry/EDIT/'\n",
        "datasetnames=['imdb']\n",
        "victimmodel='roberta'\n",
        "#datasetnames=['imdb','yelp_polarity','sst2','ag_news\n",
        "\n",
        "batch_size = 32  # Set your desired batch size\n",
        "\n",
        "modelpath='textattack/roberta-base-'\n",
        "for i,datasetname in enumerate(datasetnames):\n",
        "    if(datasetname=='ag_news'):\n",
        "        modelname=modelpath+'ag-news'\n",
        "    elif datasetname=='yelp_polarity':\n",
        "       modelname='VictorSanh/roberta-base-finetuned-'+'yelp-polarity'\n",
        "    elif datasetname=='sst2':\n",
        "       modelname=modelpath+'SST-2'\n",
        "    else:\n",
        "       modelname=modelpath+datasetname\n",
        "    args = Args()\n",
        "\n",
        "    candidate_token_num=args.tn\n",
        "    huggingface_model=args.hug\n",
        "    ma_fre=args.mfre\n",
        "\n",
        "    # Load masked language models\n",
        "    if args.unm_model=='roberta-base':\n",
        "        tokenizer=RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "        model = RobertaForMaskedLM.from_pretrained(\"roberta-base\")\n",
        "    elif args.unm_model=='bert-base-uncased':\n",
        "        tokenizer=RobertaTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        model = RobertaForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "    else:\n",
        "        tokenizer=RobertaTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "        model = RobertaForMaskedLM.from_pretrained(\"albert-base-v2\")\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Load detection file\n",
        "    detection_file = ''\n",
        "\n",
        "    # LOAD VICTIM MODEL\n",
        "    model_cls,tokenizer_cls=load_model(modelname)\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model_cls = nn.DataParallel(model_cls)\n",
        "        model_cls = model_cls.to(device)\n",
        "\n",
        "\n",
        "    path=savepath+datasetname+'_'+victimmodel\n",
        "    benigns=pd.read_csv(path+'_clean_data.csv')\n",
        "    advs=pd.read_csv(path+'_adv_data.csv')\n",
        "    if(datasetname!='sst2'):\n",
        "         x_benigns=list(benigns['text'])\n",
        "    else:\n",
        "      x_benigns=list(benigns['sentence'])\n",
        "    x_advs=list(advs['perturbed_text'])\n",
        "\n",
        "    all_ben_masked_str=[]\n",
        "    all_ben_masked_str_tokens=[]\n",
        "    all_ben_um_sentence=[]\n",
        "    all_ben_um_sentence_label=[]\n",
        "    all_ben_euq_labels=[]\n",
        "    all_ben_logits_out=[]\n",
        "    n=1000\n",
        "    elapse_time=[]\n",
        "    # padding_socre_diff_f=[]\n",
        "    # x_benigns, x_advs = get_adv(detect)\n",
        "    rand_index =np.random.choice(len(x_benigns),n)\n",
        "    file_path=datasetname+victimmodel+str(len(x_benigns)-1)+'Benign.pkl'\n",
        "    if os.path.exists(file_path):\n",
        "           with open(file_path, 'rb') as file:\n",
        "              loaded_data = pickle.load(file)\n",
        "        # Process the loaded data as needed\n",
        "              all_ben_logits_out, all_ben_um_sentence_label, all_ben_euq_labels,elapse_time = loaded_data\n",
        "              print(\"org\",str(len(x_benigns)-1))\n",
        "    else:\n",
        "      for idx in tqdm(range(n)):\n",
        "          file_path=datasetname+victimmodel+str(idx)+'Benign.pkl'\n",
        "          if os.path.exists(file_path):\n",
        "            with open(file_path, 'rb') as file:\n",
        "                loaded_data = pickle.load(file)\n",
        "          # Process the loaded data as needed\n",
        "                all_ben_logits_out, all_ben_um_sentence_label, all_ben_euq_labels,elapse_time = loaded_data\n",
        "                print(\"org\",idx)\n",
        "          else:\n",
        "            start_time = time.time()\n",
        "            orig_str=x_benigns[idx]\n",
        "            if(len(orig_str.split(' '))>1):\n",
        "              # masked_str=rand_mask_string(orig_str,tokenizer,ma_fre)\n",
        "              masked_str=mask_string(orig_str,tokenizer)\n",
        "              all_ben_masked_str.append(masked_str)\n",
        "\n",
        "              masked_str=mask_string(orig_str,tokenizer)\n",
        "              all_ben_masked_str.append(masked_str)\n",
        "\n",
        "              masked_str_tokens = masked_str_token(masked_str,model,tokenizer)\n",
        "              all_ben_masked_str_tokens.append(masked_str_tokens)\n",
        "\n",
        "              um_sentence = get_mlm_um_sen(masked_str,masked_str_tokens,3)\n",
        "              all_ben_um_sentence.append(um_sentence)\n",
        "\n",
        "              um_sen_logits_out,um_sen_conf_socres,um_sen_label= predict_class(um_sentence,model_cls,tokenizer_cls,huggingface_model)\n",
        "              all_ben_logits_out.append(um_sen_logits_out)\n",
        "              all_ben_um_sentence_label.append(um_sen_label)\n",
        "\n",
        "              #distinguishable score\n",
        "              # _,orig_str_sorce,_= predict_class([orig_str],model_cls,tokenizer_cls)\n",
        "              # padding_socre_diff=compute_score_difference_padding(orig_str_sorce,um_sen_conf_socres)\n",
        "              # padding_socre_diff = padding_socre_diff[:,:1].unsqueeze(0)\n",
        "\n",
        "              # padding_socre_diff_sig  = padding_socre_diff.cpu().numpy().flatten().tolist()\n",
        "              # padding_socre_diff_f.append(padding_socre_diff_sig)\n",
        "\n",
        "              euq_labels= euq_label(orig_str,um_sen_label,model_cls,tokenizer_cls,candidate_token_num,huggingface_model)\n",
        "              all_ben_euq_labels.append(euq_labels)\n",
        "              end_time = time.time()\n",
        "              elapsed_time = end_time - start_time\n",
        "              print(\"time taken \",elapsed_time)\n",
        "              elapse_time.append(elapsed_time)\n",
        "              with open(file_path, 'wb') as file:\n",
        "                pickle.dump([all_ben_logits_out,all_ben_um_sentence_label,all_ben_euq_labels,elapse_time], file)\n",
        "    all_adv_masked_str=[]\n",
        "    all_adv_masked_str_tokens=[]\n",
        "    all_adv_um_sentence=[]\n",
        "    all_adv_um_sentence_label=[]\n",
        "    all_adv_euq_labels=[]\n",
        "    all_adv_logits_out=[]\n",
        "    n=len(x_advs)\n",
        "\n",
        "    file_path=datasetname+victimmodel+str(len(x_advs)-1)+'adv.pkl'\n",
        "    if os.path.exists(file_path):\n",
        "           with open(file_path, 'rb') as file:\n",
        "              loaded_data = pickle.load(file)\n",
        "              # Process the loaded data as needed\n",
        "              all_adv_logits_out,all_adv_um_sentence_label,all_adv_euq_labels,elapse_time = loaded_data\n",
        "           print(\"adv\",len(x_advs)-1)\n",
        "    else:\n",
        "     for idx in tqdm(range(n)):\n",
        "      file_path=datasetname+victimmodel+str(idx)+'adv.pkl'\n",
        "      if os.path.exists(file_path):\n",
        "          with open(file_path, 'rb') as file:\n",
        "              loaded_data = pickle.load(file)\n",
        "        # Process the loaded data as needed\n",
        "          all_adv_logits_out,all_adv_um_sentence_label,all_adv_euq_labels,elapse_time = loaded_data\n",
        "          print(\"adv\",idx)\n",
        "      else:\n",
        "          start_time = time.time()\n",
        "          orig_str=x_advs[idx]\n",
        "          if(len(orig_str.split(' '))>1):\n",
        "            # masked_str=rand_mask_string(orig_str,tokenizer,ma_fre)\n",
        "            masked_str=mask_string(orig_str,tokenizer)\n",
        "            all_adv_masked_str.append(masked_str)\n",
        "\n",
        "            masked_str=mask_string(orig_str,tokenizer)\n",
        "            all_adv_masked_str.append(masked_str)\n",
        "\n",
        "            masked_str_tokens = masked_str_token(masked_str,model,tokenizer)\n",
        "            all_adv_masked_str_tokens.append(masked_str_tokens)\n",
        "\n",
        "            um_sentence = get_mlm_um_sen(masked_str,masked_str_tokens,3)\n",
        "            all_adv_um_sentence.append(um_sentence)\n",
        "\n",
        "            um_sen_logits_out,um_sen_conf_socres,um_sen_label= predict_class(um_sentence,model_cls,tokenizer_cls,huggingface_model)\n",
        "            all_adv_logits_out.append(um_sen_logits_out)\n",
        "            all_adv_um_sentence_label.append(um_sen_label)\n",
        "\n",
        "            #distinguishable score\n",
        "            # _,orig_str_sorce,_= predict_class([orig_str],model_cls,tokenizer_cls)\n",
        "            # padding_socre_diff=compute_score_difference_padding(orig_str_sorce,um_sen_conf_socres)\n",
        "            # padding_socre_diff = padding_socre_diff[:,:1].unsqueeze(0)\n",
        "\n",
        "\n",
        "            # padding_socre_diff_sig  = padding_socre_diff.cpu().numpy().flatten().tolist()\n",
        "            # padding_socre_diff_f.append(padding_socre_diff_sig)\n",
        "\n",
        "            euq_labels= euq_label(orig_str,um_sen_label,model_cls,tokenizer_cls,candidate_token_num,huggingface_model)\n",
        "            all_adv_euq_labels.append(euq_labels)\n",
        "            end_time = time.time()\n",
        "            elapsed_time = end_time - start_time\n",
        "            elapse_time.append(elapsed_time)\n",
        "            with open(file_path, 'wb') as file:\n",
        "              pickle.dump([all_adv_logits_out,all_adv_um_sentence_label,all_adv_euq_labels,elapse_time], file)\n",
        "\n",
        "    if os.path.exists(datasetname+victimmodel+'benign_adv.pkl'):\n",
        "      with open(datasetname+victimmodel+'benign_adv.pkl', 'rb') as file:\n",
        "        loaded_data = pickle.load(file)\n",
        "        # Process the loaded data as needed\n",
        "        ben_metric, adv_metric = loaded_data\n",
        "    else:\n",
        "      ben_metric=mean_mean_label(all_ben_euq_labels)\n",
        "      adv_metric=mean_mean_label(all_adv_euq_labels)\n",
        "      with open(datasetname+victimmodel+'benign_adv.pkl', 'wb') as file:\n",
        "            pickle.dump([ben_metric,adv_metric], file)\n",
        "    metrics=gap_infer_acc_f1(ben_metric, adv_metric)\n",
        "    # print('unmask model:',args.unm_model)\n",
        "    # print('candidate_token_num:',candidate_token_num)\n",
        "    # print(\"mask frequency is :\",ma_fre)\n",
        "    # print('test config:',detection_file)\n",
        "    # print('********')\n",
        "    # print('gap_a:',gap_a,\"ACC:\",acc,\"gap_f:\",gap_f,'F1:',f1)\n",
        "    print(metrics)\n",
        "\n",
        "    with open(M_path+'result_MLDM.csv', 'a+', newline='') as csv_file:\n",
        "      writer = csv.writer(csv_file)\n",
        "\n",
        "        # Write header\n",
        "      header=['datasetname', 'victimmodel','elapsed_time']\n",
        "      header.extend(list(metrics[4].keys()))\n",
        "      writer.writerow(header)\n",
        "      mean_elapsed_time = sum(elapse_time) / len(elapse_time)\n",
        "\n",
        "      row=[datasetname, victimmodel,mean_elapsed_time]\n",
        "      row.extend(list(metrics[4].values()))\n",
        "      writer.writerow(row)\n",
        "\n",
        "\n",
        "Overall_elapsed_time = time.time() - Overall_start_time\n",
        "print(f'Overall processing time: {Overall_elapsed_time:.2f} seconds.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrpTVB10fRy8"
      },
      "outputs": [],
      "source": [
        "# with open(datasetname+victimmodel+'results.pkl', 'a+') as file:\n",
        "#           pickle.dump([metrics], file)\n",
        "with open(path+'result_MLDM.csv', 'a+', newline='') as csv_file:\n",
        "      writer = csv.writer(csv_file)\n",
        "\n",
        "        # Write header\n",
        "      header=['datasetname', 'victimmodel','elapsed_time']\n",
        "      header.extend(list(metrics[4].keys()))\n",
        "      writer.writerow(header)\n",
        "      mean_elapsed_time = sum(elapse_time) / len(elapse_time)\n",
        "\n",
        "      row=[datasetname, victimmodel,mean_elapsed_time]\n",
        "      row.extend(list(metrics[4].values()))\n",
        "      writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmXfNSWylr6g"
      },
      "outputs": [],
      "source": [
        "print(row\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCmtz82LA0yU"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "with open(path+'result_MLDM.csv', 'a+', newline='') as csv_file:\n",
        "      writer = csv.writer(csv_file)\n",
        "\n",
        "        # Write header\n",
        "      header=['datasetname', 'victimmodel']\n",
        "      header.extend(list(metrics[4].keys()))\n",
        "      writer.writerow(header)\n",
        "      row=[datasetname, victimmodel]\n",
        "      row.extend(list(metrics[4].values()))\n",
        "      writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRgCGbEJYP4J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL9LuZnf0whS"
      },
      "outputs": [],
      "source": [
        "all_adv_masked_str=[]\n",
        "all_adv_masked_str_tokens=[]\n",
        "all_adv_um_sentence=[]\n",
        "all_adv_um_sentence_label=[]\n",
        "all_adv_euq_labels=[]\n",
        "all_adv_logits_out=[]\n",
        "n= len(x_advs)\n",
        "for idx in tqdm(range(n)):\n",
        "\n",
        "        orig_str=x_advs[rand_index[idx]]\n",
        "        # masked_str=rand_mask_string(orig_str,tokenizer,ma_fre)\n",
        "        masked_str=mask_string(orig_str,tokenizer)\n",
        "        all_adv_masked_str.append(masked_str)\n",
        "\n",
        "        masked_str=mask_string(orig_str,tokenizer)\n",
        "        all_adv_masked_str.append(masked_str)\n",
        "\n",
        "        masked_str_tokens = masked_str_token(masked_str,model,tokenizer)\n",
        "        all_adv_masked_str_tokens.append(masked_str_tokens)\n",
        "\n",
        "        um_sentence = get_mlm_um_sen(masked_str,masked_str_tokens,3)\n",
        "        all_adv_um_sentence.append(um_sentence)\n",
        "\n",
        "        um_sen_logits_out,um_sen_conf_socres,um_sen_label= predict_class(um_sentence,model_cls,tokenizer_cls,huggingface_model)\n",
        "        all_adv_logits_out.append(um_sen_logits_out)\n",
        "        all_adv_um_sentence_label.append(um_sen_label)\n",
        "\n",
        "        #distinguishable score\n",
        "        # _,orig_str_sorce,_= predict_class([orig_str],model_cls,tokenizer_cls)\n",
        "        # padding_socre_diff=compute_score_difference_padding(orig_str_sorce,um_sen_conf_socres)\n",
        "        # padding_socre_diff = padding_socre_diff[:,:1].unsqueeze(0)\n",
        "\n",
        "\n",
        "        # padding_socre_diff_sig  = padding_socre_diff.cpu().numpy().flatten().tolist()\n",
        "        # padding_socre_diff_f.append(padding_socre_diff_sig)\n",
        "\n",
        "        euq_labels= euq_label(orig_str,um_sen_label,model_cls,tokenizer_cls,candidate_token_num,huggingface_model)\n",
        "        all_adv_euq_labels.append(euq_labels)\n",
        "with open(datasetname+victimmodel+'adv.pkl', 'wb') as file:\n",
        "          pickle.dump([all_adv_logits_out,all_adv_um_sentence_label,all_adv_euq_labels], file)\n",
        "ben_metric=mean_mean_label(all_ben_euq_labels)\n",
        "adv_metric=mean_mean_label(all_adv_euq_labels)\n",
        "with open(datasetname+victimmodel+'benign_adv.pkl', 'wb') as file:\n",
        "          pickle.dump([ben_metric,adv_metric], file)\n",
        "metrics=gap_infer_acc_f1(ben_metric, adv_metric)\n",
        "    # print('unmask model:',args.unm_model)\n",
        "    # print('candidate_token_num:',candidate_token_num)\n",
        "    # print(\"mask frequency is :\",ma_fre)\n",
        "    # print('test config:',detection_file)\n",
        "    # print('********')\n",
        "    # print('gap_a:',gap_a,\"ACC:\",acc,\"gap_f:\",gap_f,'F1:',f1)\n",
        "print(metrics)\n",
        "with open(datasetname+victimmodel+'results.pkl', 'wb') as file:\n",
        "          pickle.dump(metrics, file)\n",
        "\n",
        "Overall_elapsed_time = time.time() - Overall_start_time\n",
        "print(f'Overall processing time: {Overall_elapsed_time:.2f} seconds.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPwviiy25ziu"
      },
      "outputs": [],
      "source": [
        "x_advs[rand_index[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI1PqyAw516C"
      },
      "outputs": [],
      "source": [
        "rand_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_YJTzYs93Bvt"
      },
      "outputs": [],
      "source": [
        "ben_metric=mean_mean_label(all_ben_euq_labels)\n",
        "adv_metric=mean_mean_label(all_adv_euq_labels)\n",
        "metrics=gap_infer_acc_f1(ben_metric, adv_metric)\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsIMVzRr2ybh"
      },
      "outputs": [],
      "source": [
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FImKD3odxtL_"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "xgb_classifier = xgb.XGBClassifier(\n",
        "                    max_depth=3,\n",
        "                    learning_rate=0.34281802,\n",
        "                    gamma=0.6770816,\n",
        "                    min_child_weight=2.5520658,\n",
        "                    max_delta_step=0.71469694,\n",
        "                    subsample=0.61460966,\n",
        "                    colsample_bytree=0.73929816,\n",
        "                    colsample_bylevel=0.87191725,\n",
        "                    reg_alpha=0.9064181,\n",
        "                    reg_lambda=0.5686102,\n",
        "                    n_estimators=29,\n",
        "                    # silent=0,\n",
        "                    nthread=4,\n",
        "                    scale_pos_weight=1.0,\n",
        "                    base_score=0.5,\n",
        "                    # missing=None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGyRkaAy0zkZ"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BISvQt8z5W4H",
        "NMbiymm6WkwF",
        "QbqtH6J9WWgy"
      ],
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f315ba1cc0b3457d80b1abbfe5f6fc5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5dbb161b3839446fb0e535cf0c23a0e8",
              "IPY_MODEL_3e3920fc40c34d0092105e60b3f88957",
              "IPY_MODEL_059e655f22e441d3952fd76674227fb0"
            ],
            "layout": "IPY_MODEL_225ae5b976ed44df90ae0d74762f45b4"
          }
        },
        "5dbb161b3839446fb0e535cf0c23a0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d94f92a4838547a8b6dc0c8adda2d5b9",
            "placeholder": "​",
            "style": "IPY_MODEL_bc0c5be1956940a7a45e37a46dbb1560",
            "value": "vocab.json: 100%"
          }
        },
        "3e3920fc40c34d0092105e60b3f88957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6b2dba5dff45d3aacc296d0097a555",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fefacf8b4a045d596a1e02b95c8d828",
            "value": 898823
          }
        },
        "059e655f22e441d3952fd76674227fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ca550c69a84539b7bece89265a2a0f",
            "placeholder": "​",
            "style": "IPY_MODEL_56f82cce2b824ed381063229ed0045b1",
            "value": " 899k/899k [00:00&lt;00:00, 5.22MB/s]"
          }
        },
        "225ae5b976ed44df90ae0d74762f45b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94f92a4838547a8b6dc0c8adda2d5b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0c5be1956940a7a45e37a46dbb1560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a6b2dba5dff45d3aacc296d0097a555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fefacf8b4a045d596a1e02b95c8d828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6ca550c69a84539b7bece89265a2a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f82cce2b824ed381063229ed0045b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8793587c4634505b225a8b907ad46c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe5368387e604452ab72af193997cb39",
              "IPY_MODEL_255d499f3a69435b92afab81b74c2e5e",
              "IPY_MODEL_f649bdc4f6ec4a1aa617ec5ff571c639"
            ],
            "layout": "IPY_MODEL_42bb816262e44d30a7db7af33296c655"
          }
        },
        "fe5368387e604452ab72af193997cb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a1ccc3e4da423f922338c7783aba6b",
            "placeholder": "​",
            "style": "IPY_MODEL_c0df99ffc1e5401796c18ddead34dd82",
            "value": "merges.txt: 100%"
          }
        },
        "255d499f3a69435b92afab81b74c2e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93fed13940f8459d995503c08dff78b2",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7949e3efa5394354a526c65254374776",
            "value": 456318
          }
        },
        "f649bdc4f6ec4a1aa617ec5ff571c639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaf6327b86c84172ab1e7891ada13195",
            "placeholder": "​",
            "style": "IPY_MODEL_998abde92597400b957c1505b8d9db87",
            "value": " 456k/456k [00:00&lt;00:00, 4.11MB/s]"
          }
        },
        "42bb816262e44d30a7db7af33296c655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a1ccc3e4da423f922338c7783aba6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0df99ffc1e5401796c18ddead34dd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93fed13940f8459d995503c08dff78b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7949e3efa5394354a526c65254374776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaf6327b86c84172ab1e7891ada13195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998abde92597400b957c1505b8d9db87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af79e577c50148b98c6893d7545eba7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e06250eab263411b89418bcd4fe989ee",
              "IPY_MODEL_58d23455fede4b5888536b2c052c2131",
              "IPY_MODEL_a14857cf26d74732bd289c0874006a3e"
            ],
            "layout": "IPY_MODEL_895b5427f3da4001a45f250f62469b79"
          }
        },
        "e06250eab263411b89418bcd4fe989ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d10a7a30294473e88c39b019f91eb74",
            "placeholder": "​",
            "style": "IPY_MODEL_5c3e9188d9a449c7a091aa148031e99a",
            "value": "tokenizer.json: 100%"
          }
        },
        "58d23455fede4b5888536b2c052c2131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_931c1a7a42e24148864df49cc4852d67",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34244de9ccf34f49815f5fc92cd55f87",
            "value": 1355863
          }
        },
        "a14857cf26d74732bd289c0874006a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd78a3a76004638a842e45bc76a84cc",
            "placeholder": "​",
            "style": "IPY_MODEL_9728f46dc4c3486c91e6f4fcf9da294e",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 18.7MB/s]"
          }
        },
        "895b5427f3da4001a45f250f62469b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d10a7a30294473e88c39b019f91eb74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c3e9188d9a449c7a091aa148031e99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "931c1a7a42e24148864df49cc4852d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34244de9ccf34f49815f5fc92cd55f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fd78a3a76004638a842e45bc76a84cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9728f46dc4c3486c91e6f4fcf9da294e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2959eb6c7b42498ebec6ddcd75b7b01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_535cf33f18654dd9b74cd8b1d8e43b74",
              "IPY_MODEL_9cf978f6d6094661afb2d4cdfd8af75f",
              "IPY_MODEL_2d2d5ba22453479783894929f57b728c"
            ],
            "layout": "IPY_MODEL_bc627b72c924482798ff8ec751b32475"
          }
        },
        "535cf33f18654dd9b74cd8b1d8e43b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb507e5872da4fc49f520cc703059cbe",
            "placeholder": "​",
            "style": "IPY_MODEL_3cc3dd2798614efa9912ef8f458fe817",
            "value": "config.json: 100%"
          }
        },
        "9cf978f6d6094661afb2d4cdfd8af75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba512d83b11b4dc99686bbf4ed2c74c1",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30dae50f020b441a8602336c00e54e24",
            "value": 481
          }
        },
        "2d2d5ba22453479783894929f57b728c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beddf4da962548dabcec8480e350d7d1",
            "placeholder": "​",
            "style": "IPY_MODEL_6137a8f1162a475fa39ca30e0b44f812",
            "value": " 481/481 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "bc627b72c924482798ff8ec751b32475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb507e5872da4fc49f520cc703059cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cc3dd2798614efa9912ef8f458fe817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba512d83b11b4dc99686bbf4ed2c74c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dae50f020b441a8602336c00e54e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "beddf4da962548dabcec8480e350d7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6137a8f1162a475fa39ca30e0b44f812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8bcdf89089e4eafbd7103375d4ba081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b18471f5f904338890b036ae8c618e6",
              "IPY_MODEL_dd5e36da842443c4a13dfe9142ec7d40",
              "IPY_MODEL_3fc495602e1042208095f1877723bbd7"
            ],
            "layout": "IPY_MODEL_5993791d71344181b4bf7f019ea7fb8a"
          }
        },
        "5b18471f5f904338890b036ae8c618e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fc7ae38833c494e8069d733c4af68cd",
            "placeholder": "​",
            "style": "IPY_MODEL_8384c3d427b9460788d91f0ab78e3f6d",
            "value": "model.safetensors: 100%"
          }
        },
        "dd5e36da842443c4a13dfe9142ec7d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf2cf7b32644b988c10d8d4a2096583",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eeea40cc9ff44243883c20f311f1a7fe",
            "value": 498818054
          }
        },
        "3fc495602e1042208095f1877723bbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d67bc038ce46beb813c7a75da3f3d2",
            "placeholder": "​",
            "style": "IPY_MODEL_7edd9f2c7e9c4402845b105031878864",
            "value": " 499M/499M [00:05&lt;00:00, 168MB/s]"
          }
        },
        "5993791d71344181b4bf7f019ea7fb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc7ae38833c494e8069d733c4af68cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8384c3d427b9460788d91f0ab78e3f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acf2cf7b32644b988c10d8d4a2096583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeea40cc9ff44243883c20f311f1a7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3d67bc038ce46beb813c7a75da3f3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7edd9f2c7e9c4402845b105031878864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3455cbc02d2f4c8bb95f5ab36ffaf6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ad504eb2f1045e49665314f0b920cf2",
              "IPY_MODEL_50d4bcadab5045a88329ec5f10c560f3",
              "IPY_MODEL_925eead75fd2493db5eb70afd8f5a0f4"
            ],
            "layout": "IPY_MODEL_77a43f6e154545359b0753c8af0adc3a"
          }
        },
        "6ad504eb2f1045e49665314f0b920cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a98b9a570c41bcabfdc457fd9aeb7e",
            "placeholder": "​",
            "style": "IPY_MODEL_230767cacd294c4c997cdedd2764920b",
            "value": "config.json: 100%"
          }
        },
        "50d4bcadab5045a88329ec5f10c560f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_840e1b105b2849c9a7b7aff81e6c4cfc",
            "max": 511,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a580a46f456f47348c30b419b0b534c2",
            "value": 511
          }
        },
        "925eead75fd2493db5eb70afd8f5a0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36abbc6d4761417d86580f1a418875ed",
            "placeholder": "​",
            "style": "IPY_MODEL_56421f07508c43e4a77675ccb142ef40",
            "value": " 511/511 [00:00&lt;00:00, 17.8kB/s]"
          }
        },
        "77a43f6e154545359b0753c8af0adc3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a98b9a570c41bcabfdc457fd9aeb7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "230767cacd294c4c997cdedd2764920b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "840e1b105b2849c9a7b7aff81e6c4cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a580a46f456f47348c30b419b0b534c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36abbc6d4761417d86580f1a418875ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56421f07508c43e4a77675ccb142ef40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bb0e8afcab648b0947acb97b963bbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_192eb42953e0429cad0ac960c04e9f6a",
              "IPY_MODEL_1cecf34235944c898f22668af2624bf5",
              "IPY_MODEL_8566a4bff01941c9b8aac11d5b4dab4b"
            ],
            "layout": "IPY_MODEL_89c974b3303b443396c81c02a134524e"
          }
        },
        "192eb42953e0429cad0ac960c04e9f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e99f1f85c6de47f581e1e04e33600cad",
            "placeholder": "​",
            "style": "IPY_MODEL_8345dd42315e4bd89a4e6bbabb763607",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1cecf34235944c898f22668af2624bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e4e0f898c284b828c98d284e634b8a1",
            "max": 437985387,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ee52b455d814c079dda967df5e5296d",
            "value": 437985387
          }
        },
        "8566a4bff01941c9b8aac11d5b4dab4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8513925d320b4f75a0a00f6fbc93871b",
            "placeholder": "​",
            "style": "IPY_MODEL_352399f8a9cf4c4cb10ba420b000cc10",
            "value": " 438M/438M [00:03&lt;00:00, 116MB/s]"
          }
        },
        "89c974b3303b443396c81c02a134524e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99f1f85c6de47f581e1e04e33600cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8345dd42315e4bd89a4e6bbabb763607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e4e0f898c284b828c98d284e634b8a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee52b455d814c079dda967df5e5296d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8513925d320b4f75a0a00f6fbc93871b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "352399f8a9cf4c4cb10ba420b000cc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c62642110d4b4909925fdc50c01d9203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20893aa06c61494d90639c2bc42131af",
              "IPY_MODEL_a51e8d9671024cee90ac828dbc3056ce",
              "IPY_MODEL_eec159cc78604860ac7cc0b405bfe092"
            ],
            "layout": "IPY_MODEL_891c5d994fa34743ba7a59eb12ed00de"
          }
        },
        "20893aa06c61494d90639c2bc42131af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f160aaa1ad14d7191497df4ce4d4838",
            "placeholder": "​",
            "style": "IPY_MODEL_0fe79100e8dc4b749edf0bf4d0248ef3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a51e8d9671024cee90ac828dbc3056ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63a8899a57c84e4aafa31f4f8277ab4c",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_749f00f81e6242b0bde909f04985f47d",
            "value": 48
          }
        },
        "eec159cc78604860ac7cc0b405bfe092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f958ee2a484d909b2b5c45e0a38da3",
            "placeholder": "​",
            "style": "IPY_MODEL_852a4479674b41b0b33e7d4ad8585c38",
            "value": " 48.0/48.0 [00:00&lt;00:00, 900B/s]"
          }
        },
        "891c5d994fa34743ba7a59eb12ed00de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f160aaa1ad14d7191497df4ce4d4838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe79100e8dc4b749edf0bf4d0248ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63a8899a57c84e4aafa31f4f8277ab4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "749f00f81e6242b0bde909f04985f47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59f958ee2a484d909b2b5c45e0a38da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "852a4479674b41b0b33e7d4ad8585c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd114717ad8543b4bd14fb51bf2795d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4b0f842d62f48f7a38ecc59352dd45e",
              "IPY_MODEL_d22e5e8d480b4b9cb7551ce0efdfa251",
              "IPY_MODEL_b9ece7a6f0144b318104778210358c9e"
            ],
            "layout": "IPY_MODEL_485786ea5ffd4fc48de67fe8b2ff46d3"
          }
        },
        "a4b0f842d62f48f7a38ecc59352dd45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15cf5fe7abbf4a52829e9a10f96fec8d",
            "placeholder": "​",
            "style": "IPY_MODEL_743434f592564b7bb244d50036151fb5",
            "value": "vocab.txt: 100%"
          }
        },
        "d22e5e8d480b4b9cb7551ce0efdfa251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc61ef5b5b2429fa4a781936d740d3b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa900c6ec65948b586c57f9f85d91f62",
            "value": 231508
          }
        },
        "b9ece7a6f0144b318104778210358c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f94f4ed175147b38be6ab338c5ebffa",
            "placeholder": "​",
            "style": "IPY_MODEL_10a9d2bcacac4bb98af07276f39dd82e",
            "value": " 232k/232k [00:00&lt;00:00, 4.21MB/s]"
          }
        },
        "485786ea5ffd4fc48de67fe8b2ff46d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15cf5fe7abbf4a52829e9a10f96fec8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "743434f592564b7bb244d50036151fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fc61ef5b5b2429fa4a781936d740d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa900c6ec65948b586c57f9f85d91f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f94f4ed175147b38be6ab338c5ebffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a9d2bcacac4bb98af07276f39dd82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7276bc9a99084a6a875b05ae83db75f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97d63b279fd744b291cd396b810fe077",
              "IPY_MODEL_b17e4c7537d943ae9d07b5d964b1d684",
              "IPY_MODEL_3bb41ff6450545b2baf0866a1d9cdbb1"
            ],
            "layout": "IPY_MODEL_7eb32cbdc79e4f96b49560849d37f28f"
          }
        },
        "97d63b279fd744b291cd396b810fe077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b8967b193b845daa89d7d2ea84eee4c",
            "placeholder": "​",
            "style": "IPY_MODEL_407b05b4f5fc4e5ea170d97133a8753a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b17e4c7537d943ae9d07b5d964b1d684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d414d62d93947b29048aecad15ce578",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c460dcce23ce4be98c021ebfced02410",
            "value": 112
          }
        },
        "3bb41ff6450545b2baf0866a1d9cdbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62edb871ed1e499495c61bc9b084d989",
            "placeholder": "​",
            "style": "IPY_MODEL_a267cc805bca4138b53ef8edfcc844f0",
            "value": " 112/112 [00:00&lt;00:00, 2.02kB/s]"
          }
        },
        "7eb32cbdc79e4f96b49560849d37f28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8967b193b845daa89d7d2ea84eee4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407b05b4f5fc4e5ea170d97133a8753a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d414d62d93947b29048aecad15ce578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c460dcce23ce4be98c021ebfced02410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62edb871ed1e499495c61bc9b084d989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a267cc805bca4138b53ef8edfcc844f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}