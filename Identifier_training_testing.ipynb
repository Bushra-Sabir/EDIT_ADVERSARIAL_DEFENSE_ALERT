{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4pmj7e8woMY",
        "outputId": "575f6f0f-c594-46e2-df60-bd444b924acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as imPipeline\n",
        "from xgboost import XGBClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_fscore_support, balanced_accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as imPipeline"
      ],
      "metadata": {
        "id": "lhfIlTbgw7Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"Unique labels in y_test:\", np.unique(y_test))\n",
        "    print(\"Unique labels in predictions:\", np.unique(predictions))\n",
        "\n",
        "    probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "\n",
        "    if cm.shape == (1, 1):\n",
        "        # Only one class present in y_test and/or predictions\n",
        "        tn, fp, fn, tp = (cm[0, 0], 0, 0, 0) if np.unique(y_test)[0] == 0 else (0, 0, 0, cm[0, 0])\n",
        "    else:\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    fpr = fp / (fp + tn)\n",
        "    fnr = fn / (fn + tp)\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    youdens_index = sensitivity + specificity - 1\n",
        "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, predictions, average='macro')\n",
        "    balanced_accuracy = balanced_accuracy_score(y_test, predictions)\n",
        "\n",
        "    results = {\n",
        "        'FPR': fpr,\n",
        "        'FNR': fnr,\n",
        "        'AUC': roc_auc,\n",
        "        'F1 Score': f1_score,\n",
        "        'Recall': recall,\n",
        "        'Precision': precision,\n",
        "        'Balanced Accuracy': balanced_accuracy,\n",
        "        'Youden\\'s Index': youdens_index\n",
        "    }\n",
        "    return results"
      ],
      "metadata": {
        "id": "YLNIRcnXxAfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "datasets=['imdb','sst2','ag-news','yelp_polarity']\n",
        "\n",
        "\n",
        "for dataset_name in datasets:\n",
        "  models=[]\n",
        "  if(dataset_name in ['imdb','ag-news']):\n",
        "\n",
        "    models.append('textattack/bert-base-uncased-'+dataset_name)\n",
        "    models.append('textattack/roberta-base-'+dataset_name)\n",
        "  elif(dataset_name =='sst2'):\n",
        "    models.append('textattack/bert-base-uncased-SST-2')\n",
        "    models.append('textattack/roberta-base-SST-2')\n",
        "\n",
        "  else:\n",
        "    models.append('textattack/bert-base-uncased-yelp-polarity')\n",
        "    models.append('VictorSanh/roberta-base-finetuned-yelp-polarity')\n",
        "\n",
        "  print(dataset_name)\n",
        "  print(models)\n",
        "  for model_name in models:\n",
        "        path = '/content/gdrive/My Drive/GLAD_RESULTS/' + dataset_name + '/'\n",
        "        savepath='/content/gdrive/My Drive/GLAD_RESULTS/identifier_performance/'\n",
        "        savepath=savepath+dataset_name+model_name.split('/')[1]\n",
        "        adversarial_file = path + 'Identify' + dataset_name + '_' + model_name.split('/')[1] + '_dataset_final_try.csv'\n",
        "        df = pd.read_csv(adversarial_file)\n",
        "        df = df.drop_duplicates()\n",
        "        df = df.fillna(0)\n",
        "        # Define features and target variable\n",
        "        features = ['expScoreAdv', 'left', 'right', 'replacescore', 'FreqImp', 'Errors', 'Freq', 'LabelChanged']\n",
        "        X = df[features]\n",
        "        y = df['Label']\n",
        "\n",
        "        # Split the dataset into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "        # Setting up the pipeline with SMOTE and XGBoost\n",
        "        pipeline = imPipeline([\n",
        "            ('smote', SMOTE(random_state=42)),\n",
        "            ('classifier', xgb.XGBClassifier(random_state=42, use_label_encoder=False))\n",
        "        ])\n",
        "\n",
        "        # Define hyperparameters grid for RandomizedSearchCV\n",
        "        param_grid = {\n",
        "            'classifier__n_estimators': [100, 200, 500],\n",
        "            'classifier__max_depth': [3, 5, 7, 10],\n",
        "            'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
        "            'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
        "            'classifier__subsample': [0.6, 0.8, 1.0]\n",
        "        }\n",
        "\n",
        "        # Setup for RandomizedSearchCV\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=pipeline,\n",
        "            param_distributions=param_grid,\n",
        "            n_iter=10,\n",
        "            scoring='balanced_accuracy',\n",
        "            cv=cv,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Fit RandomizedSearchCV to the data\n",
        "        random_search.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluating the best model from RandomizedSearchCV\n",
        "        model = random_search.best_estimator_\n",
        "        results = []\n",
        "        overall_results = evaluate_model(model, X_test, y_test)\n",
        "        overall_results['Type'] = 'Overall'\n",
        "        results.append(overall_results)\n",
        "\n",
        "        # Evaluate model for each attack type\n",
        "        X_test_with_attack = X_test.copy()\n",
        "        X_test_with_attack['Attack'] = df.loc[X_test.index, 'Attack']\n",
        "\n",
        "        for attack in X_test_with_attack['Attack'].unique():\n",
        "          if(attack!='textfooler'):\n",
        "              idx = X_test_with_attack[X_test_with_attack['Attack'] == attack].index\n",
        "              X_attack = X_test_with_attack.loc[idx].drop('Attack', axis=1)\n",
        "              y_attack = y_test.loc[idx]\n",
        "\n",
        "              attack_results = evaluate_model(model, X_attack, y_attack)\n",
        "              attack_results['Type'] = attack\n",
        "              results.append(attack_results)\n",
        "\n",
        "        # Convert the list of dictionaries to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df.to_csv(savepath + 'Test_Seen_Attack_Types.csv', index=False)\n",
        "\n",
        "        print(results_df)\n",
        "\n",
        "        with open(savepath + 'XGBoost_identifier.pkl', 'wb') as file:\n",
        "                pickle.dump(model, file)\n"
      ],
      "metadata": {
        "id": "L_Em_mm9xEhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "datasets=['sst2']\n",
        "\n",
        "savepath='/content/gdrive/My Drive/GLAD_RESULTS/identifier_performance/'\n",
        "\n",
        "\n",
        "for dataset_name in datasets:\n",
        "  models=[]\n",
        "  if(dataset_name in ['imdb','ag-news']):\n",
        "    models.append('textattack/bert-base-uncased-'+dataset_name)\n",
        "\n",
        "    models.append('textattack/roberta-base-'+dataset_name)\n",
        "\n",
        "  elif(dataset_name =='sst2'):\n",
        "    models.append('textattack/bert-base-uncased-SST-2')\n",
        "    models.append('textattack/roberta-base-SST-2')\n",
        "\n",
        "  else:\n",
        "    models.append('textattack/bert-base-uncased-yelp-polarity')\n",
        "    models.append('VictorSanh/roberta-base-finetuned-yelp-polarity')\n",
        "\n",
        "\n",
        "  for model_name in models:\n",
        "        path = '/content/gdrive/My Drive/GLAD_RESULTS/' + dataset_name + '/'\n",
        "        savepath='/content/gdrive/My Drive/GLAD_RESULTS/identifier_performance/'\n",
        "        savepath=savepath+dataset_name+model_name.split('/')[1]\n",
        "        adversarial_file = path + 'Identify' + dataset_name + '_' + model_name.split('/')[1] + '_dataset_final_test.csv'\n",
        "        # Load the test dataset\n",
        "        print(\"MODEL \",model_name, \" Dataset \", dataset_name)\n",
        "        with open(savepath + 'XGBoost_identifier.pkl', 'rb') as file:\n",
        "                identifier=pickle.load(file)\n",
        "        df_test = pd.read_csv(adversarial_file)\n",
        "        df_test = df_test.drop_duplicates()\n",
        "        df_test = df_test.fillna(0)\n",
        "        # Define the features and labels\n",
        "        features = ['expScoreAdv', 'left', 'right', 'replacescore', 'FreqImp', 'Errors', 'Freq', 'LabelChanged']\n",
        "        print(\"Features used: \", features)\n",
        "        X_test = df_test[features]\n",
        "        y_test = df_test['Label']\n",
        "        print(adversarial_file)\n",
        "        # Load the trained model\n",
        "        # Make sure the model is loaded; assuming it's pickled or loaded elsewhere in your script\n",
        "        # with open('path_to_model.pkl', 'rb') as file:\n",
        "        #     model = pickle.load(file)\n",
        "\n",
        "        # Evaluate the model overall\n",
        "        overall_results= evaluate_model(identifier, X_test, y_test)\n",
        "        overall_results['Type'] = 'Overall'\n",
        "\n",
        "        # Initialize a list to store the results\n",
        "        results = [overall_results]\n",
        "\n",
        "        # Iterating over each unique attack type\n",
        "        for attack in df_test['Attack'].unique():\n",
        "            # Filter X_test for the current attack type, assuming 'Attack' is a column in df_test\n",
        "            idx = df_test[df_test['Attack'] == attack].index\n",
        "            X_attack = X_test.loc[idx]\n",
        "            y_attack = y_test.loc[idx]\n",
        "\n",
        "            # Evaluate the model\n",
        "            attack_results= evaluate_model(identifier, X_attack, y_attack)\n",
        "\n",
        "            # Create a report dictionary for the current attack type\n",
        "            attack_results['Type'] = attack\n",
        "            print(attack)\n",
        "            results.append(attack_results)\n",
        "\n",
        "        # Convert the list of dictionaries to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(results_df)\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv(savepath + 'Test_UnSeen_Attack_Types_.csv', index=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IJECtKcrzyhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7414df9-dbb3-41f6-aca1-130336ace5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL  textattack/bert-base-uncased-SST-2  Dataset  sst2\n",
            "Features used:  ['expScoreAdv', 'left', 'right', 'replacescore', 'FreqImp', 'Errors', 'Freq', 'LabelChanged']\n",
            "/content/gdrive/My Drive/GLAD_RESULTS/sst2/Identifysst2_bert-base-uncased-SST-2_dataset_final_test.csv\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "textbugger\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "textfooler\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "tf-adj\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "a2t\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.216535  0.369800  0.766266  0.678233  0.706832   0.667133   \n",
            "1  0.184466  0.181818  0.885912  0.766622  0.816858   0.746795   \n",
            "2  0.202397  0.291339  0.811663  0.727813  0.753132   0.716107   \n",
            "3  0.268170  0.630303  0.585145  0.531638  0.550763   0.535328   \n",
            "4  0.153153  0.413793  0.786683  0.718036  0.716527   0.719643   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index        Type  \n",
            "0           0.706832        0.413665     Overall  \n",
            "1           0.816858        0.633716  textbugger  \n",
            "2           0.753132        0.506265  textfooler  \n",
            "3           0.550763        0.101527      tf-adj  \n",
            "4           0.716527        0.433054         a2t  \n",
            "MODEL  textattack/roberta-base-SST-2  Dataset  sst2\n",
            "Features used:  ['expScoreAdv', 'left', 'right', 'replacescore', 'FreqImp', 'Errors', 'Freq', 'LabelChanged']\n",
            "/content/gdrive/My Drive/GLAD_RESULTS/sst2/Identifysst2_roberta-base-SST-2_dataset_final_test.csv\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "textbugger\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "textfooler\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "tf-adj\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "a2t\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.231295  0.418876  0.730080  0.651515  0.674915   0.643119   \n",
            "1  0.269094  0.330144  0.749161  0.622553  0.700381   0.619336   \n",
            "2  0.203913  0.379121  0.785929  0.701117  0.708483   0.696051   \n",
            "3  0.240964  0.720000  0.530671  0.513249  0.519518   0.515254   \n",
            "4  0.167568  0.460317  0.700644  0.684103  0.686057   0.682303   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index        Type  \n",
            "0           0.674915        0.349829     Overall  \n",
            "1           0.700381        0.400762  textbugger  \n",
            "2           0.708483        0.416966  textfooler  \n",
            "3           0.519518        0.039036      tf-adj  \n",
            "4           0.686057        0.372115         a2t  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparing with Baselines"
      ],
      "metadata": {
        "id": "dh9mShkoAnBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "datasets=['imdb','sst2','ag-news','yelp_polarity']\n",
        "\n",
        "\n",
        "for dataset_name in datasets:\n",
        "  models=[]\n",
        "  if(dataset_name in ['imdb','ag-news']):\n",
        "\n",
        "    models.append('textattack/bert-base-uncased-'+dataset_name)\n",
        "    models.append('textattack/roberta-base-'+dataset_name)\n",
        "  elif(dataset_name =='sst2'):\n",
        "    models.append('textattack/bert-base-uncased-SST-2')\n",
        "    models.append('textattack/roberta-base-SST-2')\n",
        "\n",
        "  else:\n",
        "    models.append('textattack/bert-base-uncased-yelp-polarity')\n",
        "    models.append('VictorSanh/roberta-base-finetuned-yelp-polarity')\n",
        "\n",
        "  print(dataset_name)\n",
        "  print(models)\n",
        "\n",
        "  for model_name in models:\n",
        "    features = ['expScoreAdv', 'replacescore', 'Freq']\n",
        "\n",
        "    for f in features:\n",
        "        path = '/content/gdrive/My Drive/GLAD_RESULTS/' + dataset_name + '/'\n",
        "        savepath='/content/gdrive/My Drive/GLAD_RESULTS/identifier_performance/'\n",
        "        savepath=savepath+dataset_name+model_name.split('/')[1]+f+\"_considered_\"\n",
        "        adversarial_file = path + 'Identify' + dataset_name + '_' + model_name.split('/')[1] + '_dataset_final_try.csv'\n",
        "        df = pd.read_csv(adversarial_file)\n",
        "        df = df.drop_duplicates()\n",
        "        df = df.fillna(0)\n",
        "        # Define features and target variable\n",
        "        print(\"Feature\")\n",
        "        X = df\n",
        "        y = df['Label']\n",
        "\n",
        "        # Split the dataset into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "        # Setting up the pipeline with SMOTE and XGBoost\n",
        "        pipeline = imPipeline([\n",
        "            ('smote', SMOTE(random_state=42)),\n",
        "            ('classifier', xgb.XGBClassifier(random_state=42, use_label_encoder=False))\n",
        "        ])\n",
        "\n",
        "        # Define hyperparameters grid for RandomizedSearchCV\n",
        "        param_grid = {\n",
        "            'classifier__n_estimators': [100, 200, 500],\n",
        "            'classifier__max_depth': [3, 5, 7, 10],\n",
        "            'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
        "            'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
        "            'classifier__subsample': [0.6, 0.8, 1.0]\n",
        "        }\n",
        "\n",
        "        # Setup for RandomizedSearchCV\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=pipeline,\n",
        "            param_distributions=param_grid,\n",
        "            n_iter=10,\n",
        "            scoring='balanced_accuracy',\n",
        "            cv=cv,\n",
        "            random_state=42\n",
        "        )\n",
        "        X_train=X_train[f]\n",
        "        X_attack=X_test\n",
        "        # Fit RandomizedSearchCV to the data\n",
        "        random_search.fit(np.array(X_train).reshape(-1,1), y_train)\n",
        "\n",
        "        # Evaluating the best model from RandomizedSearchCV\n",
        "        model = random_search.best_estimator_\n",
        "        results = []\n",
        "        overall_results = evaluate_model(model, np.array(X_test[f]).reshape(-1,1), y_test)\n",
        "        overall_results['Type'] = 'Overall'\n",
        "        results.append(overall_results)\n",
        "        print(X_attack.columns)\n",
        "        # Evaluate model for each attack type\n",
        "        X_test_with_attack = X_attack.copy()[[f,'Attack']]\n",
        "        X_test_with_attack['Attack'] = df.loc[X_attack.index, 'Attack']\n",
        "\n",
        "        for attack in X_test_with_attack['Attack'].unique():\n",
        "          if(attack!='textfooler'):\n",
        "              idx = X_test_with_attack[X_test_with_attack['Attack'] == attack].index\n",
        "              X_attack = X_test_with_attack.loc[idx].drop('Attack', axis=1)\n",
        "              y_attack = y_test.loc[idx]\n",
        "\n",
        "              attack_results = evaluate_model(model, np.array(X_attack).reshape(-1,1), y_attack)\n",
        "              attack_results['Type'] = attack\n",
        "              results.append(attack_results)\n",
        "\n",
        "        # Convert the list of dictionaries to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df.to_csv(savepath + 'Test_Seen_Attack_Types.csv', index=False)\n",
        "\n",
        "        print(results_df)\n",
        "\n",
        "        with open(savepath + 'XGBoost_identifier.pkl', 'wb') as file:\n",
        "                pickle.dump(model, file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yprRV5uMArKM",
        "outputId": "530ad86d-694d-4108-cd6b-6b6362b874a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdb\n",
            "['textattack/bert-base-uncased-imdb', 'textattack/roberta-base-imdb']\n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.240841  0.504670  0.670831  0.558512  0.627245   0.561966   \n",
            "1  0.258398  0.604034  0.591723  0.506818  0.568784   0.526923   \n",
            "2  0.222502  0.179104  0.871408  0.617796  0.799197   0.609110   \n",
            "3  0.227423  0.518519  0.675497  0.582929  0.627029   0.578600   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.627245        0.254490      Overall  \n",
            "1           0.568784        0.137568          bae  \n",
            "2           0.799197        0.598394  deepwordbug  \n",
            "3           0.627029        0.254058         pwws  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.300108  0.395711  0.697131  0.547621  0.652091   0.565462   \n",
            "1  0.320312  0.428875  0.661424  0.508390  0.625406   0.543025   \n",
            "2  0.262270  0.432836  0.691269  0.537054  0.652447   0.553541   \n",
            "3  0.291796  0.371648  0.720430  0.583595  0.668278   0.590068   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.652091        0.304181      Overall  \n",
            "1           0.625406        0.250813          bae  \n",
            "2           0.652447        0.304894  deepwordbug  \n",
            "3           0.668278        0.336557         pwws  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.313660  0.439986  0.679441  0.528707  0.623177   0.552447   \n",
            "1  0.305371  0.681529  0.526145  0.463942  0.506550   0.502377   \n",
            "2  0.345079  0.080597  0.924362  0.547052  0.787162   0.586586   \n",
            "3  0.309775  0.374202  0.722032  0.571008  0.658012   0.582853   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.623177        0.246353      Overall  \n",
            "1           0.506550        0.013100          bae  \n",
            "2           0.787162        0.574324  deepwordbug  \n",
            "3           0.658012        0.316023         pwws  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-be22b07c0906>:30: DtypeWarning: Columns (23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(adversarial_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16',\n",
            "       'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20',\n",
            "       'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.283854  0.370775  0.728799  0.549327  0.672686   0.566122   \n",
            "1  0.266300  0.471810  0.677975  0.523330  0.630945   0.544227   \n",
            "2  0.269912  0.350649  0.750798  0.582424  0.689720   0.587541   \n",
            "3  0.368421  0.192308  0.786708  0.512048  0.719636   0.564288   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.672686        0.345371      Overall  \n",
            "1           0.630945        0.261889          bae  \n",
            "2           0.689720        0.379439         pwws  \n",
            "3           0.719636        0.439271  deepwordbug  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-be22b07c0906>:30: DtypeWarning: Columns (23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(adversarial_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16',\n",
            "       'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20',\n",
            "       'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.306721  0.400596  0.690189  0.528427  0.646341   0.554433   \n",
            "1  0.307858  0.427300  0.682800  0.506988  0.632421   0.541446   \n",
            "2  0.314858  0.322820  0.732635  0.558822  0.681161   0.578370   \n",
            "3  0.281547  0.653846  0.537793  0.478065  0.532303   0.511119   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.646341        0.292683      Overall  \n",
            "1           0.632421        0.264843          bae  \n",
            "2           0.681161        0.362322         pwws  \n",
            "3           0.532303        0.064607  deepwordbug  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-be22b07c0906>:30: DtypeWarning: Columns (23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(adversarial_file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16',\n",
            "       'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20',\n",
            "       'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.203022  0.507952  0.700361  0.571028  0.644513   0.567593   \n",
            "1  0.196800  0.759644  0.552697  0.496040  0.521778   0.509382   \n",
            "2  0.205403  0.452690  0.738824  0.601094  0.670953   0.591949   \n",
            "3  0.213063  0.084615  0.933057  0.642090  0.851161   0.626376   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.644513        0.289025      Overall  \n",
            "1           0.521778        0.043556          bae  \n",
            "2           0.670953        0.341907         pwws  \n",
            "3           0.851161        0.702322  deepwordbug  \n",
            "sst2\n",
            "['textattack/bert-base-uncased-SST-2', 'textattack/roberta-base-SST-2']\n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.204506  0.378882  0.763254  0.682266  0.708306   0.670704   \n",
            "1  0.202952  0.388889  0.756868  0.657591  0.704080   0.643196   \n",
            "2  0.202797  0.377551  0.761827  0.694899  0.709826   0.686491   \n",
            "3  0.250000  0.333333  0.797222  0.694737  0.708333   0.689394   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.708306        0.416612      Overall  \n",
            "1           0.704080        0.408159          bae  \n",
            "2           0.709826        0.419652         pwws  \n",
            "3           0.708333        0.416667  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.301560  0.304348  0.784046  0.642202  0.697046   0.641601   \n",
            "1  0.321033  0.277778  0.814336  0.608156  0.700595   0.617073   \n",
            "2  0.286713  0.316327  0.777990  0.662810  0.698480   0.658875   \n",
            "3  0.250000  0.333333  0.719444  0.694737  0.708333   0.689394   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.697046        0.394092      Overall  \n",
            "1           0.700595        0.401189          bae  \n",
            "2           0.698480        0.396960         pwws  \n",
            "3           0.708333        0.416667  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.325823  0.397516  0.682331  0.595159  0.638331   0.599535   \n",
            "1  0.302583  0.574074  0.563687  0.529583  0.561671   0.539069   \n",
            "2  0.353147  0.336735  0.713643  0.613276  0.655059   0.620095   \n",
            "3  0.250000  0.000000  1.000000  0.819876  0.875000   0.821429   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.638331        0.276661      Overall  \n",
            "1           0.561671        0.123343          bae  \n",
            "2           0.655059        0.310118         pwws  \n",
            "3           0.875000        0.750000  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.265519  0.397213  0.721709  0.647720  0.668634   0.642253   \n",
            "1  0.230088  0.438462  0.725465  0.657047  0.665725   0.652099   \n",
            "2  0.293353  0.340580  0.712360  0.608857  0.683034   0.610919   \n",
            "3  0.284047  0.380682  0.730335  0.666674  0.667636   0.665984   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.668634        0.337268      Overall  \n",
            "1           0.665725        0.331450         pwws  \n",
            "2           0.683034        0.366068          bae  \n",
            "3           0.667636        0.335271  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.225569  0.512195  0.675060  0.625422  0.631118   0.621789   \n",
            "1  0.206490  0.419231  0.736204  0.680085  0.687140   0.675215   \n",
            "2  0.218208  0.471014  0.695663  0.618453  0.655389   0.609316   \n",
            "3  0.295720  0.681818  0.538015  0.506191  0.511231   0.512786   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.631118        0.262236      Overall  \n",
            "1           0.687140        0.374280         pwws  \n",
            "2           0.655389        0.310777          bae  \n",
            "3           0.511231        0.022462  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.172096  0.465157  0.751209  0.680040  0.681374   0.678785   \n",
            "1  0.197640  0.607692  0.692339  0.599848  0.597334   0.603566   \n",
            "2  0.174855  0.717391  0.599350  0.550109  0.553877   0.547994   \n",
            "3  0.097276  0.056818  0.968540  0.917246  0.922953   0.913894   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.681374        0.362747      Overall  \n",
            "1           0.597334        0.194668         pwws  \n",
            "2           0.553877        0.107753          bae  \n",
            "3           0.922953        0.845906  deepwordbug  \n",
            "ag-news\n",
            "['textattack/bert-base-uncased-ag-news', 'textattack/roberta-base-ag-news']\n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.382921  0.292439  0.711275  0.603100  0.662320   0.619021   \n",
            "1  0.381287  0.421053  0.635956  0.487035  0.598830   0.537029   \n",
            "2  0.363636  0.338403  0.690150  0.607945  0.648980   0.616306   \n",
            "3  0.408360  0.221574  0.744837  0.654244  0.685033   0.670652   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.662320        0.324639      Overall  \n",
            "1           0.598830        0.197661          bae  \n",
            "2           0.648980        0.297961         pwws  \n",
            "3           0.685033        0.370066  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.324944  0.437946  0.662441  0.589057  0.618555   0.591512   \n",
            "1  0.323977  0.400000  0.664426  0.525797  0.638012   0.554485   \n",
            "2  0.323529  0.361217  0.711926  0.624721  0.657627   0.625843   \n",
            "3  0.327974  0.507289  0.612927  0.580350  0.582369   0.579582   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.618555        0.237110      Overall  \n",
            "1           0.638012        0.276023          bae  \n",
            "2           0.657627        0.315254         pwws  \n",
            "3           0.582369        0.164737  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.104719  0.362340  0.832386  0.769216  0.766471   0.772132   \n",
            "1  0.095906  0.884211  0.535100  0.510029  0.509942   0.510132   \n",
            "2  0.117647  0.574144  0.742647  0.665249  0.654104   0.686905   \n",
            "3  0.101286  0.055394  0.976988  0.909669  0.921660   0.902169   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.766471        0.532941      Overall  \n",
            "1           0.509942        0.019883          bae  \n",
            "2           0.654104        0.308208         pwws  \n",
            "3           0.921660        0.843320  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.435951  0.335378  0.648139  0.561966  0.614335   0.586781   \n",
            "1  0.372599  0.270833  0.722966  0.649557  0.678284   0.657642   \n",
            "2  0.416822  0.350562  0.653273  0.582213  0.616308   0.596599   \n",
            "3  0.504931  0.456376  0.539031  0.426084  0.519347   0.508648   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.614335        0.228671      Overall  \n",
            "1           0.678284        0.356567  deepwordbug  \n",
            "2           0.616308        0.232616         pwws  \n",
            "3           0.519347        0.038693          bae  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.453752  0.473415  0.556425  0.504234  0.536416   0.527721   \n",
            "1  0.422535  0.533854  0.534264  0.514296  0.521805   0.519585   \n",
            "2  0.436449  0.424719  0.596839  0.543023  0.569416   0.557722   \n",
            "3  0.496055  0.463087  0.541579  0.429867  0.520429   0.509128   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.536416        0.072833      Overall  \n",
            "1           0.521805        0.043611  deepwordbug  \n",
            "2           0.569416        0.138832         pwws  \n",
            "3           0.520429        0.040858          bae  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.102269  0.412065  0.807958  0.751895  0.742833   0.763490   \n",
            "1  0.092190  0.046875  0.974145  0.915415  0.930468   0.905429   \n",
            "2  0.118692  0.564045  0.751663  0.669783  0.658632   0.697072   \n",
            "3  0.092702  0.899329  0.528696  0.503014  0.503984   0.505240   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.742833        0.485666      Overall  \n",
            "1           0.930468        0.860935  deepwordbug  \n",
            "2           0.658632        0.317263         pwws  \n",
            "3           0.503984        0.007969          bae  \n",
            "yelp_polarity\n",
            "['textattack/bert-base-uncased-yelp-polarity', 'VictorSanh/roberta-base-finetuned-yelp-polarity']\n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.261570  0.330579  0.761549  0.592167  0.703926   0.594179   \n",
            "1  0.252856  0.526690  0.650706  0.537650  0.610227   0.548367   \n",
            "2  0.220930  0.292969  0.809389  0.624220  0.743051   0.613436   \n",
            "3  0.319430  0.183871  0.818364  0.610522  0.748349   0.623157   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.703926        0.407851      Overall  \n",
            "1           0.610227        0.220454          bae  \n",
            "2           0.743051        0.486101         pwws  \n",
            "3           0.748349        0.496699  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.250439  0.428571  0.702944  0.574951  0.660495   0.577186   \n",
            "1  0.266184  0.505338  0.646237  0.534655  0.614239   0.548619   \n",
            "2  0.208855  0.406250  0.735783  0.604233  0.692447   0.595016   \n",
            "3  0.276704  0.377419  0.721415  0.590042  0.672938   0.592925   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.660495        0.320989      Overall  \n",
            "1           0.614239        0.228478          bae  \n",
            "2           0.692447        0.384895         pwws  \n",
            "3           0.672938        0.345877  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.164909  0.430933  0.768999  0.638521  0.702079   0.619795   \n",
            "1  0.166032  0.846975  0.541790  0.489899  0.493496   0.495874   \n",
            "2  0.182469  0.378906  0.805435  0.632513  0.719313   0.615017   \n",
            "3  0.143438  0.096774  0.942135  0.778710  0.879894   0.740359   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.702079        0.404158      Overall  \n",
            "1           0.493496       -0.013007          bae  \n",
            "2           0.719313        0.438625         pwws  \n",
            "3           0.879894        0.759787  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.306890  0.276987  0.769141  0.593824  0.708061   0.604077   \n",
            "1  0.270244  0.267035  0.803764  0.634162  0.731360   0.630605   \n",
            "2  0.307001  0.448718  0.667665  0.515718  0.622140   0.544498   \n",
            "3  0.386667  0.135294  0.792669  0.620809  0.739020   0.648964   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.708061        0.416123      Overall  \n",
            "1           0.731360        0.462721         pwws  \n",
            "2           0.622140        0.244281          bae  \n",
            "3           0.739020        0.478039  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.258596  0.530544  0.645258  0.555726  0.605430   0.559585   \n",
            "1  0.250643  0.465930  0.693535  0.589127  0.641714   0.586578   \n",
            "2  0.236989  0.458333  0.693785  0.557814  0.652339   0.563034   \n",
            "3  0.324912  0.700000  0.515167  0.479183  0.487544   0.491099   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.605430        0.210860      Overall  \n",
            "1           0.641714        0.283427         pwws  \n",
            "2           0.652339        0.304678          bae  \n",
            "3           0.487544       -0.024912  deepwordbug  \n",
            "Feature\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Index(['words', 'expScoreAdv', 'left', 'right', 'gradient', 'replacescore',\n",
            "       'FreqImp', 'Errors', 'Freq', 'LabelChanged', 'Label', 'Attack',\n",
            "       'Example'],\n",
            "      dtype='object')\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "Unique labels in y_test: [0 1]\n",
            "Unique labels in predictions: [0 1]\n",
            "        FPR       FNR       AUC  F1 Score    Recall  Precision  \\\n",
            "0  0.163168  0.425941  0.778330  0.657802  0.705445   0.639306   \n",
            "1  0.156812  0.414365  0.804549  0.675925  0.714412   0.657783   \n",
            "2  0.169455  0.842949  0.543973  0.488346  0.493798   0.496440   \n",
            "3  0.162807  0.061765  0.950284  0.810090  0.887714   0.780825   \n",
            "\n",
            "   Balanced Accuracy  Youden's Index         Type  \n",
            "0           0.705445        0.410891      Overall  \n",
            "1           0.714412        0.428823         pwws  \n",
            "2           0.493798       -0.012403          bae  \n",
            "3           0.887714        0.775428  deepwordbug  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "datasets=['sst2']\n",
        "\n",
        "savepath='/content/gdrive/My Drive/GLAD_RESULTS/identifier_performance/'\n",
        "\n",
        "\n",
        "for dataset_name in datasets:\n",
        "  models=[]\n",
        "  if(dataset_name in ['imdb','ag-news']):\n",
        "    models.append('textattack/bert-base-uncased-'+dataset_name)\n",
        "\n",
        "    models.append('textattack/roberta-base-'+dataset_name)\n",
        "\n",
        "  elif(dataset_name =='sst2'):\n",
        "    models.append('textattack/bert-base-uncased-SST-2')\n",
        "    models.append('textattack/roberta-base-SST-2')\n",
        "\n",
        "  else:\n",
        "    models.append('textattack/bert-base-uncased-yelp-polarity')\n",
        "    models.append('VictorSanh/roberta-base-finetuned-yelp-polarity')\n",
        "\n",
        "\n",
        "  for model_name in models:\n",
        "    features = ['expScoreAdv', 'replacescore', 'Freq']\n",
        "\n",
        "    for f in features:\n",
        "        path = '/content/gdrive/My Drive/GLAD_RESULTS/' + dataset_name + '/'\n",
        "        savepath='/content/gdrive/My Drive/GLAD_RESULTS/identifier_performance/'\n",
        "        savepath=savepath+dataset_name+model_name.split('/')[1]+f+\"_considered_\"\n",
        "        adversarial_file = path + 'Identify' + dataset_name + '_' + model_name.split('/')[1] + '_dataset_final_test.csv'\n",
        "        # Load the test dataset\n",
        "        print(\"MODEL \",model_name, \" Dataset \", dataset_name)\n",
        "        with open(savepath + 'XGBoost_identifier.pkl', 'rb') as file:\n",
        "                identifier=pickle.load(file)\n",
        "        df_test = pd.read_csv(adversarial_file)\n",
        "        df_test = df_test.drop_duplicates()\n",
        "        df_test = df_test.fillna(0)\n",
        "        # Define the features and labels\n",
        "        features = ['expScoreAdv', 'left', 'right', 'replacescore', 'FreqImp', 'Errors', 'Freq', 'LabelChanged']\n",
        "        print(\"Features used: \", f)\n",
        "        X_test = df_test[f]\n",
        "        y_test = df_test['Label']\n",
        "\n",
        "        # Load the trained model\n",
        "        # Make sure the model is loaded; assuming it's pickled or loaded elsewhere in your script\n",
        "        # with open('path_to_model.pkl', 'rb') as file:\n",
        "        #     model = pickle.load(file)\n",
        "\n",
        "        # Evaluate the model overall\n",
        "        overall_results= evaluate_model(identifier, np.array(X_test).reshape(-1,1), y_test)\n",
        "        overall_results['Type'] = 'Overall'\n",
        "\n",
        "        # Initialize a list to store the results\n",
        "        results = [overall_results]\n",
        "\n",
        "        # Iterating over each unique attack type\n",
        "        for attack in df_test['Attack'].unique():\n",
        "            # Filter X_test for the current attack type, assuming 'Attack' is a column in df_test\n",
        "            idx = df_test[df_test['Attack'] == attack].index\n",
        "            X_attack = X_test.loc[idx]\n",
        "            y_attack = y_test.loc[idx]\n",
        "\n",
        "            # Evaluate the model\n",
        "            attack_results= evaluate_model(identifier, X_attack, y_attack)\n",
        "\n",
        "            # Create a report dictionary for the current attack type\n",
        "            attack_results['Type'] = attack\n",
        "            print(attack)\n",
        "            results.append(attack_results)\n",
        "\n",
        "        # Convert the list of dictionaries to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(results_df)\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv(savepath + 'Test_UnSeen_Attack_Types_.csv', index=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elc1inEhJBuW",
        "outputId": "f83b2c49-85ae-465d-eb9c-9b8851bc499c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL  textattack/bert-base-uncased-SST-2  Dataset  sst2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "datasets=['ag-news','imdb','yelp_polarity','sst2']\n",
        "\n",
        "savepath='/content/gdrive/My Drive/GLAD_RESULTS/identifier_performance/'\n",
        "\n",
        "\n",
        "for dataset_name in datasets:\n",
        "  models=[]\n",
        "  if(dataset_name in ['imdb','ag-news']):\n",
        "    models.append('textattack/bert-base-uncased-'+dataset_name)\n",
        "\n",
        "    models.append('textattack/roberta-base-'+dataset_name)\n",
        "\n",
        "  elif(dataset_name =='sst2'):\n",
        "    models.append('textattack/bert-base-uncased-SST-2')\n",
        "    models.append('textattack/roberta-base-SST-2')\n",
        "\n",
        "  else:\n",
        "    models.append('textattack/bert-base-uncased-yelp-polarity')\n",
        "    models.append('VictorSanh/roberta-base-finetuned-yelp-polarity')\n",
        "\n",
        "\n",
        "  for model_name in models:\n",
        "        path = '/content/gdrive/My Drive/GLAD_RESULTS/' + dataset_name + '/'\n",
        "        savepath='/content/gdrive/My Drive/GLAD_RESULTS/identifier_performance/'\n",
        "        savepath=savepath+dataset_name+model_name.split('/')[1]\n",
        "        adversarial_file = path + 'Identify' + dataset_name + '_' + model_name.split('/')[1] + '_dataset_final_test.csv'\n",
        "        # Load the test dataset\n",
        "        print(\"MODEL \",model_name, \" Dataset \", dataset_name)\n",
        "        with open(savepath + 'XGBoost_identifier.pkl', 'rb') as file:\n",
        "                identifier=pickle.load(file)\n",
        "        df_test = pd.read_csv(adversarial_file)\n",
        "        df_test = df_test.drop_duplicates()\n",
        "        df_test = df_test.fillna(0)\n",
        "        # Define the features and labels\n",
        "        features = ['expScoreAdv', 'left', 'right', 'replacescore', 'FreqImp', 'Errors', 'Freq', 'LabelChanged']\n",
        "        print(\"Features used: \", features)\n",
        "        X_test = df_test[features]\n",
        "        y_test = df_test['Label']\n",
        "        print(adversarial_file)\n",
        "        # Load the trained model\n",
        "        # Make sure the model is loaded; assuming it's pickled or loaded elsewhere in your script\n",
        "        # with open('path_to_model.pkl', 'rb') as file:\n",
        "        #     model = pickle.load(file)\n",
        "\n",
        "        # Evaluate the model overall\n",
        "        overall_results= evaluate_model(identifier, X_test, y_test)\n",
        "        overall_results['Type'] = 'Overall'\n",
        "\n",
        "        # Initialize a list to store the results\n",
        "        results = [overall_results]\n",
        "\n",
        "        # Iterating over each unique attack type\n",
        "        for attack in df_test['Attack'].unique():\n",
        "            # Filter X_test for the current attack type, assuming 'Attack' is a column in df_test\n",
        "            idx = df_test[df_test['Attack'] == attack].index\n",
        "            X_attack = X_test.loc[idx]\n",
        "            y_attack = y_test.loc[idx]\n",
        "\n",
        "            # Evaluate the model\n",
        "            attack_results= evaluate_model(identifier, X_attack, y_attack)\n",
        "\n",
        "            # Create a report dictionary for the current attack type\n",
        "            attack_results['Type'] = attack\n",
        "            print(attack)\n",
        "            results.append(attack_results)\n",
        "\n",
        "        # Convert the list of dictionaries to a DataFrame\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(results_df)\n",
        "        # Save the DataFrame to a CSV file\n",
        "        results_df.to_csv(savepath + 'Test_UnSeen_Attack_Types_.csv', index=False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cx5h33PaYxBe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}